{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras_RetinaNet_TrainRaccoon.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wh0MB5I3--Gm"
      },
      "source": [
        "# Keras-RetinaNet으로 Custom data인 Raccoon 데이터셋 학습시키기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pdIwZ6A-3h4",
        "outputId": "4d659bb5-416b-4f5e-92d9-8c1f647172f8"
      },
      "source": [
        "# 현재 디렉토리는 /content이며 이 디렉토리를 기준으로 실습코드와 데이터를 다운로드 합니다. \n",
        "!pwd\n",
        "!rm -rf DLCV\n",
        "!git clone https://github.com/chulminkw/DLCV.git\n",
        "# DLCV 디렉토리가 Download되고 DLCV 밑에 Detection과 Segmentation 디렉토리가 있는 것을 확인\n",
        "!ls -lia \n",
        "!ls -lia DLCV\n",
        "\n",
        "# tensorflow 1.15을 설치합니다. 자동으로 tensorflow 2.2가 1.15으로 downgrade 됩니다. \n",
        "!pip install tensorflow-gpu==1.15.2 \n",
        "# keras 2.3를 설치합니다. \n",
        "!pip install keras==2.3.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'DLCV'...\n",
            "remote: Enumerating objects: 234, done.\u001b[K\n",
            "remote: Counting objects: 100% (75/75), done.\u001b[K\n",
            "remote: Compressing objects: 100% (71/71), done.\u001b[K\n",
            "remote: Total 234 (delta 32), reused 0 (delta 0), pack-reused 159\u001b[K\n",
            "Receiving objects: 100% (234/234), 142.72 MiB | 27.04 MiB/s, done.\n",
            "Resolving deltas: 100% (89/89), done.\n",
            "total 20\n",
            "4849680 drwxr-xr-x 1 root root 4096 Apr 30 04:14 .\n",
            "3407966 drwxr-xr-x 1 root root 4096 Apr 30 04:09 ..\n",
            "6029326 drwxr-xr-x 4 root root 4096 Apr 21 13:38 .config\n",
            "3407961 drwxr-xr-x 7 root root 4096 Apr 30 04:14 DLCV\n",
            "4849681 drwxr-xr-x 1 root root 4096 Apr 21 13:39 sample_data\n",
            "total 11016\n",
            "3407961 drwxr-xr-x 7 root root    4096 Apr 30 04:14  .\n",
            "4849680 drwxr-xr-x 1 root root    4096 Apr 30 04:14  ..\n",
            "3408118 drwxr-xr-x 2 root root    4096 Apr 30 04:14  colab_tf115_modify_files\n",
            "3408121 drwxr-xr-x 6 root root    4096 Apr 30 04:14  data\n",
            "3408084 drwxr-xr-x 8 root root    4096 Apr 30 04:14  Detection\n",
            "3408061 -rw-r--r-- 1 root root 6567662 Apr 30 04:14  DLCV_Colab_SrcCode_20200905.zip\n",
            "3407962 drwxr-xr-x 8 root root    4096 Apr 30 04:14  .git\n",
            "3408155 -rw-r--r-- 1 root root 2063693 Apr 30 04:14  labelimg.pptx\n",
            "3408156 -rw-r--r-- 1 root root 2612271 Apr 30 04:14 '구글클라우드 가입하기.pdf'\n",
            "3408110 -rw-r--r-- 1 root root     142 Apr 30 04:14  README.md\n",
            "3408111 drwxr-xr-x 3 root root    4096 Apr 30 04:14  Segmentation\n",
            "Collecting tensorflow-gpu==1.15.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/42/7bddc0d5bc169596fbd13b6e1b844f832491ab671381e483da3bf5292ca9/tensorflow_gpu-1.15.2-cp37-cp37m-manylinux2010_x86_64.whl (410.9MB)\n",
            "\u001b[K     |████████████████████████████████| 411.0MB 44kB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (0.36.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.19.5)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (0.8.1)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.12.1)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.32.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 65.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.1.2)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 42.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (0.12.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (3.12.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15.2) (2.10.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (56.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (3.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (3.4.1)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7540 sha256=ffde5a1e6c6d43e1b06b50c00bafe2c77204a448525f6e8cde37a0ce43c32dea\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement tensorboard~=2.4, but you'll have tensorboard 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement tensorflow-estimator<2.5.0,>=2.4.0, but you'll have tensorflow-estimator 1.15.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gast, keras-applications, tensorboard, tensorflow-estimator, tensorflow-gpu\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-estimator-1.15.1 tensorflow-gpu-1.15.2\n",
            "Collecting keras==2.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/18/2e1ef121e5560ac24c7ac9e363aa5fa7006c40563c989e7211aba95b793a/Keras-2.3.0-py2.py3-none-any.whl (377kB)\n",
            "\u001b[K     |████████████████████████████████| 378kB 12.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.3.0) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.0) (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.0) (1.19.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.0) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.0) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.3.0) (2.10.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.0) (1.0.8)\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "Successfully installed keras-2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "jl7Srzt5_G8u",
        "outputId": "c6aae33c-f3e2-46cc-bff9-be41281c1f15"
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "print(tf.__version__)\n",
        "print(keras.__version__)\n",
        "\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n",
            "2.3.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "''"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCuouJ0RDA0G"
      },
      "source": [
        "## Keras-RetinaNet 다운로드\n",
        "- 최근 Keras 2.4 버전으로 마이그레이션되어서 이전 코드를 <a href='https://github.com/chulminkw/keras-retinanet-tf115'>여기</a>에서 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYY9P8MB_c3T",
        "outputId": "6fe36fb4-ab9a-4291-e70b-ae70bde9825e"
      },
      "source": [
        "%cd /content/DLCV/Detection/retina\n",
        "!rm -rf /content/DLCV/Detection/retina/keras-retinanet\n",
        "# fizyr keras-retinanet이 현재 keras 2.4 로 마이그레이션 되면서 버그가 많아짐.\n",
        "#  tensorflow 1.15와 호환되는 keras-retinanet 버전(v0.5.1) 다운로드를 https://github.com/chulminkw/keras-retinanet-tf115.git 에서 수행. \n",
        "!git clone https://github.com/chulminkw/keras-retinanet-tf115.git keras-retinanet\n",
        "\n",
        "#  https://github.com/chulminkw/keras-retinanet-tf115.git에서 download받은 keras-retinanet 설치\n",
        "%cd /content/DLCV/Detection/retina/keras-retinanet\n",
        "!echo \"##### installing keras-retinanet\"\n",
        "!pip install . --user\n",
        "!python setup.py build_ext --inplace"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/DLCV/Detection/retina\n",
            "Cloning into 'keras-retinanet'...\n",
            "remote: Enumerating objects: 149, done.\u001b[K\n",
            "remote: Total 149 (delta 0), reused 0 (delta 0), pack-reused 149\u001b[K\n",
            "Receiving objects: 100% (149/149), 2.12 MiB | 23.63 MiB/s, done.\n",
            "Resolving deltas: 100% (70/70), done.\n",
            "/content/DLCV/Detection/retina/keras-retinanet\n",
            "##### installing keras-retinanet\n",
            "Processing /content/DLCV/Detection/retina/keras-retinanet\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from keras-retinanet==0.5.1) (2.3.0)\n",
            "Collecting keras-resnet\n",
            "  Downloading https://files.pythonhosted.org/packages/76/d4/a35cbd07381139dda4db42c81b88c59254faac026109022727b45b31bcad/keras-resnet-0.2.0.tar.gz\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from keras-retinanet==0.5.1) (1.15.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from keras-retinanet==0.5.1) (1.4.1)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from keras-retinanet==0.5.1) (0.29.22)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from keras-retinanet==0.5.1) (7.1.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from keras-retinanet==0.5.1) (4.1.2.30)\n",
            "Requirement already satisfied: progressbar2 in /usr/local/lib/python3.7/dist-packages (from keras-retinanet==0.5.1) (3.38.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras->keras-retinanet==0.5.1) (1.19.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras->keras-retinanet==0.5.1) (2.10.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from keras->keras-retinanet==0.5.1) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras->keras-retinanet==0.5.1) (1.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras->keras-retinanet==0.5.1) (3.13)\n",
            "Requirement already satisfied: python-utils>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from progressbar2->keras-retinanet==0.5.1) (2.5.6)\n",
            "Building wheels for collected packages: keras-retinanet, keras-resnet\n",
            "  Building wheel for keras-retinanet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-retinanet: filename=keras_retinanet-0.5.1-cp37-cp37m-linux_x86_64.whl size=145786 sha256=68dd861b33c553f5e9f8b87af581b35d0aaf8373e9553e6178c630cf087706b9\n",
            "  Stored in directory: /root/.cache/pip/wheels/78/11/a0/e7d32b794790f97776b6d352fbb95de0eb246ebbdb5515c99a\n",
            "  Building wheel for keras-resnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-resnet: filename=keras_resnet-0.2.0-py2.py3-none-any.whl size=20486 sha256=bc082cc42ca845eb40ab1fbea7de17c3ede8afa7950d0a12aa01d0de8e6e6576\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/09/a5/497a30fd9ad9964e98a1254d1e164bcd1b8a5eda36197ecb3c\n",
            "Successfully built keras-retinanet keras-resnet\n",
            "Installing collected packages: keras-resnet, keras-retinanet\n",
            "\u001b[33m  WARNING: The scripts retinanet-convert-model, retinanet-debug, retinanet-evaluate and retinanet-train are installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "Successfully installed keras-resnet-0.2.0 keras-retinanet-0.5.1\n",
            "running build_ext\n",
            "cythoning keras_retinanet/utils/compute_overlap.pyx to keras_retinanet/utils/compute_overlap.c\n",
            "/usr/local/lib/python3.7/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/DLCV/Detection/retina/keras-retinanet/keras_retinanet/utils/compute_overlap.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "building 'keras_retinanet.utils.compute_overlap' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-3.7\n",
            "creating build/temp.linux-x86_64-3.7/keras_retinanet\n",
            "creating build/temp.linux-x86_64-3.7/keras_retinanet/utils\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/include/python3.7m -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -c keras_retinanet/utils/compute_overlap.c -o build/temp.linux-x86_64-3.7/keras_retinanet/utils/compute_overlap.o\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1822:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kkeras_retinanet/utils/compute_overlap.c:610\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
            " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
            "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "creating build/lib.linux-x86_64-3.7\n",
            "creating build/lib.linux-x86_64-3.7/keras_retinanet\n",
            "creating build/lib.linux-x86_64-3.7/keras_retinanet/utils\n",
            "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/keras_retinanet/utils/compute_overlap.o -o build/lib.linux-x86_64-3.7/keras_retinanet/utils/compute_overlap.cpython-37m-x86_64-linux-gnu.so\n",
            "copying build/lib.linux-x86_64-3.7/keras_retinanet/utils/compute_overlap.cpython-37m-x86_64-linux-gnu.so -> keras_retinanet/utils\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCZRpGCvDVGd",
        "outputId": "ac64ce8c-d8b4-48b0-f533-67b367e8f50a"
      },
      "source": [
        "# 다운로드 받은 Keras-Retinanet 모듈 임포트 되는지 확인 -> 런타임 다시시작 한번 해주어야 함\n",
        "from keras_retinanet import models\n",
        "from keras_retinanet.models import backbone\n",
        "\n",
        "b = backbone('resnet50')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaY5NLkVDx7F"
      },
      "source": [
        "## Custom 데이터인 Raccoon 데이터셋 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6f0ritqDnJp",
        "outputId": "06060256-35c6-44f2-8bd5-525242aa87bc"
      },
      "source": [
        "# /content/DLCV/data 디렉토리에 raccoon_dataset을 다운로드함. \n",
        "%cd /content/DLCV/data/\n",
        "!git clone https://github.com/experiencor/raccoon_dataset.git\n",
        "# raccoon_dataset을 raccoon으로 디렉토리 이름 변경하고 확인 \n",
        "!mv raccoon_dataset raccoon\n",
        "!ls -lia"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/DLCV/data\n",
            "Cloning into 'raccoon_dataset'...\n",
            "remote: Enumerating objects: 646, done.\u001b[K\n",
            "remote: Total 646 (delta 0), reused 0 (delta 0), pack-reused 646\u001b[K\n",
            "Receiving objects: 100% (646/646), 48.00 MiB | 22.02 MiB/s, done.\n",
            "Resolving deltas: 100% (412/412), done.\n",
            "total 28\n",
            "3408121 drwxr-xr-x 7 root root 4096 Apr 30 04:35 .\n",
            "3407961 drwxr-xr-x 7 root root 4096 Apr 30 04:14 ..\n",
            "3408122 drwxr-xr-x 2 root root 4096 Apr 30 04:14 image\n",
            "3408135 drwxr-xr-x 2 root root 4096 Apr 30 04:14 output\n",
            "3408328 drwxr-xr-x 7 root root 4096 Apr 30 04:35 raccoon\n",
            "3408137 drwxr-xr-x 2 root root 4096 Apr 30 04:14 util\n",
            "3408144 drwxr-xr-x 2 root root 4096 Apr 30 04:14 video\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKkZQkQAD8yL"
      },
      "source": [
        "## Raccoon 데이터셋 image, annotation 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L26W7u15D33k"
      },
      "source": [
        "# image, annotation 디렉토리 설정\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "HOME_DIR = '/content'\n",
        "\n",
        "ANNO_DIR = os.path.join(HOME_DIR, 'DLCV/data/raccoon/annotations')\n",
        "IMAGE_DIR = os.path.join(HOME_DIR, 'DLCV/data/raccoon/images')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJhvGw9GEmy-"
      },
      "source": [
        "- Object에 대한 annotation 정보를 CSV 포맷으로 설정\n",
        "- csv 형태의 annotation과 class mapping format이 필요. annotation은 아래와 같이 표현 가능하며 하나의 오브젝트당 한 라인에서 comma로 정보를 분리함. 만일 하나의 이미지 파일에서 두개 이상의 오브젝트가 있다면 두개 이상의 라인으로 정보 표시.\n",
        "```\n",
        "/data/imgs/img_001.jpg,837,346,981,456,cow\n",
        "/data/imgs/img_002.jpg,215,312,279,391,cat\n",
        "/data/imgs/img_002.jpg,22,5,89,84,bird\n",
        "/data/imgs/img_003.jpg,,,,,\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bH6UENYVGtt0"
      },
      "source": [
        "### 학습, 검증 데이터 분할"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VcXJQqDEYjk"
      },
      "source": [
        "# 학습 데이터와 검증 데이터 분할해야 하므로 annotation 정보도 학습,검증으로 분할\n",
        "# keras-Retinanet은 validation annotation으로 학습 시 모델 evaluation 가능\n",
        "import glob\n",
        "import numpy as np\n",
        "\n",
        "def get_train_valid_indexes(anno_path, valid_size):\n",
        "  '''\n",
        "  Args:\n",
        "    anno_path: Annotation 정보있는 경로\n",
        "    valid_size: Validation 데이터 비율(ex. 0.2, 0.3 ...)\n",
        "  '''\n",
        "  np.random.seed(0) # 분할 시드 설정\n",
        "\n",
        "  xml_files = [xml_file for xml_file in glob.glob(os.path.join(anno_path, '*.xml'))]\n",
        "  xml_files = np.array(xml_files)\n",
        "  total_cnt = xml_files.shape[0]\n",
        "  valid_cnt = int(total_cnt * valid_size)\n",
        "\n",
        "  total_idx = np.arange(0, total_cnt)\n",
        "  valid_idx = np.random.choice(total_cnt, size=valid_cnt, replace=False) # replace:복원추출\n",
        "  # np.isin(타겟대상들, 찾을요소들) -> True/False로 반환\n",
        "  train_idx = total_idx[~np.isin(total_idx, valid_idx)] # Fancy Index\n",
        "  \n",
        "  return train_idx, valid_idx\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8vtdBIdGbgj",
        "outputId": "5e029f84-af84-4db1-9635-3455dac90a41"
      },
      "source": [
        "train_idx, valid_idx = get_train_valid_indexes(ANNO_DIR, 0.2)\n",
        "print(train_idx.shape, valid_idx.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(160,) (40,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPkcePLzGv9N"
      },
      "source": [
        "### Annotation XML -> CSV 포맷으로 변경"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsCsrMCBGdTy"
      },
      "source": [
        "import glob\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "def xml_to_csv_sampling(path, output_filename, sample_idx):\n",
        "  '''\n",
        "  Args:\n",
        "    path: annotation 경로\n",
        "    output_filename: XML->CSV로 변경해 write한 파일명\n",
        "    sample_idx: train or validation 데이터 index\n",
        "  '''\n",
        "  xml_list = np.array([xml_file for xml_file in glob.glob(path + '/*.xml')])\n",
        "  # Train or Validation\n",
        "  xml_list = xml_list[sample_idx]\n",
        "  # XML -> CSV format으로 변경\n",
        "  with open(output_filename, 'w') as csv_file:\n",
        "    for xml_file in xml_list:\n",
        "      # XML Parsing\n",
        "      tree = ET.parse(xml_file)\n",
        "      root = tree.getroot()\n",
        "      full_image_name = os.path.join(IMAGE_DIR, root.find('filename').text)\n",
        "      for obj in root.findall('object'):\n",
        "        xmlbox = obj.find('bndbox')\n",
        "        x1 = int(xmlbox.find('xmin').text)\n",
        "        y1 = int(xmlbox.find('ymin').text)\n",
        "        x2 = int(xmlbox.find('xmax').text)\n",
        "        y2 = int(xmlbox.find('ymax').text)\n",
        "        class_name = 'raccoon'\n",
        "        value_str = f\"{full_image_name},{x1},{y1},{x2},{y2},{class_name}\"\n",
        "        csv_file.write(value_str + '\\n')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9VFlMxJHqOa"
      },
      "source": [
        "train_idx, valid_idx = get_train_valid_indexes(ANNO_DIR, 0.2)\n",
        "xml_to_csv_sampling(ANNO_DIR, os.path.join(ANNO_DIR, 'raccoon_anno_retina_train.csv'),\n",
        "                    train_idx)\n",
        "xml_to_csv_sampling(ANNO_DIR, os.path.join(ANNO_DIR, 'raccoon_anno_retina_valid.csv'),\n",
        "                    valid_idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7hCXgc7KGgq",
        "outputId": "6b15dbaf-e905-489a-abb8-56be11592b87"
      },
      "source": [
        "# Class_id - Class_name 매핑하는 txt 파일 생성\n",
        "default_dir = '/content/DLCV'\n",
        "classes_path = os.path.join(default_dir, 'data/raccoon/annotations/raccoon_class.txt')\n",
        "\n",
        "with open(classes_path, 'w') as f:\n",
        "  f.write(\"raccoon, 0\")\n",
        "\n",
        "!cat /content/DLCV/data/raccoon/annotations/raccoon_class.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "raccoon, 0"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfNqe9XqK6Ms"
      },
      "source": [
        "## Keras-RetinaNet 중에서 COCO 데이터셋으로 Pretrained된 모델 다운로드 및 로드\n",
        "- 이 모델을 로드하고 라쿤 데이터셋을 학습시킬 예정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmP_SLf7K3vH",
        "outputId": "872204b7-61a1-4ddf-f398-c50efadce649"
      },
      "source": [
        "%cd /content/DLCV/Detection/retina/keras-retinanet/snapshots/\n",
        "\n",
        "# snapshots 디렉토리에 coco dataset으로 pretrain된 Keras-Retinanet 모델 저장\n",
        "!wget https://github.com/fizyr/keras-retinanet/releases/download/0.5.1/resnet50_coco_best_v2.1.0.h5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/DLCV/Detection/retina/keras-retinanet/snapshots\n",
            "--2021-04-30 05:07:49--  https://github.com/fizyr/keras-retinanet/releases/download/0.5.1/resnet50_coco_best_v2.1.0.h5\n",
            "Resolving github.com (github.com)... 140.82.121.3\n",
            "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-releases.githubusercontent.com/100249425/b7184a80-9350-11e9-9cc2-454f5c616394?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210430%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210430T050749Z&X-Amz-Expires=300&X-Amz-Signature=07cde49d1948d3c67783f5cdccec80232e2a65bb9a298c25a7db09c12b0ef3f4&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=100249425&response-content-disposition=attachment%3B%20filename%3Dresnet50_coco_best_v2.1.0.h5&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-04-30 05:07:49--  https://github-releases.githubusercontent.com/100249425/b7184a80-9350-11e9-9cc2-454f5c616394?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210430%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210430T050749Z&X-Amz-Expires=300&X-Amz-Signature=07cde49d1948d3c67783f5cdccec80232e2a65bb9a298c25a7db09c12b0ef3f4&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=100249425&response-content-disposition=attachment%3B%20filename%3Dresnet50_coco_best_v2.1.0.h5&response-content-type=application%2Foctet-stream\n",
            "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.109.154, 185.199.108.154, 185.199.111.154, ...\n",
            "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.109.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 152662144 (146M) [application/octet-stream]\n",
            "Saving to: ‘resnet50_coco_best_v2.1.0.h5’\n",
            "\n",
            "resnet50_coco_best_ 100%[===================>] 145.59M  41.2MB/s    in 4.6s    \n",
            "\n",
            "2021-04-30 05:07:54 (31.3 MB/s) - ‘resnet50_coco_best_v2.1.0.h5’ saved [152662144/152662144]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuEyW4aYLUzz"
      },
      "source": [
        "## Keras-Retina Net으로 학습시키는 1번 방법\n",
        "- ``train.py`` 모듈만을 사용\n",
        "- 이렇게 학습시키면 학습시간이 비교적 오래걸림\n",
        "- ``batch_size`` 파라미터값이 2이상 설정 시 메모리 에러 발생\n",
        "- 라쿤 데이터셋은 자그마한 데이터셋이므로 ``epoch``와 ``steps`` 하이퍼파라미터 개별로 설정해주기\n",
        "- 따로 하이퍼파라미터 입력안해줄 시 모두 코드 내부에서 작성된 디폴트 파라미터로 수행됨\n",
        "- shell script로 수행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "UQzU-u3aLFj0",
        "outputId": "408d2605-c91d-4599-8b38-5fbe30002070"
      },
      "source": [
        "!chmod +x /content/DLCV/Detection/retina/keras-retinanet/keras_retinanet/bin/train.py\n",
        "\n",
        "# train.py -> 하이퍼파라미터 -> train_annotation 경로 -> class_id-name 경로 -> validation_annotation 경로\n",
        "!/content/DLCV/Detection/retina/keras-retinanet/keras_retinanet/bin/train.py --epochs=10 --steps=200 \\\n",
        "  csv /content/DLCV/data/raccoon/annotations/raccoon_anno_retina_train.csv \\\n",
        "      /content/DLCV/data/raccoon/annotations/raccoon_class.txt \\\n",
        "      --val-annotations=/content/DLCV/data/raccoon/annotations/raccoon_anno_retina_valid.csv \\"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Process ForkPoolWorker-1:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
            "    task = get()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 352, in get\n",
            "    res = self._reader.recv_bytes()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
            "    buf = self._recv_bytes(maxlength)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
            "    buf = self._recv(4)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
            "    chunk = read(handle, remaining)\n",
            "KeyboardInterrupt\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/DLCV/Detection/retina/keras-retinanet/keras_retinanet/bin/train.py\", line 514, in <module>\n",
            "    main()\n",
            "  File \"/content/DLCV/Detection/retina/keras-retinanet/keras_retinanet/bin/train.py\", line 509, in main\n",
            "    validation_data=validation_generator\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1732, in fit_generator\n",
            "    initial_epoch=initial_epoch)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training_generator.py\", line 220, in fit_generator\n",
            "    reset_metrics=False)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1514, in train_on_batch\n",
            "    outputs = self.train_function(ins)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/backend.py\", line 3476, in __call__\n",
            "    run_metadata=self.run_metadata)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\", line 1472, in __call__\n",
            "    run_metadata_ptr)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YE8Y0uSMayu"
      },
      "source": [
        "## Keras-Retina Net으로 학습시키는 2번 방법\n",
        "- ``train.py`` 파일의 여러 모듈을 직접 임포트하고 약간의 파라미터 수정 후 직접 학습 수행\n",
        "- 이렇게 하면 학습시간 상대적으로 빨라짐\n",
        "- 모듈이 내부적으로 어떻게 동작하는지 이해 가능"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MupWj-KqMAET"
      },
      "source": [
        "# 필요한 모듈들 임포트\n",
        "import cv2\n",
        "from os import listdir, walk # 하위 디렉토리, 파일을 탐색해주는 라이브러리\n",
        "import math\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from os.path import join\n",
        "\n",
        "# Keras 모듈\n",
        "from keras_retinanet.bin.train import create_generators, create_models, create_callbacks\n",
        "from keras_retinanet.models import backbone, load_model, convert_model\n",
        "from keras_retinanet.utils.config import read_config_file, parse_anchor_parameters\n",
        "from keras_retinanet.utils.visualization import draw_boxes\n",
        "\n",
        "tf.set_random_seed(31)\n",
        "np.random.seed(17)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6QqbTmrNtNq"
      },
      "source": [
        "### 환경 파라미터(config) 설정\n",
        "- ``config`` 클래스명으로 설정하는 이유는 Keras-Retina Net 코드 내부에서 환경설정 파라미터 값들을 실제 ``config`` 클래스명 안에 저장해놓았기 때문! 이를 이용해 우리가 ``config``를 커스터마이징해서 자연스레 연결"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sxts-zVNpat"
      },
      "source": [
        "b = backbone('resnet50')\n",
        "files = os.listdir(ANNO_DIR) # 모든 annotation 파일들\n",
        "train_file_cnt = train_idx.shape[0]\n",
        "\n",
        "class args:\n",
        "  batch_size = 4\n",
        "  config = None\n",
        "  random_transform = True # 자체적으로 제작한 Data Augmentation 기법\n",
        "  annotations = os.path.join(ANNO_DIR, 'raccoon_anno_retina_train.csv')\n",
        "  val_annotations = os.path.join(ANNO_DIR, 'raccoon_anno_retina_valid.csv')\n",
        "  classes = os.path.join(ANNO_DIR, 'raccoon_class.txt')\n",
        "\n",
        "  image_min_side = 800\n",
        "  image_max_side = 1333\n",
        "  no_resize = None\n",
        "  dataset_type = 'csv'\n",
        "  tensorboard_dir = ''\n",
        "  evaluation = True\n",
        "  snapshots = True\n",
        "  # 학습한 모델 저장할 디렉토리 설정\n",
        "  snapshot_path = '/content/DLCV/Detection/retina/keras-retinanet/snapshots'\n",
        "  backbone = 'resnet50'\n",
        "  # 학습 파라미터\n",
        "  epochs = 10\n",
        "  steps = train_file_cnt // batch_size\n",
        "  weighted_average = True\n",
        "  # 코랩 버전 keras-retinanet upgrade에 따른  신규 추가\n",
        "  reduce_lr_patience = 2\n",
        "  reduce_lr_factor = 0.1\n",
        "  #  코랩 버전 keras-retinanet upgrade에 따른 신규 추가 2020.08.29\n",
        "  group_method='ratio'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQBAAtSfPGCN"
      },
      "source": [
        "### Train/Valid Generator 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHO8eG8MOGGQ"
      },
      "source": [
        "train_gen, valid_gen = create_generators(args, b.preprocess_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUqAIEudPPL7"
      },
      "source": [
        "### Backend CNN인 Resnet과 기타 환경 config 설정으로 기본 모델 생성\n",
        "- 아직 COCO 데이터셋으로 Pretrained된 weight로드 안 한 상태임!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meI0zOfK7sCS"
      },
      "source": [
        "- ``model``과 ``training_model``은 거의 동일. 다만 ``training_model``은 멀티 GPU 학습을 가능하게 하도록 만든 모델. 그래서 GPU가 1개 이면 두개 동일\n",
        "- Object Detection 모델은 classification 모델과 다르게 마지막 layer가 Convolution Layer로 되어 있음. 그래서 최종 학습 결과가 Cov layer로 되어있고 이를 클래스, BB 좌표를 이끌어내는 layer와 NMS 필터링 layer가 Inference 모델에 따로 갖추어져 있음.\n",
        "- 그래서 어떤 패키지는 train, inference를 하나에서 구현하지만 train 모델은 이 inference layer를 학습하지 않음.\n",
        "- 여기서 사용한 ``fyzyr keras retinanet``은 train, inference 모델을 각각 가져가는 방식  취함"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYXp2usVPNlh",
        "outputId": "c0bec996-29c5-4a82-dba4-3ee58e29c6e7"
      },
      "source": [
        "model, training_model, prediction_model = create_models(backbone_retinanet=b.retinanet,\n",
        "                                                        num_classes=train_gen.num_classes(),\n",
        "                                                        weights=None,\n",
        "                                                        multi_gpu=False,\n",
        "                                                        freeze_backbone=True,\n",
        "                                                        lr=1e-3,\n",
        "                                                        config=args.config)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /root/.local/lib/python3.7/site-packages/keras_retinanet/backend/tensorflow_backend.py:68: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "tracking <tf.Variable 'Variable:0' shape=(9, 4) dtype=float32> anchors\n",
            "tracking <tf.Variable 'Variable_1:0' shape=(9, 4) dtype=float32> anchors\n",
            "tracking <tf.Variable 'Variable_2:0' shape=(9, 4) dtype=float32> anchors\n",
            "tracking <tf.Variable 'Variable_3:0' shape=(9, 4) dtype=float32> anchors\n",
            "tracking <tf.Variable 'Variable_4:0' shape=(9, 4) dtype=float32> anchors\n",
            "WARNING:tensorflow:From /root/.local/lib/python3.7/site-packages/keras_retinanet/backend/tensorflow_backend.py:104: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrzytW-2Ppvc"
      },
      "source": [
        "### Callback 함수들 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNWbBYVbPnrP"
      },
      "source": [
        "callbacks = create_callbacks(model,\n",
        "                             training_model,\n",
        "                             prediction_model,\n",
        "                             valid_gen,\n",
        "                             args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJhLXf9MPzF5"
      },
      "source": [
        "### 기본 모델에 COCO 데이터셋으로 Pretrained된 모델을 최초 weight로 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4GlLyz8Px9k",
        "outputId": "13b17c4c-e87f-4326-81a0-7c95e72b9fcc"
      },
      "source": [
        "default_retina_dir = '/content/DLCV/Detection/retina'\n",
        "training_model.load_weights(os.path.join(default_retina_dir,\n",
        "                                         'keras-retinanet/snapshots/resnet50_coco_best_v2.1.0.h5'),\n",
        "                            skip_mismatch=True,\n",
        "                            by_name=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/saving.py:1316: UserWarning: Skipping loading of weights for layer classification_submodel due to mismatch in shape ((3, 3, 256, 9) vs (720, 256, 3, 3)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.7/dist-packages/keras/engine/saving.py:1316: UserWarning: Skipping loading of weights for layer classification_submodel due to mismatch in shape ((9,) vs (720,)).\n",
            "  weight_values[i].shape))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hg-DwATLQrNk"
      },
      "source": [
        "### 이제 Raccoon 데이터셋으로 학습 시작\n",
        "\n",
        "-``args`` 클래스에 라쿤 데이터셋에 대한 경로(정보)가 다들어있음. 그래서 Generator들이 이 ``args``를 통해 라쿤 데이터셋 학습!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "collapsed": true,
        "id": "pD13-sOjQeKR",
        "outputId": "719b84ec-88a9-4169-bd94-e59ae74073c3"
      },
      "source": [
        "training_model.fit_generator(generator=train_gen,\n",
        "                             steps_per_epoch=args.steps,\n",
        "                             epochs=args.epochs,\n",
        "                             verbose=1,\n",
        "                             validation_data=valid_gen,\n",
        "                             callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Epoch 1/10\n",
            "36/40 [==========================>...] - ETA: 2:46 - loss: 1.6875 - regression_loss: 1.3431 - classification_loss: 0.3444"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-c4d6d297d3bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                              \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                              \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                              callbacks=callbacks)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSBmLMljS1Fm"
      },
      "source": [
        "## 주어진 새로운 이미지를 Detect하기 위해서는 Inference용 Keras-Retina Net으로 바꾸어주어야 함!\n",
        "- ``convert_model.py`` 활용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_a2nhRURqP9"
      },
      "source": [
        "# 가장 마지막에 만들어진 학습 모델을 변환합니다. \n",
        "!chmod +x /content/DLCV/Detection/retina/keras-retinanet/keras_retinanet/bin/convert_model.py\n",
        "!/content/DLCV/Detection/retina/keras-retinanet/keras_retinanet/bin/convert_model.py /content/DLCV/Detection/retina/keras-retinanet/snapshots/resnet50_csv_10.h5 \\\n",
        "/content/DLCV/Detection/retina/keras-retinanet/snapshots/raccoon_inference.h5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBxBFBq7TEYq"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "ROOT_DIR = os.path.abspath('.')\n",
        "sys.path.append(ROOT_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0VCmxvZTK_h"
      },
      "source": [
        "# show images inline\n",
        "%matplotlib inline\n",
        "\n",
        "# automatically reload modules when they have changed\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# import keras\n",
        "import keras\n",
        "\n",
        "# import miscellaneous modules\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "\n",
        "from keras_retinanet import models\n",
        "from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
        "from keras_retinanet.utils.visualization import draw_box, draw_caption\n",
        "from keras_retinanet.utils.colors import label_color\n",
        "#from keras_retinanet.utils.gpu import setup_gpu\n",
        "\n",
        "# use this to change which GPU to use\n",
        "gpu = 0\n",
        "\n",
        "# set the modified tf session as backend in keras\n",
        "#setup_gpu(gpu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "collapsed": true,
        "id": "Kw108sLJTmPO",
        "outputId": "a91a2c5e-6d8c-45a9-dae1-f60e96d09d08"
      },
      "source": [
        "# 변환시킨 Inference 모델 로드하기\n",
        "import os\n",
        "import sys\n",
        "\n",
        "ROOT_DIR = '/content/DLCV/Detection/retina'\n",
        "\n",
        "model_path = os.path.join(ROOT_DIR, 'keras-retinanet/snapshots/raccoon_inference.h5')\n",
        "\n",
        "raccoon_retina_model = models.load_model(model_path,\n",
        "                                         backbone_name='resnet50')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-d0b7c6c74112>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m raccoon_retina_model = models.load_model(model_path,\n\u001b[0;32m---> 10\u001b[0;31m                                          backbone_name='resnet50')\n\u001b[0m",
            "\u001b[0;32m/root/.local/lib/python3.7/site-packages/keras_retinanet/models/__init__.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, backbone_name)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \"\"\"\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackbone_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mload_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_supported_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deserialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'write'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/io_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode)\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_is_path_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    406\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[1;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = '/content/DLCV/Detection/retina/keras-retinanet/snapshots/raccoon_inference.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AO3OQk1rUBbi"
      },
      "source": [
        "from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
        "from keras_retinanet.utils.visualization import draw_box, draw_caption\n",
        "from keras_retinanet.utils.colors import label_color\n",
        "\n",
        "labels_to_names_seq = {0: 'Raccoon'}\n",
        "\n",
        "def get_detected_image_retina(model, img_array, use_copied_array=True,\n",
        "                              is_print=True):\n",
        "  draw_img = None\n",
        "  if use_copied_array:\n",
        "    draw_img = img_array.copy()\n",
        "  else:\n",
        "    draw_img = img_array\n",
        "  \n",
        "  # 이미지 사전처리, scale, resize\n",
        "  img_array = preprocess_image(img_array)\n",
        "  img_array, scale = resize_image(img_array)\n",
        "\n",
        "  start = time.time()\n",
        "  # 해당 이미지에 대해 Object Detection 수행\n",
        "  boxes, scores, labels = model.predict_on_batch(np.expand_dims(img_array,\n",
        "                                                                axis=0))\n",
        "  if is_print:\n",
        "    print(\"Object Detection 처리 시간:\", round(time.time() - start, 5))\n",
        "  \n",
        "  # 좌표를 원래 크기로 변환\n",
        "  boxes /= scale\n",
        "\n",
        "  for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
        "    # score는 높은 순으로 내림차순 정렬되어 있음\n",
        "    if score < 0.5:\n",
        "      break\n",
        "    \n",
        "    # 클래스별 바운딩 박스 색깔 설정\n",
        "    color = label_color(label)\n",
        "    # 좌표 int 형으로 변환\n",
        "    b = box.astype(int)\n",
        "    caption = f\"{labels_to_names_seq[label]}-{score :.3f}\"\n",
        "    # 박스, 캡션 씌우기\n",
        "    draw_box(draw_img, b, color=color)\n",
        "    draw_caption(draw_img, b, caption)\n",
        "\n",
        "  if is_print:\n",
        "    print(\"이미지 processing 시산:\", round(time.time() - start, 5))\n",
        "  \n",
        "  return draw_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQwG_Es4XWtK"
      },
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "#HOME_DIR = str(Path.home())\n",
        "# 코랩 버전 수정\n",
        "HOME_DIR = '/content'\n",
        "ANNO_DIR = os.path.join(HOME_DIR, 'DLCV/data/raccoon/annotations')\n",
        "IMAGE_DIR = os.path.join(HOME_DIR, 'DLCV/data/raccoon/images')\n",
        "\n",
        "img_array  = cv2.imread(os.path.join(IMAGE_DIR, 'raccoon-22.jpg'))\n",
        "draw_img_array = img_array.copy()\n",
        "draw_img_array = cv2.cvtColor(draw_img_array, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "plt.figure(figsize=(15, 15))\n",
        "plt.axis('off')\n",
        "plt.imshow(draw_img_array)\n",
        "plt.show()\n",
        "\n",
        "detected_image = get_detected_image_retina(raccoon_retina_model, img_array, use_copied_array=True, is_print=True)\n",
        "img_rgb = cv2.cvtColor(detected_image, cv2.COLOR_BGR2RGB)\n",
        "plt.figure(figsize=(15, 15))\n",
        "plt.axis('off')\n",
        "plt.imshow(img_rgb)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGv3QwJSYPu9"
      },
      "source": [
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "\n",
        "# 모든 이미지 파일중에서 임의의 16개 파일만 설정. \n",
        "all_image_files = glob.glob(IMAGE_DIR + '/*.jpg')\n",
        "all_image_files = np.array(all_image_files)\n",
        "file_cnt = all_image_files.shape[0]\n",
        "show_cnt = 16\n",
        "\n",
        "show_indexes = np.random.choice(file_cnt, show_cnt)\n",
        "show_files = all_image_files[show_indexes]\n",
        "print(show_files)\n",
        "fig, axs = plt.subplots(figsize=(24,24) , ncols=4 , nrows=4)\n",
        "\n",
        "for i , filename in enumerate(show_files):\n",
        "    print(filename)\n",
        "    row = int(i/4)\n",
        "    col = i%4\n",
        "    img_array = cv2.imread(os.path.join(IMAGE_DIR, filename))\n",
        "    detected_image = get_detected_image_retina(raccoon_retina_model,img_array, use_copied_array=True, is_print=True)\n",
        "    img_rgb = cv2.cvtColor(detected_image, cv2.COLOR_BGR2RGB)\n",
        "    axs[row][col].imshow(img_rgb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nf2gLj9uYWCD"
      },
      "source": [
        "## Video Object Detection\n",
        "\n",
        "- 라쿤 데이터셋으로 재학습시킨 모델로 Video Object Detection 수행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XW_NooFoYVON"
      },
      "source": [
        "def detect_video_retina(model, input_path, output_path=''):\n",
        "  start = time.time()\n",
        "  # VideoCapture\n",
        "  cap = cv2.VideoCapture(input_path)\n",
        "  # 코덱, FPS, 프레임 사이즈, VideoWriter\n",
        "  codec = cv2.VideoWriter_fourcc(*'XVID')\n",
        "  vid_fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "  vid_size = (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
        "              int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
        "  vid_writer = cap.VideoWriter(output_path,\n",
        "                               code,\n",
        "                               vid_fps,\n",
        "                               vid_size)\n",
        "  frame_cnt = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "  print(\"총 프레임 수:\", frame_cnt)\n",
        "\n",
        "  # 한 프레임씩 Object Detection 수행하고 write 하기!\n",
        "  while True:\n",
        "    hasFrame, imgFrame = cap.read()\n",
        "    if not hasFrame:\n",
        "      print(\"더 이상 처리할 프레임이 없습니다!\")\n",
        "      break\n",
        "    \n",
        "    detected_frame = get_detected_image_retina(model, imgFrame)\n",
        "    vid_writer.write(detected_frame)\n",
        "  \n",
        "  vid_writer.release()\n",
        "  cap.release()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-BBCRK5ZrJn"
      },
      "source": [
        "## Keras-RetinaNet 성능 Evaluate 하기\n",
        "\n",
        "- 라쿤 데이터셋으로 재학습시키고 Inference용으로 변환한 모델로 성능평가하기\n",
        "- ``evlauate``할 때는 무조건 Inference 용 모델을 사용해야만 함"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZ0jLTdgZk2H"
      },
      "source": [
        "from keras_retinanet.bin.evaluate import create_generator as eval_create_generator\n",
        "\n",
        "HOME_DIR = '/content'\n",
        "ANNO_DIR = os.path.join(HOME_DIR, 'DLCV/data/raccoon/annotations')\n",
        "\n",
        "class args:\n",
        "    dataset_type='csv'\n",
        "    score_threshold=0.05\n",
        "    iou_threshold=0.5\n",
        "    max_detections=100\n",
        "    image_min_side=800\n",
        "    image_max_side=1333\n",
        "    config=None\n",
        "    annotations=os.path.join(ANNO_DIR, 'raccoon_anno_retina_valid.csv')\n",
        "    classes=os.path.join(ANNO_DIR, 'raccoon_class.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoOoxOCwZ2Sf"
      },
      "source": [
        "# args 인자 집어넣기\n",
        "generator = eval_create_generator(args)\n",
        "\n",
        "from keras_retinanet.utils.eval import evaluate\n",
        "\n",
        "average_precisions = evaluate(generator,\n",
        "                              raccoon_retina_model,\n",
        "                              iou_threshold=args.iou_threshold,\n",
        "                              score_threshold=args.score_threshold,\n",
        "                              max_detections=args.max_detections)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmxSBjTFafw1"
      },
      "source": [
        "# print evaluation\n",
        "total_instances = []\n",
        "precisions = []\n",
        "for label, (average_precision, num_annotations) in average_precisions.items():\n",
        "    print('{:.0f} instances of class'.format(num_annotations),\n",
        "          generator.label_to_name(label), 'with average precision: {:.4f}'.format(average_precision))\n",
        "    total_instances.append(num_annotations)\n",
        "    precisions.append(average_precision)\n",
        "\n",
        "if sum(total_instances) == 0:\n",
        "    print('No test instances found.')\n",
        "\n",
        "#print('Inference time for {:.0f} images: {:.4f}'.format(generator.size(), inference_time))\n",
        "\n",
        "print('mAP using the weighted average of precisions among classes: {:.4f}'.format(sum([a * b for a, b in zip(total_instances, precisions)]) / sum(total_instances)))\n",
        "print('mAP: {:.4f}'.format(sum(precisions) / sum(x > 0 for x in total_instances)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}