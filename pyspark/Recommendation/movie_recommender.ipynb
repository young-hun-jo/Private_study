{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "os.chdir('/Users/younghun/Desktop/gitrepo/data/movie_dataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import random \n",
    "\n",
    "# Pyspark Library #\n",
    "# SQL\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import mean, col, split, regexp_extract, when, lit\n",
    "# ML\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, IndexToString\n",
    "from pyspark.ml.feature import QuantileDiscretizer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스파크 세션 만들기\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName('recommender_system')\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ``Pyspark.toPandas()``메소드는 Spark의 DataFrame 자료구조를 Pandas의 테이블 모습으로 보여주도록 해줌!\n",
    "<br><br>\n",
    "- ``inferSchema=True``: 해당 csv파일 내부에 존재하는 헤더(스키마)를 알아서 캐치하여 반환\n",
    "- ``header=True``: 헤더(스키마)가 있다고 알려주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(os.getcwd() + '/movie_ratings_df.csv',\n",
    "                   inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ``limit(), select(), show()`` => 데이터 미리보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Three Colors: Red</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>Three Colors: Red</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>Three Colors: Red</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId              title  rating\n",
       "0       1  Three Colors: Red     1.0\n",
       "1      11  Three Colors: Red     3.5\n",
       "2      22  Three Colors: Red     5.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 유저에 대한 정보가 주어졌을 때, 유저가 볼 만한 영화를 추천해주자!\n",
    "- ``printSchema()``로 테이블의 스키마 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- title 변수명이 string으로 되어 있기 때문에 MLLib을 이용해서 수치형 값으로 convert하기\n",
    "- ``StringIndexer(inputCol='변환할 칼럼명', outputCol='변환후 생성할 칼럼명')`` => 이 객체를 ``fit, transform``메소드에 dataframe 넣어주기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert string to numeric value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "      <th>title_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Three Colors: Red</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>Three Colors: Red</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>Three Colors: Red</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>Three Colors: Red</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>Three Colors: Red</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId              title  rating  title_new\n",
       "0       1  Three Colors: Red     1.0        6.0\n",
       "1      11  Three Colors: Red     3.5        6.0\n",
       "2      22  Three Colors: Red     5.0        6.0\n",
       "3      24  Three Colors: Red     5.0        6.0\n",
       "4      29  Three Colors: Red     3.0        6.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stringIndexer = StringIndexer(inputCol='title',\n",
    "                             outputCol='title_new')\n",
    "model = stringIndexer.fit(df)\n",
    "indexed = model.transform(df)\n",
    "indexed.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build recommender-system - ALS(Alternate Least Squares)\n",
    "\n",
    "- ``regParam``: 데이터셋의 크기에 의존하지 않고 추천 시스템의 일반화를 시켜주기 위한 정규화 항\n",
    "- ``coldStartStrategy``: 아직 평가되지 않은 즉, 결측치(NaN)값을 갖는 row들을 제외하고 모델 성능이 평가됨(``drop``)\n",
    "    * Train 데이터에는 있지만 Test에는 존재하지 않는 즉, 새로운 유저나 제품이 출시되었을 때, 이에 대한 히스토리가 없어서 평점이 없는 Cold Start문제가 발생하는 것에 대한 대응 방법\n",
    "    * ``nan``방법도 있는데, 이는 결측치를 포함해서 모델 성능 평가\n",
    "- ``nonnegative=True``: least squares 할 때 음수(-)값이 미포함되어 있는 제한사항을 줄 것인지 -> **평점과 영화제목, 유저아이디는 모두 음수값이 없기** 때문에 ``True``로!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function JavaWrapper.__del__ at 0x7fadb20aa830>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/apache-spark/3.0.1/libexec/python/pyspark/ml/wrapper.py\", line 42, in __del__\n",
      "    if SparkContext._active_spark_context and self._java_obj is not None:\n",
      "AttributeError: 'ALS' object has no attribute '_java_obj'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "      <th>title_new</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1829</td>\n",
       "      <td>Yesterday</td>\n",
       "      <td>2.5</td>\n",
       "      <td>148.0</td>\n",
       "      <td>2.160393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6466</td>\n",
       "      <td>Yesterday</td>\n",
       "      <td>4.5</td>\n",
       "      <td>148.0</td>\n",
       "      <td>3.411708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15447</td>\n",
       "      <td>Yesterday</td>\n",
       "      <td>3.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>3.053997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23364</td>\n",
       "      <td>Yesterday</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>3.635531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25591</td>\n",
       "      <td>Yesterday</td>\n",
       "      <td>5.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>2.422732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId      title  rating  title_new  prediction\n",
       "0    1829  Yesterday     2.5      148.0    2.160393\n",
       "1    6466  Yesterday     4.5      148.0    3.411708\n",
       "2   15447  Yesterday     3.0      148.0    3.053997\n",
       "3   23364  Yesterday     4.0      148.0    3.635531\n",
       "4   25591  Yesterday     5.0      148.0    2.422732"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = indexed.randomSplit([0.75, 0.25])\n",
    "# ALS recommender algorithm\n",
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "rec = ALS(maxIter=10,\n",
    "         regParam=0.01,\n",
    "         userCol='userId',\n",
    "         itemCol='title_new',\n",
    "         ratingCol='rating', # label -> predict할 때는 필요 없음!\n",
    "         nonnegative=True,\n",
    "         coldStartStrategy='drop')\n",
    "# ALS모델 학습 -> dataframe을 넣어주기\n",
    "rec_model = rec.fit(train)\n",
    "\n",
    "# transform을 이용해 예측 -> dataframe을 넣어주기\n",
    "pred_ratings = rec_model.transform(test)\n",
    "pred_ratings.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9037694696632295\n"
     ]
    }
   ],
   "source": [
    "# Get metric for training\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol='rating',\n",
    "                               predictionCol='prediction',\n",
    "                               metricName='rmse')\n",
    "# evaluate 메소드에 예측값 담겨있는 dataframe 넣어주기\n",
    "rmse = evaluator.evaluate(pred_ratings)\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.6877014610850091\n"
     ]
    }
   ],
   "source": [
    "mae_eval = RegressionEvaluator(labelCol='rating',\n",
    "                              predictionCol='prediction',\n",
    "                              metricName='mae')\n",
    "mae = mae_eval.evaluate(pred_ratings)\n",
    "print(\"MAE:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- rating에 대한 정답과 예측차이의 평균 ``RMSE``값이 0.9이다.\n",
    "- rating에 대한 정답과 예측차이의 평균 ``MAE``값이 0.68이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 특정 사용자가 좋아할만한 영화 추천해주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|title_new|\n",
      "+---------+\n",
      "|    305.0|\n",
      "|    596.0|\n",
      "|    769.0|\n",
      "|    496.0|\n",
      "|    299.0|\n",
      "+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None <class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# 숫자로 바꾼 영화제목들 중 Unique한 값들만 담아 추출하기 -> Dataframe 반환\n",
    "unique_movies = indexed.select(\"title_new\").distinct()\n",
    "print(unique_movies.show(5), type(unique_movies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pyspark에서 Column 이름을 rename하는 방법들\n",
    "    * ``withColumnRenamed``: ``df.withColumnRenamed('변경 전', '변경 후')\n",
    "    * ``toDF``: 한 번에 칼럼명을 바꾸는 방법. 순차적으로 입력.이 방법은 다른 방법보다 매우 느림.``df.toDF('바꿀변수명1', '바꿀변수명2', ...)``\n",
    "    * ``alias``: ``df.select(col('기존 변수명').alias('변경 후 변수명'))``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pyspark에서 ``filter``의 역할(``where``과 기능 동일)\n",
    "    * ``df.filter(condition)``\n",
    "        * condition에 Pyspark문법으로 구성된 조건을 넣어도 되고 SQL문도 넣어도 수행됨\n",
    "        * 2개 이상의 condition 넣어줄 때는 ``논리 연산자(&, |)`` 사용 가능\n",
    "        * ``array_contains(df.column, 'value')``을 넣어주어 Array에서 특정 value를 갖는 row들 추출 가능\n",
    "        * nested(중첩)된 변수들 일때도 사용 가능 ex)name 칼럼안에 lastname 칼럼이 있다 => ``df.name.lastname == 'John'`` 식으로 가능!\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pyspark에서 ``lit()``의 역할\n",
    "    * 데이터프레임에 문자열이나 상수값을 할당하면서 새로운 칼럼을 만들기 위함\n",
    "    * 칼럼 type으로 반환\n",
    "    * ``lit(value).alias('변수명')``: value값을 동일하게 할당하면서 만들어 '변수명'으로 칼럼이름 지정\n",
    "    * ``df2.withColumn('lit_value2', when(col('Salary') >=400 & col('Salary') <= 500, lit('100')).otherwise(lit('200'))``: lit_value2라는 새로운 변수를 만드는데, 400 <= Salary 변수값 <= 500일때는 lit_value2변수에 100값을, 그렇지 않으면 200값을 넣어라!\n",
    "<br><br>\n",
    "- Pyspark에서 ``typedLit()``의 역할\n",
    "    * ``lit()``과는 다르게 **Array, Dict**처럼 collection type을 다룰 수 있음\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_movies(user_id, n):\n",
    "    \"\"\"\n",
    "    특정 user_id가 좋아할 만한 n개의 영화 추천해주는 함수\n",
    "    \"\"\"\n",
    "    # unique_movies 데이터프레임을 'a'라는 데이터프레임으로 alias시키기\n",
    "    a = unique_movies.alias('a')\n",
    "    \n",
    "    # 특정 user_id가 본 영화들만 담은 새로운 데이터프레임 생성\n",
    "    watched_movies = indexed.filter(indexed['userId'] == user_id)\\\n",
    "                            .select('title_new')\n",
    "    \n",
    "    # 특정 user_id가 본 영화들을 'b'라는 데이터프레임으로 alias시키기\n",
    "    b = watched_movies.alias('b')\n",
    "    \n",
    "    # unique_movies를 기준으로 watched_movies를 조인시켜서 user_id가 보지 못한 영화들 파악 가능\n",
    "    total_movies = a.join(b, a['title_new'] == b['title_new'],\n",
    "                         how='left')\n",
    "    \n",
    "    # b 데이터프레임의 title_new값이 결측치를 갖고 있는 행의 a.title_new를 뽑아냄으로써 user_id가 아직 못본 영화들 추출\n",
    "    # col('b.title_new') => b 데이터프레임의 title_new칼럼 의미(SQL처럼 가능!)\n",
    "    remaining_movies = total_movies\\\n",
    "                       .where(col('b.title_new').isNull())\\\n",
    "                       .select('a.title_new').distinct()\n",
    "    # remaining_movies 데이터프레임에 특정 user_id값을 동일하게 새로운 변수로 추가해주기\n",
    "    remaining_movies = remaining_movies.withColumn('userId',\n",
    "                                                  lit(int(user_id)))\n",
    "    # 위에서 만든 ALS 모델을 사용하여 추천 평점 예측 후 n개 만큼 view -> \n",
    "    recommender = rec_model.transform(remaining_movies)\\\n",
    "                           .orderBy('prediction', ascending=False)\\\n",
    "                           .limit(n)\n",
    "    # StringIndexer로 만든 것을 역으로 바꾸기 위해 IndexToString사용(영화제목을 숫자->한글제목)\n",
    "    movie_title = IndexToString(inputCol='title_new',\n",
    "                               outputCol='title',\n",
    "                               labels=model.labels) #여기서 model.labels는 StringIndexer에서 fit시켰을 때 생긴 레이블. 즉, 영화 제목들\n",
    "    # transform해서 영화제목을 숫자->한글로 변환! => dataframe으로 반환\n",
    "    final_recommendations = movie_title.transform(recommender)\n",
    "    \n",
    "    return final_recommendations.show(n, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+----------+------------------------------+\n",
      "|title_new|userId|prediction|title                         |\n",
      "+---------+------+----------+------------------------------+\n",
      "|6725.0   |1829  |17.840975 |Some Kind of a Nut            |\n",
      "|6852.0   |1829  |15.735489 |Way Beyond Weight             |\n",
      "|6227.0   |1829  |12.143332 |Exterminators of the Year 3000|\n",
      "|5821.0   |1829  |10.902253 |Insidious: Chapter 2          |\n",
      "|6016.0   |1829  |10.588577 |I Can Do Bad All By Myself    |\n",
      "+---------+------+----------+------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_movies(1829, 5)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
