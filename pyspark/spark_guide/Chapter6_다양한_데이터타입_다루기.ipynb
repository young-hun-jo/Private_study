{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "native-executive",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#스파크-데이터-타입으로-변환\" data-toc-modified-id=\"스파크-데이터-타입으로-변환-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>스파크 데이터 타입으로 변환</a></span></li><li><span><a href=\"#Boolean-데이터-타입-다루기\" data-toc-modified-id=\"Boolean-데이터-타입-다루기-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Boolean 데이터 타입 다루기</a></span></li><li><span><a href=\"#수치형-데이터-타입-다루기\" data-toc-modified-id=\"수치형-데이터-타입-다루기-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>수치형 데이터 타입 다루기</a></span></li><li><span><a href=\"#문자열-데이터-타입-다루기\" data-toc-modified-id=\"문자열-데이터-타입-다루기-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>문자열 데이터 타입 다루기</a></span><ul class=\"toc-item\"><li><span><a href=\"#문자열---정규표현식\" data-toc-modified-id=\"문자열---정규표현식-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>문자열 - 정규표현식</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "regular-joining",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mall\u001b[m\u001b[m    \u001b[1m\u001b[36mby-day\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls /Users/younghun/Desktop/gitrepo/data/spark_perfect_guide/retail-data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "forward-closer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: string (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- CustomerID: double (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format('csv')\\\n",
    "     .option('header', 'true')\\\n",
    "     .option('inferSchema', 'true')\\\n",
    "     .load('/Users/younghun/Desktop/gitrepo/data/spark_perfect_guide/retail-data/by-day/2010-12-01.csv')\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bizarre-touch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 트랜스포메이션 결과를 확인하기 위해 임시테이블인 뷰로 등록\n",
    "df.createOrReplaceTempView('dfTable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "gentle-progressive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|2010-12-01 08:26:00|     2.55|   17850.0|United Kingdom|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
      "|   536365|   84406B|CREAM CUPID HEART...|       8|2010-12-01 08:26:00|     2.75|   17850.0|United Kingdom|\n",
      "|   536365|   84029G|KNITTED UNION FLA...|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
      "|   536365|   84029E|RED WOOLLY HOTTIE...|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indonesian-pregnancy",
   "metadata": {},
   "source": [
    "## 스파크 데이터 타입으로 변환\n",
    "- 스파크 자체 데이터 타입으로 변환시키기 위해 ``lit`` 함수를 분명히 기억!!\n",
    "    * ``lit``은 다른 언어의 데이터 타입을 스파크 데이터 타입에 맞게 변환함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efficient-divide",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---+\n",
      "|  5|five|5.0|\n",
      "+---+----+---+\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "+---+----+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "test = df.select(lit(5), lit('five'), lit(5.0))\n",
    "test.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polyphonic-friendship",
   "metadata": {},
   "source": [
    "## Boolean 데이터 타입 다루기\n",
    "- Boolean은 로우를 필터링할 때 매우 자주 사용됨\n",
    "- 주로 조건문이 일치하면 True, 일치하지 않으면 False로 반환시켜 필터링 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "convinced-container",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|2010-12-01 08:26:00|     2.55|   17850.0|United Kingdom|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "rational-terror",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------------------+\n",
      "|InvoiceNo|Description                  |\n",
      "+---------+-----------------------------+\n",
      "|536366   |HAND WARMER UNION JACK       |\n",
      "|536366   |HAND WARMER RED POLKA DOT    |\n",
      "|536367   |ASSORTED COLOUR BIRD ORNAMENT|\n",
      "|536367   |POPPY'S PLAYHOUSE BEDROOM    |\n",
      "|536367   |POPPY'S PLAYHOUSE KITCHEN    |\n",
      "+---------+-----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df.where(col('InvoiceNo') != 536365)\\\n",
    "  .select(\"InvoiceNo\", \"Description\")\\\n",
    "  .show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "exciting-disco",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------------------+\n",
      "|InvoiceNo|Description                  |\n",
      "+---------+-----------------------------+\n",
      "|536366   |HAND WARMER UNION JACK       |\n",
      "|536366   |HAND WARMER RED POLKA DOT    |\n",
      "|536367   |ASSORTED COLOUR BIRD ORNAMENT|\n",
      "|536367   |POPPY'S PLAYHOUSE BEDROOM    |\n",
      "|536367   |POPPY'S PLAYHOUSE KITCHEN    |\n",
      "+---------+-----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(col('InvoiceNo') != 536365)\\\n",
    "  .selectExpr(\"InvoiceNo\",\"Description\")\\\n",
    "  .show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "exposed-frequency",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------------------+\n",
      "|InvoiceNo|Description                  |\n",
      "+---------+-----------------------------+\n",
      "|536366   |HAND WARMER UNION JACK       |\n",
      "|536366   |HAND WARMER RED POLKA DOT    |\n",
      "|536367   |ASSORTED COLOUR BIRD ORNAMENT|\n",
      "|536367   |POPPY'S PLAYHOUSE BEDROOM    |\n",
      "|536367   |POPPY'S PLAYHOUSE KITCHEN    |\n",
      "+---------+-----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "# 문자열 표현식으로도 사용 가능\n",
    "df.where(\"InvoiceNo != 536365\")\\\n",
    "  .select(expr(\"InvoiceNo\"), expr(\"Description\"))\\\n",
    "  .show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exotic-disabled",
   "metadata": {},
   "source": [
    "- ``instr(string, substr)``: ``string`` 문자열에서 ``substr``이 시작하는 첫 번째 인덱스를 반환(단, **Pyspark에서 문자열 index 번호는 1부터 시작!**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fancy-princeton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|   Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n",
      "|   536544|      DOT|DOTCOM POSTAGE|       1|2010-12-01 14:32:00|   569.77|      null|United Kingdom|\n",
      "|   536592|      DOT|DOTCOM POSTAGE|       1|2010-12-01 17:06:00|   607.49|      null|United Kingdom|\n",
      "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 여러가지 필터링 조건\n",
    "from pyspark.sql.functions import instr\n",
    "\n",
    "priceFilter = col('UnitPrice') > 600\n",
    "descriFilter = instr(df.Description, 'POSTAGE') >= 1\n",
    "\n",
    "# 논리연산자 사용가능\n",
    "\"\"\"\n",
    "and로 필터추가하려면 연속적으로 where 구문 붙여서 하나의 문장으로 만들면 됨\n",
    "or(|)로 필터추가하려면 동일한 구문 조건 안에 넣어야 함(하단 참조)\n",
    "\"\"\"\n",
    "df.where(df.StockCode.isin(\"DOT\")).where(priceFilter | descriFilter).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tested-cradle",
   "metadata": {},
   "source": [
    "- ``select``시, 불리언 타입의 칼럼을 추출할 때는 자동으로 True인 값들만 추출함(Boolean Indexing 처럼!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "frequent-container",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|UnitPrice|isExpensive|\n",
      "+---------+-----------+\n",
      "|   569.77|       true|\n",
      "|   607.49|       true|\n",
      "+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 불리언 표현식을 사용해서 DF 필터링하기\n",
    "DOTCodeFilter = col('StockCode') == 'DOT'\n",
    "priceFilter = col('UnitPrice') >= 600\n",
    "descriFilter = instr(df.Description, 'POSTAGE') >= 1\n",
    "\n",
    "df.withColumn('isExpensive', DOTCodeFilter & (priceFilter | descriFilter))\\\n",
    "  .where('isExpensive')\\\n",
    "  .select('UnitPrice', 'isExpensive').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "white-bowling",
   "metadata": {},
   "source": [
    "- 위와 같이 필터조건을 표현식으로 작성해도 되지만 **칼럼명을 사용**해서도 작성할 수 있음\n",
    "    * 동작방식은 동일하기 때문에 표현식과 칼럼명 방법 사이의 속도 차이 존재 X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "little-lottery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------+\n",
      "|   Description|isExpensive|\n",
      "+--------------+-----------+\n",
      "|DOTCOM POSTAGE|       true|\n",
      "|DOTCOM POSTAGE|       true|\n",
      "+--------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "df.withColumn('isExpensive', expr('NOT UnitPrice <= 250'))\\\n",
    "  .where('isExpensive')\\\n",
    "  .select('Description', 'isExpensive').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automated-quarter",
   "metadata": {},
   "source": [
    "- 불리언 표현식을 만들 때 ``null`` 데이터는 어떻게 다루어야 할까?\n",
    "    * 다음과 같은 코드 수행\n",
    "- ``join``방법 중 ``left-anti join``이란 왼쪽 테이블에는 있으면서 오른쪽 테이블에는 없는 row들만 남김"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "robust-insured",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "|InvoiceNo|StockCode|Description|Quantity|InvoiceDate|UnitPrice|CustomerID|Country|\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(col('Description').eqNullSafe('hello')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressed-conditioning",
   "metadata": {},
   "source": [
    "- ``eqNullSafe(df.column)`` 메소드는 결측치를 없는 데이터로 간주함!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiac-idaho",
   "metadata": {},
   "source": [
    "## 수치형 데이터 타입 다루기\n",
    "- ``pow``를 활용해 거듭제곱 계산 가능(=Native Python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "designing-survivor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|CustomerId|      realQuantity|\n",
      "+----------+------------------+\n",
      "|   17850.0|239.08999999999997|\n",
      "|   17850.0|          418.7156|\n",
      "|   17850.0|             489.0|\n",
      "|   17850.0|          418.7156|\n",
      "|   17850.0|          418.7156|\n",
      "+----------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr, pow\n",
    "\n",
    "fabricatedQuantity = pow(col('Quantity')*col('UnitPrice'), 2) + 5 # Column으로 반환됨\n",
    "df.select(expr('CustomerId'), fabricatedQuantity.alias('realQuantity')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fuzzy-eugene",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|CustomerId|      realQuantity|\n",
      "+----------+------------------+\n",
      "|   17850.0|239.08999999999997|\n",
      "|   17850.0|          418.7156|\n",
      "|   17850.0|             489.0|\n",
      "|   17850.0|          418.7156|\n",
      "|   17850.0|          418.7156|\n",
      "+----------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL 구문으로도 가능\n",
    "df.selectExpr(\"CustomerId\",\n",
    "             \"(POWER((Quantity * UnitPrice), 2) + 5) as realQuantity\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjacent-functionality",
   "metadata": {},
   "source": [
    "- 반올림 메소드: ``round()``\n",
    "- 내림 메소드: ``bround()``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "tested-palestine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+\n",
      "|round(2.5, 0)|bround(2.5, 0)|\n",
      "+-------------+--------------+\n",
      "|          3.0|           2.0|\n",
      "|          3.0|           2.0|\n",
      "|          3.0|           2.0|\n",
      "|          3.0|           2.0|\n",
      "|          3.0|           2.0|\n",
      "+-------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit, round, bround\n",
    "\n",
    "# lit으로 스파크 자체 데이터 타입으로 변경\n",
    "df.select(round(lit(2.5)), bround(lit(2.5))).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broadband-squad",
   "metadata": {},
   "source": [
    "- 두 수치형 변수간의 ``Pearson Correlation`` 계산하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "crude-peoples",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.04112314436835551"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import corr\n",
    "\n",
    "df.stat.corr('Quantity', 'UnitPrice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "linear-biotechnology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|corr(Quantity, UnitPrice)|\n",
      "+-------------------------+\n",
      "|     -0.04112314436835551|\n",
      "+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(corr('Quantity', 'UnitPrice')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "traditional-insider",
   "metadata": {},
   "source": [
    "- 하나 이상의 수치형 칼럼에 대한 요약 통계 계산 방법\n",
    "    * ``describe()`` 메서드 사용. 단, 통계 스키마가 변경될 수도 있으니 콘솔용에서 확인 가능\n",
    "    * 정확한 통계수치를 보기 위해서는 통계 요약값 계산 메소드를 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "backed-environment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+--------------------+------------------+-------------------+------------------+------------------+--------------+\n",
      "|summary|        InvoiceNo|         StockCode|         Description|          Quantity|        InvoiceDate|         UnitPrice|        CustomerID|       Country|\n",
      "+-------+-----------------+------------------+--------------------+------------------+-------------------+------------------+------------------+--------------+\n",
      "|  count|             3108|              3108|                3098|              3108|               3108|              3108|              1968|          3108|\n",
      "|   mean| 536516.684944841|27834.304044117645|                null| 8.627413127413128|               null| 4.151946589446603|15661.388719512195|          null|\n",
      "| stddev|72.89447869788873|17407.897548583845|                null|26.371821677029203|               null|15.638659854603892|1854.4496996893627|          null|\n",
      "|    min|           536365|             10002| 4 PURPLE FLOCK D...|               -24|2010-12-01 08:26:00|               0.0|           12431.0|     Australia|\n",
      "|    max|          C536548|              POST|ZINC WILLIE WINKI...|               600|2010-12-01 17:35:00|            607.49|           18229.0|United Kingdom|\n",
      "+-------+-----------------+------------------+--------------------+------------------+-------------------+------------------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "occupational-improvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count, max, min, mean, stddev_pop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposed-ownership",
   "metadata": {},
   "source": [
    "- StatFunctions 패키지 활용해서도 가능. ``stat``속성으로 접근해서 사용가능한 DataFrame 메서드\n",
    "    * ex) ``approxQuantile(column, probability, relativeError)``\n",
    "        - ``probability``: 백분위(list/tuple)\n",
    "        - ``relativeError``: 목표값과 얼마만큼의 에러차이를 허용할 것인지(만약 0으로 설정시 목표치와 매우 근사하지만 연산 비용이 많이듬(expensive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "angry-workshop",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.51]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.stat.approxQuantile('UnitPrice', [0.5], 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assigned-broadway",
   "metadata": {},
   "source": [
    "- StatFunctions는 ``crosstab``(교차표) 기능도 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-camping",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.stat.crosstab('StockCode', 'Quantity').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "numeric-oklahoma",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "| StockCode_freqItems|  Quantity_freqItems|\n",
      "+--------------------+--------------------+\n",
      "|[90214E, 20728, 2...|[200, 128, 23, 32...|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.stat.freqItems(['StockCode', 'Quantity']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thrown-psychology",
   "metadata": {},
   "source": [
    "- StatFunctions의 ``monotonically_increasing_id()``: 모든 로우에 unique한 ID값을 만들어줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "atlantic-outreach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+\n",
      "|monotonically_increasing_id()|\n",
      "+-----------------------------+\n",
      "|                            0|\n",
      "|                            1|\n",
      "|                            2|\n",
      "|                            3|\n",
      "|                            4|\n",
      "+-----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "\n",
    "df.select(monotonically_increasing_id()).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "architectural-tamil",
   "metadata": {},
   "source": [
    "- 이외 StatFunctions에는 다양한 고급 알고리즘 메소드도 제공을 함. 필요 시 공식문서 참조하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upper-tenant",
   "metadata": {},
   "source": [
    "## 문자열 데이터 타입 다루기\n",
    "\n",
    "- ``initcap``: 주어진 문자열에서 공백으로 나뉘는 모든 단어의 첫 글자를 대문자로 변경\n",
    "- ``upper``: 모든 문자를 대문자로\n",
    "- ``lower``: 모든 문자를 소문자로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "protective-leadership",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+\n",
      "|initcap(Description)               |\n",
      "+-----------------------------------+\n",
      "|White Hanging Heart T-light Holder |\n",
      "|White Metal Lantern                |\n",
      "|Cream Cupid Hearts Coat Hanger     |\n",
      "|Knitted Union Flag Hot Water Bottle|\n",
      "|Red Woolly Hottie White Heart.     |\n",
      "+-----------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import initcap\n",
    "\n",
    "df.select(initcap(col('Description'))).show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "through-customer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+-----------------------------------+-----------------------------------+\n",
      "|Description                        |lower(Description)                 |upper(Description)                 |\n",
      "+-----------------------------------+-----------------------------------+-----------------------------------+\n",
      "|WHITE HANGING HEART T-LIGHT HOLDER |white hanging heart t-light holder |WHITE HANGING HEART T-LIGHT HOLDER |\n",
      "|WHITE METAL LANTERN                |white metal lantern                |WHITE METAL LANTERN                |\n",
      "|CREAM CUPID HEARTS COAT HANGER     |cream cupid hearts coat hanger     |CREAM CUPID HEARTS COAT HANGER     |\n",
      "|KNITTED UNION FLAG HOT WATER BOTTLE|knitted union flag hot water bottle|KNITTED UNION FLAG HOT WATER BOTTLE|\n",
      "|RED WOOLLY HOTTIE WHITE HEART.     |red woolly hottie white heart.     |RED WOOLLY HOTTIE WHITE HEART.     |\n",
      "+-----------------------------------+-----------------------------------+-----------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import upper, lower\n",
    "\n",
    "df.select(col('Description'),\n",
    "         lower(col('Description')),\n",
    "         upper(col('Description'))).show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recovered-scientist",
   "metadata": {},
   "source": [
    "- 공백 제거하거나 추가하는 작업도 가능\n",
    "    * ``ltrim, rtrim, lpad, rpad, trim``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "commercial-chart",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+------------------+------------------+\n",
      "|ltrim(  HELLO  )|rtrim(  HELLO  )|lpad(HELLO, 15, #)|rpad(HELLO, 15, $)|\n",
      "+----------------+----------------+------------------+------------------+\n",
      "|         HELLO  |           HELLO|   ##########HELLO|   HELLO$$$$$$$$$$|\n",
      "|         HELLO  |           HELLO|   ##########HELLO|   HELLO$$$$$$$$$$|\n",
      "|         HELLO  |           HELLO|   ##########HELLO|   HELLO$$$$$$$$$$|\n",
      "|         HELLO  |           HELLO|   ##########HELLO|   HELLO$$$$$$$$$$|\n",
      "|         HELLO  |           HELLO|   ##########HELLO|   HELLO$$$$$$$$$$|\n",
      "|         HELLO  |           HELLO|   ##########HELLO|   HELLO$$$$$$$$$$|\n",
      "|         HELLO  |           HELLO|   ##########HELLO|   HELLO$$$$$$$$$$|\n",
      "|         HELLO  |           HELLO|   ##########HELLO|   HELLO$$$$$$$$$$|\n",
      "|         HELLO  |           HELLO|   ##########HELLO|   HELLO$$$$$$$$$$|\n",
      "|         HELLO  |           HELLO|   ##########HELLO|   HELLO$$$$$$$$$$|\n",
      "|         HELLO  |           HELLO|   ##########HELLO|   HELLO$$$$$$$$$$|\n",
      "|         HELLO  |           HELLO|   ##########HELLO|   HELLO$$$$$$$$$$|\n",
      "|         HELLO  |           HELLO|   ##########HELLO|   HELLO$$$$$$$$$$|\n",
      "|         HELLO  |           HELLO|   ##########HELLO|   HELLO$$$$$$$$$$|\n",
      "|         HELLO  |           HELLO|   ##########HELLO|   HELLO$$$$$$$$$$|\n",
      "|         HELLO  |           HELLO|   ##########HELLO|   HELLO$$$$$$$$$$|\n",
      "|         HELLO  |           HELLO|   ##########HELLO|   HELLO$$$$$$$$$$|\n",
      "|         HELLO  |           HELLO|   ##########HELLO|   HELLO$$$$$$$$$$|\n",
      "|         HELLO  |           HELLO|   ##########HELLO|   HELLO$$$$$$$$$$|\n",
      "|         HELLO  |           HELLO|   ##########HELLO|   HELLO$$$$$$$$$$|\n",
      "+----------------+----------------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit, ltrim, rtrim, lpad, rpad, trim\n",
    "\n",
    "hello_col = lit('  HELLO  ')\n",
    "df.select(ltrim(hello_col),\n",
    "         rtrim(hello_col),\n",
    "         lpad(lit('HELLO'), 15, '#'),\n",
    "         rpad(lit('HELLO'), 15, '$')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprising-series",
   "metadata": {},
   "source": [
    "### 문자열 - 정규표현식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-button",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
