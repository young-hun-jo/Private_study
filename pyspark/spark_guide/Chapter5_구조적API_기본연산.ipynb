{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "tropical-prior",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#스키마\" data-toc-modified-id=\"스키마-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>스키마</a></span></li><li><span><a href=\"#칼럼과-표현식\" data-toc-modified-id=\"칼럼과-표현식-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>칼럼과 표현식</a></span><ul class=\"toc-item\"><li><span><a href=\"#칼럼\" data-toc-modified-id=\"칼럼-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>칼럼</a></span></li><li><span><a href=\"#표현식\" data-toc-modified-id=\"표현식-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>표현식</a></span></li><li><span><a href=\"#레코드와-로우\" data-toc-modified-id=\"레코드와-로우-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>레코드와 로우</a></span></li></ul></li><li><span><a href=\"#DataFrame의-트랜스포메이션\" data-toc-modified-id=\"DataFrame의-트랜스포메이션-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>DataFrame의 트랜스포메이션</a></span><ul class=\"toc-item\"><li><span><a href=\"#데이터프레임-생성\" data-toc-modified-id=\"데이터프레임-생성-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>데이터프레임 생성</a></span></li><li><span><a href=\"#트랜스포메이션-종류\" data-toc-modified-id=\"트랜스포메이션-종류-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>트랜스포메이션 종류</a></span><ul class=\"toc-item\"><li><span><a href=\"#select-&amp;-selectExpr\" data-toc-modified-id=\"select-&amp;-selectExpr-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span><code>select</code> &amp; <code>selectExpr</code></a></span></li></ul></li><li><span><a href=\"#스파크-데이터-타입으로-변환하기\" data-toc-modified-id=\"스파크-데이터-타입으로-변환하기-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>스파크 데이터 타입으로 변환하기</a></span></li><li><span><a href=\"#칼럼-추가하기\" data-toc-modified-id=\"칼럼-추가하기-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>칼럼 추가하기</a></span></li><li><span><a href=\"#칼럼명-변경하기\" data-toc-modified-id=\"칼럼명-변경하기-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>칼럼명 변경하기</a></span><ul class=\"toc-item\"><li><span><a href=\"#예약-문자와-키워드\" data-toc-modified-id=\"예약-문자와-키워드-3.5.1\"><span class=\"toc-item-num\">3.5.1&nbsp;&nbsp;</span>예약 문자와 키워드</a></span></li></ul></li><li><span><a href=\"#대소문자-구분\" data-toc-modified-id=\"대소문자-구분-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>대소문자 구분</a></span></li><li><span><a href=\"#칼럼-제거하기\" data-toc-modified-id=\"칼럼-제거하기-3.7\"><span class=\"toc-item-num\">3.7&nbsp;&nbsp;</span>칼럼 제거하기</a></span></li><li><span><a href=\"#칼럼의-데이터-타입-변경하기\" data-toc-modified-id=\"칼럼의-데이터-타입-변경하기-3.8\"><span class=\"toc-item-num\">3.8&nbsp;&nbsp;</span>칼럼의 데이터 타입 변경하기</a></span></li><li><span><a href=\"#로우-필터링하기\" data-toc-modified-id=\"로우-필터링하기-3.9\"><span class=\"toc-item-num\">3.9&nbsp;&nbsp;</span>로우 필터링하기</a></span></li><li><span><a href=\"#고유한(unique)-로우-얻기\" data-toc-modified-id=\"고유한(unique)-로우-얻기-3.10\"><span class=\"toc-item-num\">3.10&nbsp;&nbsp;</span>고유한(unique) 로우 얻기</a></span></li><li><span><a href=\"#무작위-샘플-만들기\" data-toc-modified-id=\"무작위-샘플-만들기-3.11\"><span class=\"toc-item-num\">3.11&nbsp;&nbsp;</span>무작위 샘플 만들기</a></span></li><li><span><a href=\"#임의-분할하기\" data-toc-modified-id=\"임의-분할하기-3.12\"><span class=\"toc-item-num\">3.12&nbsp;&nbsp;</span>임의 분할하기</a></span></li><li><span><a href=\"#로우-합치기와-추가하기\" data-toc-modified-id=\"로우-합치기와-추가하기-3.13\"><span class=\"toc-item-num\">3.13&nbsp;&nbsp;</span>로우 합치기와 추가하기</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "lucky-heating",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "df = spark.read.format('json').load('/Users/younghun/Desktop/gitrepo/data/spark_perfect_guide/flight-data/json/2015-summary.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "inappropriate-volunteer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DEST_COUNTRY_NAME: string (nullable = true)\n",
      " |-- ORIGIN_COUNTRY_NAME: string (nullable = true)\n",
      " |-- count: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 스키마 살펴보기\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standing-firewall",
   "metadata": {},
   "source": [
    "# 스키마"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "academic-chamber",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(DEST_COUNTRY_NAME,StringType,true),StructField(ORIGIN_COUNTRY_NAME,StringType,true),StructField(count,LongType,true)))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.format('json').load('/Users/younghun/Desktop/gitrepo/data/spark_perfect_guide/flight-data/json/2015-summary.json').schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-movement",
   "metadata": {},
   "source": [
    "- 스키마를 출력한 결과\n",
    "    * ``StructType``이라는 리스트 안에 각 칼럼별로 ``StructField``가 담겨져 있음\n",
    "    * 즉, 스키마 = 여러개의 ``StructField`` 타입 필드로 구성된 ``StructType`` 객체\n",
    "- 데이터 타입과 스키마의 데이터 타입이 불일치하면 스파크에서는 오류 발생\n",
    "- 스파크에서는 자체 데이터 타입을 사용하므로 사용하는 언어 API(ex.Python, R 등)의 데이터 타입을 사용할 수 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suitable-rental",
   "metadata": {},
   "source": [
    "- 스키마 정의시 **메타 데이터**를 정의할 수도 있음\n",
    "    * **메타 데이터란, 해당 칼럼과 관련된 정보이며 추후 스파크의 머신러닝 라이브러리에서 사용함**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "informed-america",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임에 스키마를 만들고 적용하는 예제\n",
    "from pyspark.sql.types import StructField, StructType, StringType, LongType\n",
    "\n",
    "myManualSchema = StructType([\n",
    "    StructField('DEST_COUNTRY_NAME', StringType(), True),\n",
    "    StructField('ORIGIN_COUNTRY_NAME', StringType(), True),\n",
    "    StructField('count', LongType(), False, metadata={'hello': 'world'})\n",
    "])\n",
    "\n",
    "# 데이터 로드 시 스키마 정의\n",
    "df = spark.read.format('json').schema(myManualSchema)\\\n",
    "     .load('/Users/younghun/Desktop/gitrepo/data/spark_perfect_guide/flight-data/json/2015-summary.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bulgarian-tract",
   "metadata": {},
   "source": [
    "# 칼럼과 표현식\n",
    "- 표현식으로 데이터프레임의 칼럼을 선택, 조작, 제거 가능\n",
    "- 스파크의 칼럼은 표현식을 사용해 레코드(Row) 단위로 계산한 값을 단순하게 나타내는 논리적인 구조\n",
    "- 칼럼의 실제값을 얻으려면 레코드(Row)가 필요하고 레코드를 얻으려면 데이터프레임이 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swiss-lobby",
   "metadata": {},
   "source": [
    "## 칼럼\n",
    "\n",
    "- 칼럼을 생성, 참조할 수 있는 방법은 여러가지가 있지만 ``col()``이나 ``column()``을 사용하는 것이 가장 간단. 소괄호 인자에는 ``칼럼명``을 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "proud-slide",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b'someColumnName'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, column\n",
    "\n",
    "col('someColumnName')\n",
    "column('someColumnName')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assumed-portfolio",
   "metadata": {},
   "source": [
    "- 이 때 해당 칼럼이 로드한 DataFrame에 있는지 여부는 알 수 없음. 알려면 **카탈로그**에 저장된 정보와 비교해야 함. 그런데 이 비교하는 단계는 **분석기**가 트랜스포메이션으로 구성된 논리적실행계획을 검증 전/후로 가는 단계에 걸쳐있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legendary-posting",
   "metadata": {},
   "source": [
    "- 명시적 컬럼 참조. ``col()`` 사용. 이는 데이터프레임 조인 시 특정 칼럼을 참조하는 데 사용\n",
    "- 단, ``col()``을 사용해 명시적으로 컬럼을 정의하면 **분석기** 실행 단계에서 컬럼 확인 절차를 생략함!(그러므로 더 빨라지겠지..?)\n",
    "- Pyspark에서는 ``df['column_name']``을 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "geographic-deployment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b'count'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['count']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protecting-migration",
   "metadata": {},
   "source": [
    "## 표현식\n",
    "- 표현식이란, 데이터프레임의 레코드의 여러값에 대한 **트랜스포메이션의 집합**\n",
    "- ``expr()``과 ``col()``로 특정 칼럼을 참조하는 것은 동일\n",
    "- 예를 들어, ``expr('SomeCol - 5')`` == ``col('someCol') - 5`` == ``expr(SomeCol') - 5``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dressed-whole",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b'((((SomeCol + 5) * 200) - 6) < otherCol)'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "expr(\"(((SomeCol + 5) * 200) - 6) < otherCol\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arctic-rhythm",
   "metadata": {},
   "source": [
    "- 위 데이터프레임 코드는 SQL의 SELECT 구문으로 해당 표현식을 동일하게 사용해도 동일한 결과를 생성. 왜냐하면 실행 시점에 동일한 논리 트리로 컴파일되기 때문. 성능도 동일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "moved-royal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DEST_COUNTRY_NAME', 'ORIGIN_COUNTRY_NAME', 'count']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터프레임의 컬럼에 접근해보기\n",
    "spark.read.format('json').load('/Users/younghun/Desktop/gitrepo/data/spark_perfect_guide/flight-data/json/2015-summary.json')\\\n",
    "     .columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-format",
   "metadata": {},
   "source": [
    "## 레코드와 로우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "according-mapping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Romania', count=15)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 가장 첫 번째 레코드(Row 객체)를 반환\n",
    "df.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-writer",
   "metadata": {},
   "source": [
    "- Row객체인 레코드를 생성해보자\n",
    "- 단, Row는 스키마를 갖고 있지 않고 데이터프레임만 스키마를 가짐. 따라서 Row 생성 시, 데이터프레임의 명시된 스키마 순서와 동일하게 해주어야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "environmental-sampling",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "myRow = Row('Hello', None, 1, False) # 마지막 False는 nullable에 대한 인자!?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "becoming-zealand",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello None\n"
     ]
    }
   ],
   "source": [
    "# 로우의 데이터에 접근하기\n",
    "print(myRow[0], myRow[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scheduled-allergy",
   "metadata": {},
   "source": [
    "# DataFrame의 트랜스포메이션\n",
    "## 데이터프레임 생성\n",
    "- 기본 트렌스포메이션 결과를 확인하기 위해 임시 뷰로 테이블 등록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "gothic-journal",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format('json').load('/Users/younghun/Desktop/gitrepo/data/spark_perfect_guide/flight-data/json/2015-summary.json')\n",
    "df.createOrReplaceTempView('dfTable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "secure-permission",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DEST_COUNTRY_NAME: string (nullable = true)\n",
      " |-- ORIGIN_COUNTRY_NAME: string (nullable = true)\n",
      " |-- count: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "afraid-wonder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-----+\n",
      "| some| col|names|\n",
      "+-----+----+-----+\n",
      "|Hello|null|    1|\n",
      "+-----+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import StructField, StructType, LongType\n",
    "\n",
    "myManualSchema = StructType([\n",
    "    StructField('some', StringType(), True),\n",
    "    StructField('col', StringType(), True),\n",
    "    StructField('names', LongType(), False)\n",
    "])\n",
    "\n",
    "myRow = Row(\"Hello\", None, 1) # 데이터프레임이 갖는 Schema 순서로 정의\n",
    "myDf = spark.createDataFrame([myRow], schema=myManualSchema)\n",
    "myDf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blocked-causing",
   "metadata": {},
   "source": [
    "## 트랜스포메이션 종류\n",
    "- 칼럼이나 표현식을 사용하는 ``select``\n",
    "- 문자열 표현식을 사용하는 ``selectExpr``\n",
    "- 매서드로 사용할 수 없는 ``org.apache.spark.sql.functions`` 패키지에 포함된 다양한 함수\n",
    "<br><br>\n",
    "- 위 3가지의 방법으로 데이터프레임을 다룰 때 필요한 대부분의 트랜스포메이션을 수행할 수 있음\n",
    "### ``select`` & ``selectExpr``\n",
    "- 데이터 테이블에 SQL 쿼리문을 실행하는 것처럼 사용 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "white-qualification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|DEST_COUNTRY_NAME|\n",
      "+-----------------+\n",
      "|    United States|\n",
      "|    United States|\n",
      "+-----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('DEST_COUNTRY_NAME').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "revised-indicator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|\n",
      "+-----------------+-------------------+\n",
      "|    United States|            Romania|\n",
      "|    United States|            Croatia|\n",
      "+-----------------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 여러개의 칼럼 가져오기\n",
    "df.select(\"DEST_COUNTRY_NAME\", \"ORIGIN_COUNTRY_NAME\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "special-applicant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+-----------------+\n",
      "|DEST_COUNTRY_NAME|DEST_COUNTRY_NAME|DEST_COUNTRY_NAME|\n",
      "+-----------------+-----------------+-----------------+\n",
      "|    United States|    United States|    United States|\n",
      "|    United States|    United States|    United States|\n",
      "+-----------------+-----------------+-----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 다음과 같이 다양한 방법들로 칼럼을 참조할 수 있음\n",
    "from pyspark.sql.functions import expr, col, column\n",
    "\n",
    "df.select(expr(\"DEST_COUNTRY_NAME\"),\n",
    "         col(\"DEST_COUNTRY_NAME\"),\n",
    "         column(\"DEST_COUNTRY_NAME\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "affiliated-white",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+\n",
      "|DEST_COUNTRY_NAME|DEST_COUNTRY_NAME|\n",
      "+-----------------+-----------------+\n",
      "|    United States|    United States|\n",
      "|    United States|    United States|\n",
      "|    United States|    United States|\n",
      "|            Egypt|            Egypt|\n",
      "|    United States|    United States|\n",
      "+-----------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 위와 같이 col(expr/column) 객체와 단순한 문자열을 함께 섞어써도 에러 발생하지 않음(책에선 에러가 발생한다고 했으나...)\n",
    "df.select(col(\"DEST_COUNTRY_NAME\"), \"DEST_COUNTRY_NAME\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunset-stress",
   "metadata": {},
   "source": [
    "- 위 방법 중 ``expr``은 가장 유연하게 칼럼을 참조하는 방법\n",
    "    - ``alias``를 사용해 칼럼 이름을 재정의 가능\n",
    "    - ``alias``한 것을 다시 ``alias()`` 메소드로 원래대로 변경 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "vulnerable-camera",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|  Destination|\n",
      "+-------------+\n",
      "|United States|\n",
      "|United States|\n",
      "+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(expr(\"DEST_COUNTRY_NAME AS Destination\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "clean-geometry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|DEST_COUNTRY_NAME|\n",
      "+-----------------+\n",
      "|    United States|\n",
      "|    United States|\n",
      "+-----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(expr(\"DEST_COUNTRY_NAME AS Destination\").alias(\"DEST_COUNTRY_NAME\")).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honey-bandwidth",
   "metadata": {},
   "source": [
    "- 위와 같이 ``select()``안에 ``expr()``을 같이 사용하는 것을 효율적이고 간단하게 할 수 있는 것이 ``selectExpr``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "intimate-anthropology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|  Destination|count|\n",
      "+-------------+-----+\n",
      "|United States|   15|\n",
      "|United States|    1|\n",
      "|United States|  344|\n",
      "+-------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.selectExpr(\"DEST_COUNTRY_NAME AS Destination\", \"count\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pending-specific",
   "metadata": {},
   "source": [
    "- ``selectExpr``은 새로운 데이터프레임을 생성하는(ex.새로운 칼럼을 만들어내는 트렌스포메이션을 지정하면서 새로운 데이터프레임이 생성됨) 복잡한 표현식을 간단하게 만드는 도구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "sixth-brooks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+-------------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|withinCountry|\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "|    United States|            Romania|   15|        false|\n",
      "|    United States|            Croatia|    1|        false|\n",
      "|    United States|            Ireland|  344|        false|\n",
      "|            Egypt|      United States|   15|        false|\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 출발지와 도착지가 같은지 나타내는 새로운 칼럼 만들기\n",
    "df.selectExpr(\"*\", \"(DEST_COUNTRY_NAME = ORIGIN_COUNTRY_NAME) AS withinCountry\").show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "hazardous-swimming",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------------+\n",
      "| avg(count)|count(DEST_COUNTRY_NAME)|\n",
      "+-----------+------------------------+\n",
      "|1770.765625|                     256|\n",
      "+-----------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 간단한 집계(평균, 최댓값, 최소값 등) 가능\n",
    "df.selectExpr(\"AVG(count)\", \"COUNT(DEST_COUNTRY_NAME)\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-browse",
   "metadata": {},
   "source": [
    "## 스파크 데이터 타입으로 변환하기\n",
    "- 명시적인 값(상숫값 또는 추후 비교에 사용할 Scala값 같은 것들)을 스파크에 전달해주기 위해 스파크 데이터 타입으로 변환해야 함\n",
    "- 이 때, 리터럴(``lit()``)을 사용함. 리터럴은 스파크가 이해할 수 있는 값(스파크 데이터 타입)으로 변환함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "original-punch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+---+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|One|\n",
      "+-----------------+-------------------+-----+---+\n",
      "|    United States|            Romania|   15|  1|\n",
      "|    United States|            Croatia|    1|  1|\n",
      "+-----------------+-------------------+-----+---+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "df.select(col(\"*\"), lit(1).alias(\"One\")).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minute-minutes",
   "metadata": {},
   "source": [
    "## 칼럼 추가하기\n",
    "- DataFrame의 ``withColumn(\"새로운칼럼이름\", 표현식)`` 메서드를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ecological-diamond",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+---------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|numberOne|\n",
      "+-----------------+-------------------+-----+---------+\n",
      "|    United States|            Romania|   15|        1|\n",
      "|    United States|            Croatia|    1|        1|\n",
      "+-----------------+-------------------+-----+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"numberOne\", lit(1)).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "civic-exclusive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|Binary|\n",
      "+-----------------+-------------------+-----+------+\n",
      "|    United States|            Romania|   15| false|\n",
      "|    United States|            Croatia|    1| false|\n",
      "|    United States|            Ireland|  344| false|\n",
      "|            Egypt|      United States|   15| false|\n",
      "|    United States|              India|   62| false|\n",
      "+-----------------+-------------------+-----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 출발지와 도착지가 같은지 여부를 불리언 타입으로 하는 새로운 칼럼 만들기\n",
    "df.withColumn(\"Binary\", expr(\"DEST_COUNTRY_NAME == ORIGIN_COUNTRY_NAME\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competent-roller",
   "metadata": {},
   "source": [
    "- ``withColumn``은 칼럼명을 rename할 수도 있음. 그러나 어떻게 보면 동일한 칼럼이 중복적으로 발생하게 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fresh-clothing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DEST_COUNTRY_NAME', 'ORIGIN_COUNTRY_NAME', 'count', 'DEST_COUNTRY_NAME2']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.withColumn(\"DEST_COUNTRY_NAME2\", expr(\"DEST_COUNTRY_NAME\")).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sensitive-vaccine",
   "metadata": {},
   "source": [
    "## 칼럼명 변경하기\n",
    "- ``withColumnRenamed(\"원래칼럼명\", \"새로운칼럼명\")``로 변경 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "balanced-portfolio",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------------+-----+\n",
      "|  Destination|ORIGIN_COUNTRY_NAME|count|\n",
      "+-------------+-------------------+-----+\n",
      "|United States|            Romania|   15|\n",
      "|United States|            Croatia|    1|\n",
      "+-------------+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumnRenamed(\"DEST_COUNTRY_NAME\", \"Destination\").show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-bangkok",
   "metadata": {},
   "source": [
    "### 예약 문자와 키워드\n",
    "- 공백이나 하이픈(-)같은 예약 문자는 칼럼명에 포함시킬 수 없음. 만약 사용하려면 백틱( ` )을 사용해 이스케이핑해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "matched-jacket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+---------------------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|This Long Column-Name|\n",
      "+-----------------+-------------------+-----+---------------------+\n",
      "|    United States|            Romania|   15|              Romania|\n",
      "|    United States|            Croatia|    1|              Croatia|\n",
      "+-----------------+-------------------+-----+---------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 이스케이핑이 필요하지 않은 경우 -> withColumn 첫 번째 인자에 새로운 칼럼명을 넣을 때\n",
    "dfWithLongColName = df.withColumn(\"This Long Column-Name\", expr(\"ORIGIN_COUNTRY_NAME\"))\n",
    "dfWithLongColName.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "hourly-member",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-------+\n",
      "|This Long Column-Name|New Col|\n",
      "+---------------------+-------+\n",
      "|              Romania|Romania|\n",
      "|              Croatia|Croatia|\n",
      "+---------------------+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 이스케이핑이 필요한 경우 -> 참조하는 표현식에 예약 문자가 있기 때문에 백틱 사용\n",
    "dfWithLongColName.selectExpr(\"`This Long Column-Name`\",\n",
    "                            \"`This Long Column-Name` as `New Col`\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "hispanic-forge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+---------------------+\n",
      "|This Long Column-Name|This Long Column-Name|\n",
      "+---------------------+---------------------+\n",
      "|              Romania|              Romania|\n",
      "|              Croatia|              Croatia|\n",
      "+---------------------+---------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 조회할 때도 칼럼 명에 예악문자나 키워드가 포함되어 있다면 백틱 추가해서 조회!\n",
    "dfWithLongColName.select(expr(\"`This Long Column-Name`\"), col(\"`This Long Column-Name`\")).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equivalent-slovenia",
   "metadata": {},
   "source": [
    "## 대소문자 구분\n",
    "- 기본적으로 스파크는 대소문자를 구분하지 않음. 하지만 지정해서 대소문자를 구분하게 할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "complete-profile",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyspark\n",
    "spark.conf.set('spark.sql.caseSensitive', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sonic-overview",
   "metadata": {},
   "source": [
    "## 칼럼 제거하기\n",
    "- ``select``로 제거할 수도 있지만 ``drop``으로도 가능\n",
    "- ``drop``인자에 여러개의 칼럼명을 넣어 다수의 칼럼들을 제거 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "collect-commerce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DEST_COUNTRY_NAME', 'count']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop\n",
    "df.drop(\"ORIGIN_COUNTRY_NAME\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "angry-proportion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|\n",
      "+-----------------+-------------------+\n",
      "|    United States|            Romania|\n",
      "|    United States|            Croatia|\n",
      "+-----------------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop multiple columns\n",
    "dfWithLongColName.drop(\"count\", \"This Long Column-Name\").show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressed-region",
   "metadata": {},
   "source": [
    "## 칼럼의 데이터 타입 변경하기\n",
    "- ``cast``메서드 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "artificial-bleeding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DEST_COUNTRY_NAME: string (nullable = true)\n",
      " |-- ORIGIN_COUNTRY_NAME: string (nullable = true)\n",
      " |-- count: long (nullable = true)\n",
      " |-- count2: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# int형 -> string으로\n",
    "ex_df = df.withColumn(\"count2\", col(\"count\").cast(\"string\"))\n",
    "ex_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rapid-beginning",
   "metadata": {},
   "source": [
    "## 로우 필터링하기\n",
    "- True/False를 판별하는 표현식을 만들어 False인 로우들을 걸러내기\n",
    "- ``where``과 ``filter`` 사용(두 방법 모두 같은 연산을 수행하며 같은 파라미터 타입을 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "meaningful-witness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|          Singapore|    1|\n",
      "|          Moldova|      United States|    1|\n",
      "|            Malta|      United States|    1|\n",
      "|    United States|          Gibraltar|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# where\n",
    "df.where(\"count < 2\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "pediatric-classic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|          Singapore|    1|\n",
      "|          Moldova|      United States|    1|\n",
      "|            Malta|      United States|    1|\n",
      "|    United States|          Gibraltar|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filter\n",
    "df.filter(\"count < 2\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abandoned-worse",
   "metadata": {},
   "source": [
    "- 필터링 조건을 여러개 붙일 수 있음. 그러나 스파크는 모든 필터링 작업을 동시에 수행하기 때문에 필터를 여러개 지정하되 필터링 순서는 스파크의 판단에 맡겨야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "corporate-player",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|          Singapore|    1|\n",
      "|          Moldova|      United States|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(col(\"count\") < 2).where(col(\"ORIGIN_COUNTRY_NAME\") != \"Croatia\").show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mounted-james",
   "metadata": {},
   "source": [
    "## 고유한(unique) 로우 얻기\n",
    "- ``distinct`` 메서드 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cooked-origin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 출발지, 도착지가 고유한 데이터\n",
    "df.select(\"ORIGIN_COUNTRY_NAME\", \"DEST_COUNTRY_NAME\").distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal-honor",
   "metadata": {},
   "source": [
    "- 출발지 -> 도착지가 유니크한 값들이 256개나 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "anticipated-theta",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(\"ORIGIN_COUNTRY_NAME\").distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distributed-armenia",
   "metadata": {},
   "source": [
    "## 무작위 샘플 만들기\n",
    "- 데이터프레임의 ``sample`` 메서드 사용\n",
    "- 표본 데이터 추출 비율을 지정할 수 있으며 복원추출 또는 비복원 추출을 지정할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "imposed-title",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 5\n",
    "withReplacement = False\n",
    "fraction = 0.5\n",
    "\n",
    "df.sample(withReplacement=withReplacement, fraction=fraction, seed=seed).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efficient-organic",
   "metadata": {},
   "source": [
    "## 임의 분할하기\n",
    "- 보통 Train/Test 데이터셋 분할시 자주 사용\n",
    "- ``randomSplit`` 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "proper-architecture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DataFrame[DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string, count: bigint], DataFrame[DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string, count: bigint]] \n",
      " <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "dataFrames = df.randomSplit([0.25, 0.75], seed=42)\n",
    "print(dataFrames,'\\n', type(dataFrames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "herbal-granny",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63 193\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dataFrames[0].count(), dataFrames[1].count())\n",
    "dataFrames[0].count() > dataFrames[1].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-method",
   "metadata": {},
   "source": [
    "## 로우 합치기와 추가하기\n",
    "- 데이터프레임은 불변성이기 때문에 로우를 추가하려면 추가할 로우를 새로운 데이터프레임으로 만들고 기존의 데이터프레임과 결합(``union``)하는 방향으로 가야 함\n",
    "- 결합할 시, 반드시 기존의 데이터르페림의 스키마와 칼럼 수가 동일해야 함!\n",
    "- 참고로 ``union``은 현재 스키마가 아닌 칼럼 위치를 기반으로 동작하기 때문에 사용자가 생각한 대로 칼렴들이 자동 정렬되어 있지 않을 수 있음!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "complex-payroll",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    New Country 2|    Other Country 3|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 새로운 데이터프레임 만들기 위해 Row 객체를 만들어서 RDD 만들어야 함\n",
    "from pyspark.sql import Row\n",
    "\n",
    "schema = df.schema  # 기존의 데이터프레임의 스키마\n",
    "\n",
    "# 책 속 'L'은 Long Integer Type을 따로 정의해야 하는 Python 2.X 버전이라 그럼\n",
    "newRows = [Row('New Country', 'Other Country', 5),\n",
    "          Row('New Country 2', 'Other Country 3', 1)]\n",
    "parallelizeRows = spark.sparkContext.parallelize(newRows)  # RDD로 변환\n",
    "newDF = spark.createDataFrame(parallelizeRows, schema=schema)  # DF으로 변환\n",
    "\n",
    "# 기존DF.union(새로운DF) ~ \n",
    "df.union(newDF)\\\n",
    "  .where('count = 1')\\\n",
    "  .where(col('ORIGIN_COUNTRY_NAME') != 'United States')\\\n",
    "  .where(col('DEST_COUNTRY_NAME') != 'United States')\\\n",
    "  .show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hired-translation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
