{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23.1\n"
     ]
    }
   ],
   "source": [
    "# sklearn 버전확인\n",
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 정확도 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# 내장 데이터 로딩\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = load_iris()\n",
    "model = DecisionTreeClassifier()\n",
    "train_feature = iris.data\n",
    "train_label = iris.target\n",
    "model.fit(train_feature, train_label)\n",
    "\n",
    "# train 데이터로만 훈련시키고 검증 하는 케이스 => 잘못된 케이스임\n",
    "pred = model.predict(train_feature)\n",
    "print(f\" 정확도 : {accuracy_score(train_label, pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold 모두 수행 후 평균 예측도 : 0.9266666666666667\n"
     ]
    }
   ],
   "source": [
    "# cross validation\n",
    "# 일반적인 K-Fold cv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "all_acc = []\n",
    "fold_idx = 0\n",
    "\n",
    "features = iris.data\n",
    "labels = iris.target\n",
    "\n",
    "for train_idx, test_idx in kf.split(features):\n",
    "    \n",
    "    train_x, train_y = features[train_idx], labels[train_idx]\n",
    "    test_x, test_y = features[test_idx], labels[test_idx]\n",
    "    \n",
    "    model = DecisionTreeClassifier()\n",
    "    model.fit(train_x, train_y)\n",
    "    pred_y = model.predict(test_x)\n",
    "    acc = accuracy_score(test_y, pred_y)\n",
    "    \n",
    "    fold_idx += 1\n",
    "    \n",
    "    all_acc.append(acc)\n",
    "\n",
    "print(f\"KFold 모두 수행 후 평균 예측도 : {np.mean(all_acc)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold 모두 수행 후 평균 예측도 : 0.9600000000000002\n"
     ]
    }
   ],
   "source": [
    "# Stratified Cross validation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "all_acc = []\n",
    "fold_idx = 0\n",
    "\n",
    "features = iris.data\n",
    "labels = iris.target\n",
    "\n",
    "for train_idx, test_idx in skf.split(features, labels):\n",
    "    \n",
    "    train_x, train_y = features[train_idx], labels[train_idx]\n",
    "    test_x, test_y = features[test_idx], labels[test_idx]\n",
    "    \n",
    "    model = DecisionTreeClassifier()\n",
    "    model.fit(train_x, train_y)\n",
    "    pred_y = model.predict(test_x)\n",
    "    acc = accuracy_score(test_y, pred_y)\n",
    "    \n",
    "    fold_idx += 1\n",
    "    \n",
    "    all_acc.append(acc)\n",
    "\n",
    "print(f\"KFold 모두 수행 후 평균 예측도 : {np.mean(all_acc)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한 번씩 검증 때마다 accuracy : [0.96666667 0.96666667 0.9        0.96666667 1.        ]\n",
      "\n",
      "5번 모두 검증한 accuracy 총 평균 : 0.9600000000000002\n"
     ]
    }
   ],
   "source": [
    "# cross_val_score로 집약해서 교차검증\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "import numpy as np\n",
    "\n",
    "iris_data = load_iris()\n",
    "features = iris_data.data\n",
    "labels = iris.target\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "scores = cross_val_score(model, features, labels,\n",
    "                        scoring='accuracy', cv=5)\n",
    "\n",
    "print(f\"한 번씩 검증 때마다 accuracy : {scores}\")\n",
    "print()\n",
    "print(f\"5번 모두 검증한 accuracy 총 평균 : {np.mean(scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최고의 Hyperparameter 찾기 위한 GridsearchCV 사용\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris_data = load_iris()\n",
    "train_x, test_x, train_y, test_y = train_test_split(iris_data.data,\n",
    "                                                   iris_data.target,\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=45)\n",
    "model = DecisionTreeClassifier()\n",
    "# parameter 넣어줄 값들 dict 형태로 정의해주기\n",
    "h_para = {'max_depth':[1,2,3], 'min_samples_split':[2,3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>4</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     params  mean_test_score  rank_test_score  \\\n",
       "0  {'max_depth': 1, 'min_samples_split': 2}         0.683333                5   \n",
       "1  {'max_depth': 1, 'min_samples_split': 3}         0.683333                5   \n",
       "2  {'max_depth': 2, 'min_samples_split': 2}         0.966667                1   \n",
       "3  {'max_depth': 2, 'min_samples_split': 3}         0.966667                1   \n",
       "4  {'max_depth': 3, 'min_samples_split': 2}         0.950000                3   \n",
       "5  {'max_depth': 3, 'min_samples_split': 3}         0.941667                4   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  \n",
       "0           0.666667           0.708333           0.708333  \n",
       "1           0.666667           0.708333           0.708333  \n",
       "2           0.958333           1.000000           0.916667  \n",
       "3           0.958333           1.000000           0.916667  \n",
       "4           0.958333           0.958333           0.916667  \n",
       "5           0.958333           0.958333           0.916667  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "grid_dtree = GridSearchCV(model, param_grid=h_para,\n",
    "                         cv=5, refit=True, return_train_score=True)\n",
    "# GridSearchCV 인자설명\n",
    "# cv = 하나의 파라미터 쌍으로 모델링할 때 train, test 교차검증을 3번실시하겠다는 뜻\n",
    "# refit=True : GridSearch한 후 가장 최고로 좋은 파라미터로 학습시켜 놓겠다.\n",
    "# ㄴ> 이것 때문에 애초에 GridSearchCV 적용한 객체만으로 최적의 파라미터 적용된 모델로드 가능\n",
    "\n",
    "# GridSearch 하면서 모든 파라미터값들에 대해 학습 수행\n",
    "grid_dtree.fit(train_x, train_y)\n",
    "\n",
    "# 각 파라미터값들에 대한 모델 결과값들이 cv_results_ 객체에 할당됨\n",
    "scores_df = pd.DataFrame(grid_dtree.cv_results_)\n",
    "\n",
    "# score 결과값(ndarray형태로 할당됨) 중 특정 칼럼들만 가져오기 \n",
    "scores_df[['params', 'mean_test_score', 'rank_test_score', \n",
    "           'split0_test_score', 'split1_test_score', 'split2_test_score']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적의 파라미터 : {'max_depth': 2, 'min_samples_split': 2}\n",
      "최적의 파라미터로 모델의 정확도 : 0.9666666666666668\n",
      "\n",
      "\n",
      "실제값과 예측값 정확도 : 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "# 최적의 파라미터는 best_params_에 할당되어있음\n",
    "print(f\"최적의 파라미터 : {grid_dtree.best_params_}\")\n",
    "print(f\"최적의 파라미터로 모델의 정확도 : {grid_dtree.best_score_}\")\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "# 최적의 파라미터로 학습되어 있는 모델링 할당\n",
    "estimator = grid_dtree.best_estimator_\n",
    "\n",
    "# 최적의 모델로 예측해보고 실제값이랑 정확도 비교\n",
    "pred_y = estimator.predict(test_x)\n",
    "print(f\"실제값과 예측값 정확도 : {accuracy_score(test_y, pred_y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
