{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+2\" color=\"brown\"><i><b><center>\"With hard work, you can get fire out of a stone.\"</center></b></i></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+3\" color=purple ><b> <center><u>Text Helper Functions</u></center></b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Version 4**  :  First Run <br>\n",
    "**Version 6**  :  Added 9 new regex function required for text processing.<br>\n",
    "**Version 7**  :  Added few functions and modified scripts.<br>\n",
    "**Version 8**  :  Updated kernel with few more functions and modified scripts.<br>\n",
    "**Version 9**  :  Modified script <br>\n",
    "**Version 10** :  Added description and modified script in 4.13 <br>\n",
    "**Version 11** :  Added few more helpers<br>\n",
    "**Version 12** :  Few modifications and added few more helpers<br>\n",
    "**Version 13** :  Added two more functions.<br>\n",
    "**Version 14** :  Small modification<br>\n",
    "**Version 15** :  Added more function<br>\n",
    "**Version 16** :  Added tag function<br>\n",
    "**Version 17** :  Fixed bug from V16<br>\n",
    "**Version 18** :  Added two more functions- ip and mac address<br>\n",
    "**Version 19** :  Added subword and latitude & longitude<br>\n",
    "**Version 20** :  Added PAN validation <br>\n",
    "**Version 21** :  Added Phone Number Country code<br>\n",
    "**Version 22** :  Added Positive and Negative look ahead<br>\n",
    "**Version 23** :  Added Positive and Negative look behind<br>\n",
    "**Version 24** :  Bug fix from V23<br>\n",
    "**Version 25** :  Added Domain<br>\n",
    "**Version 26** :  Added Percentage<br>\n",
    "**Version 27** :  (Current) Added File Format<br>\n",
    "**Version 28** :  *Loading...*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='top'></a>\n",
    "<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n",
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\"  role=\"tab\" aria-controls=\"home\">Table of content</h3>\n",
    "\n",
    "* [1. Objective](#1)   \n",
    "* [2. Data](#2)\n",
    "* [3. Basic Data Explorers](#3)\n",
    "    - [3.1 Missing values](#3.1)\n",
    "    - [3.2 Count values](#3.2)\n",
    "    - [3.3 Unique values](#3.3)\n",
    "    - [3.4 Duplicate values](#3.4)\n",
    "    - [3.5 Stat](#3.5)\n",
    "* [4. Regex Helpers](#4)\n",
    "    - [4.1 URL](#4.1)\n",
    "    - [4.2 Emoticons](#4.2)\n",
    "    - [4.3 Email](#4.3)\n",
    "    - [4.4 Hash](#4.4)\n",
    "    - [4.5 Mention](#4.5)\n",
    "    - [4.6 Number](#4.6)\n",
    "    - [4.7 Phone Number](#4.7)\n",
    "    - [4.8 Year](#4.8)\n",
    "    - [4.9 Non Alphanumeric](#4.9)\n",
    "    - [4.10 Punctuations](#4.10)\n",
    "    - [4.11 Stopwords](#4.11)\n",
    "    - [4.12 N-grams](#4.12)\n",
    "    - [4.13 Repetitive Character](#4.13)\n",
    "    - [4.14 Dollar](#4.14)\n",
    "    - [4.15 Number-Greater](#4.15)\n",
    "    - [4.16 Number- Lesser](#4.16)\n",
    "    - [4.17 OR](#4.17)\n",
    "    - [4.18 AND](#4.18)\n",
    "    - [4.19 Dates](#4.19)\n",
    "    - [4.20 Only Words](#4.20)\n",
    "    - [4.21 Only Numbers](#4.21)\n",
    "    - [4.22 Boundaries](#4.22)\n",
    "    - [4.23 Search](#4.23)\n",
    "    - [4.24 Pick Sentence](#4.24)\n",
    "    - [4.25 Duplicate Sentence](#4.25)\n",
    "    - [4.26 Caps Words](#4.26)\n",
    "    - [4.27 Length of Words](#4.27)\n",
    "    - [4.28 Length of Characters](#4.28)\n",
    "    - [4.29 Get ID](#4.29)\n",
    "    - [4.30 Specific String Rows](#4.30)\n",
    "    - [4.31 Hex code to Color](#4.31)\n",
    "    - [4.32 Tags](#4.32)\n",
    "    - [4.33 IP Address](#4.33)\n",
    "    - [4.34 Mac Address](#4.34)\n",
    "    - [4.35 Subword](#4.35)\n",
    "    - [4.36 Latitude & Longitude](#4.36)\n",
    "    - [4.37 PAN](#4.37)\n",
    "    - [4.38 Phone Number Country Code](#4.38)\n",
    "    - [4.39 Positive Look Ahead](#4.39)\n",
    "    - [4.40 Negative Look Ahead](#4.40)\n",
    "    - [4.41 Positive Look Behind](#4.41)\n",
    "    - [4.42 Negative Look Behind](#4.42)\n",
    "    - [4.43 Domain](#4.43)\n",
    "    - [4.44 Percentage](#4.44)\n",
    "    - [4.45 File Format](#4.45)\n",
    "* [5. End Notes](#5)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+3\" color=\"blue\"><b>1. Objective</b></font><br><a id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this kernel is to provide helper function for basic text processing.This functions can aid you to understand the data much better and perform EDA.\n",
    "My major focus will be on apply regex on text but still i have mentioned few basic starter codes on the 3rd part of kernel.Rest all sections will deal with text preprocessing.The whole kernel can be useful for everyone especially **beginners**.\n",
    "\n",
    "<font size=\"+1\"><i>Readers,I am making you lazy to code but at same time I am helping you out.Do utilize this kernel for any of your text oriented competitions.</i></font><br><br>\n",
    "    \n",
    "<font size=\"+1\" color=chocolate ><b>Please appreciate me through your Upvote.</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+3\" color=\"blue\"><b>2. Data</b></font><br><a id=\"2\"></a>\n",
    "\n",
    "I will be using data from [Twitter Sentiment Analysis](https://www.kaggle.com/c/tweet-sentiment-extraction/data) competiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  \n",
       "2                          bullying me  negative  \n",
       "3                       leave me alone  negative  \n",
       "4                        Sons of ****,  negative  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import re\n",
    "import emoji\n",
    "\n",
    "#Count vectorizer for N grams\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "\n",
    "# Nltk for tekenize and stopwords\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "#Loading data\n",
    "df=pd.read_csv('../input/tweet-sentiment-extraction/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+3\" color=\"blue\"><b>3. Basic Data Explorers</b></font><br> <a id=\"3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+2\" color=\"indigo\"><b>3.1 Missing values</b></font><br><a id=\"3.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_value_of_data(data):\n",
    "    total=data.isnull().sum().sort_values(ascending=False)\n",
    "    percentage=round(total/data.shape[0]*100,2)\n",
    "    return pd.concat([total,percentage],axis=1,keys=['Total','Percentage'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>selected_text</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>textID</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Total  Percentage\n",
       "selected_text      1         0.0\n",
       "text               1         0.0\n",
       "sentiment          0         0.0\n",
       "textID             0         0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_value_of_data(df)\n",
    "#  Reason for 0 percentage value = Round of 1 divided by 27481 will be 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will drop NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+2\" color=\"indigo\"><b>3.2 Count Values</b></font><br><a id=\"3.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_values_in_column(data,feature):\n",
    "    total=data.loc[:,feature].value_counts(dropna=False)\n",
    "    percentage=round(data.loc[:,feature].value_counts(dropna=False,normalize=True)*100,2)\n",
    "    return pd.concat([total,percentage],axis=1,keys=['Total','Percentage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>11117</td>\n",
       "      <td>40.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>8582</td>\n",
       "      <td>31.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>7781</td>\n",
       "      <td>28.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Total  Percentage\n",
       "neutral   11117       40.45\n",
       "positive   8582       31.23\n",
       "negative   7781       28.32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_values_in_column(df,'sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+2\" color=\"indigo\"><b>3.3 Unique Values</b></font><br><a id=\"3.3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_values_in_column(data,feature):\n",
    "    unique_val=pd.Series(data.loc[:,feature].unique())\n",
    "    return pd.concat([unique_val],axis=1,keys=['Unique Values'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unique Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unique Values\n",
       "0       neutral\n",
       "1      negative\n",
       "2      positive"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_values_in_column(df,'sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+2\" color=\"indigo\"><b>3.4 Duplicate Values</b></font><br><a id=\"3.4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def duplicated_values_data(data):\n",
    "    dup=[]\n",
    "    columns=data.columns\n",
    "    for i in data.columns:\n",
    "        dup.append(sum(data[i].duplicated()))\n",
    "    return pd.concat([pd.Series(columns),pd.Series(dup)],axis=1,keys=['Columns','Duplicate count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Columns</th>\n",
       "      <th>Duplicate count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>textID</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>text</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>selected_text</td>\n",
       "      <td>5017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sentiment</td>\n",
       "      <td>27477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Columns  Duplicate count\n",
       "0         textID                0\n",
       "1           text                0\n",
       "2  selected_text             5017\n",
       "3      sentiment            27477"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicated_values_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+2\" color=\"indigo\"><b>3.5 Stat</b></font><br><a id=\"3.5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27480</td>\n",
       "      <td>27480</td>\n",
       "      <td>27480</td>\n",
       "      <td>27480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>27480</td>\n",
       "      <td>27480</td>\n",
       "      <td>22463</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>c5aa5c0980</td>\n",
       "      <td>When youre kawawa, you make me kawawa cuz i ha...</td>\n",
       "      <td>good</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>199</td>\n",
       "      <td>11117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            textID                                               text  \\\n",
       "count        27480                                              27480   \n",
       "unique       27480                                              27480   \n",
       "top     c5aa5c0980  When youre kawawa, you make me kawawa cuz i ha...   \n",
       "freq             1                                                  1   \n",
       "\n",
       "       selected_text sentiment  \n",
       "count          27480     27480  \n",
       "unique         22463         3  \n",
       "top             good   neutral  \n",
       "freq             199     11117  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since these kind of basic python functions are pretty much well known to all python users.We dont need much focus here.Still I will elaborate this section in upcoming versions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+3\" color=\"blue\"><b>4. Regex Helpers</b></font><br> \n",
    "<a id=\"4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Major RE functions\n",
    "\n",
    "* **re.findall**   - Module is used to search for “all” occurrences that match a given pattern.\n",
    "* **re.sub**       - Substitute the matched RE patter with given text\n",
    "* **re.match**     - The match function is used to match the RE pattern to string with optional flags\n",
    "* **re.search**    - This method takes a regular expression pattern and a string and searches for that pattern with the string.\n",
    "\n",
    "\n",
    "We will be mostly using re.findall to detect patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+2\" color=\"indigo\"><b>4.1 URL</b></font><br><a id=\"4.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "def find_url(string): \n",
    "    text = re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+',string)\n",
    "    return \"\".join(text) # converting return value from list to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.kaggle.com/'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence=\"I love spending time at https://www.kaggle.com/\"\n",
    "find_url(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['url']=df['text'].apply(lambda x:find_url(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+2\" color=\"indigo\"><b>4.2 Emoticons</b></font><br><a id=\"4.2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find and convert emoji to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_emoji(text):\n",
    "    emo_text=emoji.demojize(text)\n",
    "    line=re.findall(r'\\:(.*?)\\:',emo_text)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['soccer_ball', 'beaming_face_with_smiling_eyes']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence=\"I love ⚽ very much 😁\"\n",
    "find_emoji(sentence)\n",
    "\n",
    "# Emoji cheat sheet - https://www.webfx.com/tools/emoji-cheat-sheet/\n",
    "# Uniceode for all emoji : https://unicode.org/emoji/charts/full-emoji-list.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['emoji']=df['text'].apply(lambda x: find_emoji(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Emoji from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Its all about 😀 face\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Its all about  face'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence=\"Its all about \\U0001F600 face\"\n",
    "print(sentence)\n",
    "remove_emoji(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text']=df['text'].apply(lambda x: remove_emoji(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+2\" color=\"indigo\"><b>4.3 Email</b></font><br><a id=\"4.3\"></a>\n",
    "\n",
    "Extract email from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_email(text):\n",
    "    line = re.findall(r'[\\w\\.-]+@[\\w\\.-]+',str(text))\n",
    "    return \",\".join(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abc99@gmail.com'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence=\"My gmail is abc99@gmail.com\"\n",
    "find_email(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['email']=df['text'].apply(lambda x: find_email(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+2\" color=\"indigo\"><b>4.4 Hash</b></font><br><a id=\"4.4\"></a>\n",
    "\n",
    "This value is especially to denote trends in twitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_hash(text):\n",
    "    line=re.findall(r'(?<=#)\\w+',text)\n",
    "    return \" \".join(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Corona'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence=\"#Corona is trending now in the world\" \n",
    "find_hash(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hash']=df['text'].apply(lambda x: find_hash(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+2\" color=\"indigo\"><b>4.5 Mention</b></font><br><a id=\"4.5\"></a>\n",
    "\n",
    "@ - Used to mention someone in tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_at(text):\n",
    "    line=re.findall(r'(?<=@)\\w+',text)\n",
    "    return \" \".join(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'David'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence=\"@David,can you help me out\"\n",
    "find_at(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['at_mention']=df['text'].apply(lambda x: find_at(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+2\" color=\"indigo\"><b>4.6 Number</b></font><br><a id=\"4.6\"></a>\n",
    "\n",
    "Pick only number from sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_number(text):\n",
    "    line=re.findall(r'[0-9]+',text)\n",
    "    return \" \".join(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2833047'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence=\"2833047 people are affected by corona now\"\n",
    "find_number(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['number']=df['text'].apply(lambda x: find_number(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+2\" color=\"indigo\"><b>4.7 Phone Number</b></font><br><a id=\"4.7\"></a>\n",
    "\n",
    "Indian Mobile numbers have ten digit.I will write that pattern below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_phone_number(text):\n",
    "    line=re.findall(r\"\\b\\d{10}\\b\",text)\n",
    "    return \"\".join(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9998887776'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_phone_number(\"9998887776 is a phone number of Mark from 210,North Avenue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['phone_number']=df['text'].apply(lambda x: find_phone_number(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+2\" color=\"indigo\"><b>4.8 Year</b></font><br><a id=\"4.8\"></a>\n",
    "\n",
    "Extract year from 1940 till 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_year(text):\n",
    "    line=re.findall(r\"\\b(19[40][0-9]|20[0-1][0-9]|2020)\\b\",text)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1947']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence=\"India got independence on 1947.\"\n",
    "find_year(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year']=df['text'].apply(lambda x: find_year(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+2\" color=\"indigo\"><b>4.9 Non Alphanumeric</b></font><br><a id=\"4.9\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nonalp(text):\n",
    "    line = re.findall(\"[^A-Za-z0-9 ]\",text)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@', '#', '.', '(', ')']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence=\"Twitter has lots of @ and # in posts.(general tweet)\"\n",
    "find_nonalp(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['non_alp']=df['text'].apply(lambda x: find_nonalp(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+2\" color=\"indigo\"><b>4.10 Punctuations</b></font><br><a id=\"4.10\"></a>\n",
    "\n",
    "Retrieve punctuations from sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_punct(text):\n",
    "    line = re.findall(r'[!\"\\$%&\\'()*+,\\-.\\/:;=#@?\\[\\\\\\]^_`{|}~]*', text)\n",
    "    string=\"\".join(line)\n",
    "    return list(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#', '.', '#', '(', ')']\n"
     ]
    }
   ],
   "source": [
    "example=\"Corona virus have kiled #24506 confirmed cases now.#Corona is un(tolerable)\"\n",
    "print(find_punct(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['punctuation']=df['text'].apply(lambda x : find_punct(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+2\" color=\"indigo\"><b>4.11 Stopwords</b></font><br><a id=\"4.11\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_word_fn(text):\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    word_tokens = word_tokenize(text) \n",
    "    non_stop_words = [w for w in word_tokens if not w in stop_words] \n",
    "    stop_words= [w for w in word_tokens if w in stop_words] \n",
    "    return stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is', 'a', 'off', 'the']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_sent = \"This is a sample sentence, showing off the stop words filtration.\"\n",
    "stop_word_fn(example_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stop_words']=df['text'].apply(lambda x : stop_word_fn(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+2\" color=\"indigo\"><b>4.12 N-grams</b></font><br><a id=\"4.12\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrams_top(corpus,ngram_range,n=None):\n",
    "    \"\"\"\n",
    "    List the top n words in a vocabulary according to occurrence in a text corpus.\n",
    "    \"\"\"\n",
    "    vec = CountVectorizer(stop_words = 'english',ngram_range=ngram_range).fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    total_list=words_freq[:n]\n",
    "    df=pd.DataFrame(total_list,columns=['text','count'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>just</td>\n",
       "      <td>2278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>day</td>\n",
       "      <td>2115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>good</td>\n",
       "      <td>1578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>like</td>\n",
       "      <td>1353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http</td>\n",
       "      <td>1247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>work</td>\n",
       "      <td>1150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>today</td>\n",
       "      <td>1147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>love</td>\n",
       "      <td>1145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>going</td>\n",
       "      <td>1103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>got</td>\n",
       "      <td>1085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    text  count\n",
       "0   just   2278\n",
       "1    day   2115\n",
       "2   good   1578\n",
       "3   like   1353\n",
       "4   http   1247\n",
       "5   work   1150\n",
       "6  today   1147\n",
       "7   love   1145\n",
       "8  going   1103\n",
       "9    got   1085"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams_top(df['text'],(1,1),n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mother day</td>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>twitpic com</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http twitpic</td>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mothers day</td>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>happy mother</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>just got</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>happy mothers</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>http bit</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bit ly</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>good morning</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            text  count\n",
       "0     mother day    358\n",
       "1    twitpic com    334\n",
       "2   http twitpic    332\n",
       "3    mothers day    279\n",
       "4   happy mother    275\n",
       "5       just got    219\n",
       "6  happy mothers    199\n",
       "7       http bit    180\n",
       "8         bit ly    180\n",
       "9   good morning    176"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams_top(df['text'],(2,2),n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http twitpic com</td>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>happy mother day</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>happy mothers day</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http bit ly</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http tinyurl com</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>http plurk com</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>star wars day</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>http blip fm</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>happy star wars</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>just got home</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                text  count\n",
       "0   http twitpic com    332\n",
       "1   happy mother day    268\n",
       "2  happy mothers day    195\n",
       "3        http bit ly    180\n",
       "4   http tinyurl com    166\n",
       "5     http plurk com    109\n",
       "6      star wars day     73\n",
       "7       http blip fm     73\n",
       "8    happy star wars     56\n",
       "9      just got home     53"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams_top(df['text'],(3,3),n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+2\" color=\"indigo\"><b>4.13 Repetitive Character</b></font><br><a id=\"4.13\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to change match repetitive characters to n numbers,**chage the return line in the *rep function* to grp[0:n]**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rep(text):\n",
    "    grp = text.group(0)\n",
    "    if len(grp) > 1:\n",
    "        return grp[0:1] # can change the value here on repetition\n",
    "def unique_char(rep,sentence):\n",
    "    convert = re.sub(r'(\\w)\\1+', rep, sentence) \n",
    "    return convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hey this is long text son'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence=\"heyyy this is loong textttt sooon\"\n",
    "unique_char(rep,sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['unique_char']=df['text'].apply(lambda x : unique_char(rep,x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+2\" color=\"indigo\"><b>4.14 Dollar</b></font><br><a id=\"4.14\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_dollar(text):\n",
    "    line=re.findall(r'\\$\\dp+(?:\\.\\d+)?',text)\n",
    "    return \" \".join(line)\n",
    "\n",
    "# \\$ - dollar sign followed by\n",
    "# \\d+ one or more digits\n",
    "# (?:\\.\\d+)? - decimal which is optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence=\"this shirt costs $20.56\"\n",
    "find_dollar(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dollar']=df['text'].apply(lambda x : find_dollar(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+2\" color=\"indigo\"><b>4.15 Number-Greater</b></font><br><a id=\"4.15\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number greater than 930\n",
    "def num_great(text): \n",
    "    line=re.findall(r'9[3-9][0-9]|[1-9]\\d{3,}',text)\n",
    "    return \" \".join(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'935 29974'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence=\"It is expected to be more than 935 corona death and 29974 observation cases across 29 states in india\"\n",
    "num_great(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number greater than 930 (Just part of example)\n",
    "df['num_great']=df['text'].apply(lambda x : num_great(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+2\" color=\"indigo\"><b>4.16 Number Lesser</b></font><br><a id=\"4.16\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number less than 930\n",
    "def num_less(text):\n",
    "    only_num=[]\n",
    "    for i in text.split():\n",
    "        line=re.findall(r'^(9[0-2][0-0]|[1-8][0-9][0-9]|[1-9][0-9]|[0-9])$',i) # 5 500\n",
    "        only_num.append(line)\n",
    "        all_num=[\",\".join(x) for x in only_num if x != []]\n",
    "    return \" \".join(all_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'920'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence=\"There are some countries where less than 920 cases exist with 1100 observations\"\n",
    "num_less(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number greater than 930 (Just part of example)\n",
    "df['num_less']=df['text'].apply(lambda x : num_less(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+2\" color=\"indigo\"><b>4.17 OR</b></font><br><a id=\"4.17\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def or_cond(text,key1,key2):\n",
    "    line=re.findall(r\"{}|{}\".format(key1,key2), text) \n",
    "    return \" \".join(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sad sorrow'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence=\"sad and sorrow displays emotions\"\n",
    "or_cond(sentence,'sad','sorrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks for sorrow or sad word\n",
    "df['sad_or_sorrow']=df['text'].apply(lambda x : or_cond(x,'sad','sorrow'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+2\" color=\"indigo\"><b>4.18 AND</b></font><br><a id=\"4.18\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def and_cond(text):\n",
    "    line=re.findall(r'(?=.*do)(?=.*die).*', text) \n",
    "    return \" \".join(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both string present: do or die is a motivating phrase\n",
      "Only one string present : \n"
     ]
    }
   ],
   "source": [
    "print(\"Both string present:\",and_cond(\"do or die is a motivating phrase\"))\n",
    "print(\"Only one string present :\",and_cond('die word is other side of emotion'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks for do and die both else empty\n",
    "df['do_and_die']=df['text'].apply(lambda x : and_cond(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+2\" color=\"indigo\"><b>4.19 Dates</b></font><br><a id=\"4.19\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mm-dd-yyyy format \n",
    "def find_dates(text):\n",
    "    line=re.findall(r'\\b(1[0-2]|0[1-9])/(3[01]|[12][0-9]|0[1-9])/([0-9]{4})\\b',text)\n",
    "    return line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('04', '28', '2020')]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence=\"Todays date is 04/28/2020 for format mm/dd/yyyy, not 28/04/2020\"\n",
    "find_dates(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dates']=df['text'].apply(lambda x : find_dates(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+2\" color=\"indigo\"><b>4.20 Only Words</b></font><br><a id=\"4.20\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def only_words(text):\n",
    "    line=re.findall(r'\\b[^\\d\\W]+\\b', text)\n",
    "    return \" \".join(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the world population has grown from million to million'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence=\"the world population has grown from 1650 million to 6000 million\"\n",
    "only_words(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['only_words']=df['text'].apply(lambda x : only_words(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4.21\"></a>\n",
    "<font size=\"+2\" color=\"indigo\"><b>4.21 Only Numbers</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def only_numbers(text):\n",
    "    line=re.findall(r'\\b\\d+\\b', text)\n",
    "    return \" \".join(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1650 6000'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence=\"the world population has grown from 1650 million to 6000 million\"\n",
    "only_numbers(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['only_num']=df['text'].apply(lambda x : only_numbers(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4.22\"></a>\n",
    "<font size=\"+2\" color=\"indigo\"><b>4.22 Boundaries</b></font><br><br>\n",
    "Picking up the words with boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting word with boundary\n",
    "def boundary(text):\n",
    "    line=re.findall(r'\\bneutral\\b', text)\n",
    "    return \" \".join(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neutral'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence=\"Most tweets are neutral in twitter\"\n",
    "boundary(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bound']=df['text'].apply(lambda x : boundary(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4.23\"></a>\n",
    "<font size=\"+2\" color=\"indigo\"><b>4.23 Search</b></font><br><br>\n",
    "Is the key word present in the sentence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_string(text,key):\n",
    "    return bool(re.search(r''+key+'', text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence=\"Happy Mothers day to all Moms\"\n",
    "search_string(sentence,'day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['search_day']=df['text'].apply(lambda x : search_string(x,'day'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4.24\"></a>\n",
    "<font size=\"+2\" color=\"indigo\"><b>4.24 Pick Sentence</b></font><br><br>\n",
    "If we want to get all sentence with particular keyword.We can use below function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_only_key_sentence(text,keyword):\n",
    "    line=re.findall(r'([^.]*'+keyword+'[^.]*)', text)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['People are fighting with covid these days', 'How will we survice covid']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence=\"People are fighting with covid these days.Economy has fallen down.How will we survice covid\"\n",
    "pick_only_key_sentence(sentence,'covid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pick_senence']=df['text'].apply(lambda x : pick_only_key_sentence(x,'covid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4.25\"></a>\n",
    "<font size=\"+2\" color=\"indigo\"><b>4.25 Duplicate Sentence</b></font><br><br>\n",
    "Most webscrapped data contains duplicated sentence.This function could retrieve unique ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_unique_sentence(text):\n",
    "    line=re.findall(r'(?sm)(^[^\\r\\n]+$)(?!.*^\\1$)', text)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Doctors are working very hard in this pandemic situation', 'I thank doctors']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence=\"I thank doctors\\nDoctors are working very hard in this pandemic situation\\nI thank doctors\"\n",
    "pick_unique_sentence(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pick_unique']=df['text'].apply(lambda x : pick_unique_sentence(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4.26\"></a>\n",
    "<font size=\"+2\" color=\"indigo\"><b>4.26 Caps Words</b></font><br><br>\n",
    "Extract words starting with capital letter.Some words like names,place or universal object are usually mentioned in a text starting with CAPS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_capital(text):\n",
    "    line=re.findall(r'\\b[A-Z]\\w+', text)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['World', 'No', 'God']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence=\"World is affected by corona crisis.No one other than God can save us from it\"\n",
    "find_capital(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['caps_word']=df['text'].apply(lambda x : find_capital(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4.27\"></a>\n",
    "<font size=\"+2\" color=\"indigo\"><b>4.27 Length of words</b></font><br><br>\n",
    "No regex but added one liner to identify length of words in a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2977</th>\n",
       "      <td>hoping i didn`t fail english. that would just ...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>cooking with my dad  having lots of fun in the...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2254</th>\n",
       "      <td>Feeling good about our win! Its nice being sof...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  text_length\n",
       "2977  hoping i didn`t fail english. that would just ...           10\n",
       "464   cooking with my dad  having lots of fun in the...           12\n",
       "2254  Feeling good about our win! Its nice being sof...           14"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text_length']=df['text'].str.split().map(lambda x: len(x))\n",
    "df[['text','text_length']].sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4.28\"></a>\n",
    "<font size=\"+2\" color=\"indigo\"><b>4.28 Length of characters</b></font><br><br>\n",
    "No regex but added one liner to identify length of characters in a sentence including space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>char_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23144</th>\n",
       "      <td>oh no! Poor thing keep us posted.</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3381</th>\n",
       "      <td>hold on to what you`ve got</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12731</th>\n",
       "      <td>_sb I swear mine was evil  it was green and ev...</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  char_length\n",
       "23144                  oh no! Poor thing keep us posted.           34\n",
       "3381                          hold on to what you`ve got           26\n",
       "12731  _sb I swear mine was evil  it was green and ev...           58"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['char_length']=df['text'].str.len()\n",
    "df[['text','char_length']].sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4.29\"></a>\n",
    "<font size=\"+2\" color=\"indigo\"><b>4.29 Get ID</b></font><br><br>\n",
    "Most data has IDs in it with some prefix.So if we want to pick only numbers in ID leaving the prefix out,we can apply below function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_id(text):\n",
    "    line=re.findall(r'\\bIND(\\d+)', text)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['50120']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence=\"My company id is IND50120.And I work under Asia region\"\n",
    "find_id(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['get_id']=df['text'].apply(lambda x : find_id(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4.30\"></a>\n",
    "<font size=\"+2\" color=\"indigo\"><b>4.30 Specific String Rows</b></font><br><br>\n",
    "Quering for specific string can also be done by directly applying *\"str.contains(\"XXXX\")\"* to a series/column of a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10835</th>\n",
       "      <td>mint choc ice cream whilst studying.....now th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2228</th>\n",
       "      <td>ooh good then  Thank you for the heads up bro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3358</th>\n",
       "      <td>Listening to Metal Shop at Mooneys!! All is good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "10835  mint choc ice cream whilst studying.....now th...\n",
       "2228       ooh good then  Thank you for the heads up bro\n",
       "3358    Listening to Metal Shop at Mooneys!! All is good"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_string_rows = df[df['text'].str.contains(\"good\")]\n",
    "my_string_rows[['text']].sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4.31\"></a>\n",
    "<font size=\"+2\" color=\"indigo\"><b>4.31 Hex code to Color</b></font><br><br>\n",
    "Converting hex color codes to color names.We will install and import webcolors. (only for CSS3 colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting webcolors\r\n",
      "  Downloading webcolors-1.11.1-py3-none-any.whl (9.9 kB)\r\n",
      "Installing collected packages: webcolors\r\n",
      "Successfully installed webcolors-1.11.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install webcolors\n",
    "import webcolors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_color(string): \n",
    "    text = re.findall('\\#(?:[0-9a-fA-F]{3}){1,2}',string)\n",
    "    conv_name=[]\n",
    "    for i in text:\n",
    "        conv_name.append(webcolors.hex_to_name(i))\n",
    "    return conv_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lime', 'orangered']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence=\"Find the color of #00FF00 and #FF4500\"\n",
    "find_color(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try more hex codes:https://www.rapidtables.com/web/css/css-color.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4.32\"></a>\n",
    "<font size=\"+2\" color=\"indigo\"><b>4.32 Tags</b></font><br><br>\n",
    "Most of web scrapped data contains html tags.It can be removed from below re script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tag(string):\n",
    "    text=re.sub('<.*?>','',string)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Markdown sentences can use  for breaks and  for italics'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence=\"Markdown sentences can use <br> for breaks and <i></i> for italics\"\n",
    "remove_tag(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4.33\"></a>\n",
    "<font size=\"+2\" color=\"indigo\"><b>4.33 IP Address</b></font><br><br>\n",
    "Extract IP address from text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ip_add(string):\n",
    "    text=re.findall('\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}',string)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['125.16.100.1']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence=\"An example of ip address is 125.16.100.1\"\n",
    "ip_add(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4.34\"></a>\n",
    "<font size=\"+2\" color=\"indigo\"><b>4.34 Mac Address</b></font><br><br>\n",
    "Extract Mac address from text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mac_add(string):\n",
    "    text=re.findall('(?:[0-9a-fA-F]:?){12}',string)\n",
    "    return text\n",
    "#https://stackoverflow.com/questions/26891833/python-regex-extract-mac-addresses-from-string/26892371"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00:24:17:b1:cc:cc']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence=\"MAC ADDRESSES of this laptop - 00:24:17:b1:cc:cc .Other details will be mentioned\"\n",
    "mac_add(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4.35\"></a>\n",
    "<font size=\"+2\" color=\"indigo\"><b>4.35 Subword</b></font><br><br>\n",
    "Extract number of subwords from sentences and words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subword(string,sub): \n",
    "    text=re.findall(sub,string)\n",
    "    return len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'Fundamentalism and constructivism are important skills'\n",
    "subword(sentence,'ism') # change subword and try for others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4.36\"></a>\n",
    "<font size=\"+2\" color=\"indigo\"><b>4.36 Latitude & Longitude</b></font><br><br>\n",
    "Extract number of subwords from sentences and words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lat_lon(string):\n",
    "    text=re.findall(r'^[-+]?([1-8]?\\d(\\.\\d+)?|90(\\.0+)?),\\s*[-+]?(180(\\.0+)?|((1[0-7]\\d)|([1-9]?\\d))(\\.\\d+)?)$',string)\n",
    "    if text!=[]:\n",
    "        print(\"[{}] is valid latitude & longitude\".format(string))\n",
    "    else:\n",
    "        print(\"[{}] is not a valid latitude & longitude\".format(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28.6466772,76.8130649] is valid latitude & longitude\n",
      "[2324.3244,3423.432423] is not a valid latitude & longitude\n"
     ]
    }
   ],
   "source": [
    "lat_lon('28.6466772,76.8130649')\n",
    "lat_lon('2324.3244,3423.432423')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4.37\"></a>\n",
    "<font size=\"+2\" color=\"indigo\"><b>4.37 PAN</b></font><br><br>\n",
    "\n",
    "PAN Validation:\n",
    "\n",
    "[First 5 letters in CAPS+4 didgits+Last letter in CAPS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_pan(string):\n",
    "    text=re.findall(r'^([A-Z]){5}([0-9]){4}([A-Z]){1}$',string)\n",
    "    if text!=[]:\n",
    "        print(\"{} is valid PAN number\".format(string))\n",
    "    else:\n",
    "        print(\"{} is not a valid PAN number\".format(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABCSD0123K is valid PAN number\n",
      "LEcGD012eg is not a valid PAN number\n"
     ]
    }
   ],
   "source": [
    "valid_pan(\"ABCSD0123K\")\n",
    "valid_pan(\"LEcGD012eg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4.38\"></a>\n",
    "<font size=\"+2\" color=\"indigo\"><b>4.38 Phone number Code</b></font><br><br>\n",
    "**Format**: [Country code]-[Local Area Code]-[Number]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_phone_code(string):\n",
    "    text=re.findall(r'^([0-9]){2}(-)([0-9]){2}(-)(\\d+)$',string)\n",
    "    if text!=[]:\n",
    "        print(\"{} is valid Indian Phone number wth country code\".format(string))\n",
    "    else:\n",
    "        print(\"{} is not a valid Indian Phone number wth country code\".format(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91-44-23413627 is valid Indian Phone number wth country code\n",
      "291-4456-23413627 is not a valid Indian Phone number wth country code\n"
     ]
    }
   ],
   "source": [
    "valid_phone_code('91-44-23413627')\n",
    "valid_phone_code('291-4456-23413627')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4.39\"></a>\n",
    "<font size=\"+2\" color=\"indigo\"><b>4.39 Positive Look Ahead</b></font><br><br>\n",
    "Positive look ahead will succeed if passed non-consuming expression **does match** against the forthcoming input.<br>\n",
    "The syntax is <code>A(?=B)</code> where <code>A</code> is actual expression and <code>B</code> is non-consuming expression.\n",
    "\n",
    "Scripts utlized from [here](https://github.com/nikhilkumarsingh/RegEx-In-Python/blob/master/16.%20Look%20ahead.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_look_ahead(string,A,B):\n",
    "    pattern = re.compile(''+A+'(?=\\s'+B+')')\n",
    "    match = pattern.search(string)\n",
    "    print(\"position:{} Matched word:{}\".format(match.span(),match.group()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position:(17, 21) Matched word:love\n"
     ]
    }
   ],
   "source": [
    "pos_look_ahead(\"I love kaggle. I love DL\",\"love\",\"DL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4.40\"></a>\n",
    "<font size=\"+2\" color=\"indigo\"><b>4.40 Negative Look Ahead</b></font><br><br>\n",
    "Negative look ahead will succeed if passed non-consuming expression **does not match** against the forthcoming input.<br>\n",
    "The syntax is <code>A(?!B)</code> where <code>A</code> is actual expression and <code>B</code> is non-consuming expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_look_ahead(string,A,B):\n",
    "    pattern = re.compile(''+A+'(?!\\s'+B+')')\n",
    "    match = pattern.search(string)\n",
    "    print(\"position:{} Matched word:{}\".format(match.span(),match.group()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position:(2, 6) Matched word:love\n"
     ]
    }
   ],
   "source": [
    "neg_look_ahead(\"I love kaggle. I love DL\",\"love\",\"DL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4.41\"></a>\n",
    "<font size=\"+2\" color=\"indigo\"><b>4.41 Positive Look Behind</b></font><br><br>\n",
    "Positive look behind will succeed if passed non-consuming expression **does match** against the forthcoming input.<br>\n",
    "The syntax is <code>A(?<=B)</code> where <code>A</code> is actual expression and <code>B</code> is non-consuming expression.\n",
    "    \n",
    "Scripts utilized from [here](https://github.com/nikhilkumarsingh/RegEx-In-Python/blob/master/17.%20Look%20behind.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_look_behind(string,A,B):\n",
    "    pattern = re.compile(\"(?<=\"+A+\"\\s)\"+B+\"\")\n",
    "    match = pattern.search(string)\n",
    "    print(\"position:{} Matched word: {}\".format(match.span(),match.group()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position:(7, 10) Matched word: nlp\n"
     ]
    }
   ],
   "source": [
    "pos_look_behind(\"i love nlp.everyone likes nlp\",\"love\",\"nlp\")\n",
    "# the word \"nlp\" that do come after \"love\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4.42\"></a>\n",
    "<font size=\"+2\" color=\"indigo\"><b>4.42 Negative Look Behind</b></font><br><br>\n",
    "Positive look behind will succeed if passed non-consuming expression **does not match** against the forthcoming input.<br>\n",
    "The syntax is \"A(?<!=B)\" where \"A\"is actual expression and \"B\" is non-consuming expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_look_behind(string,A,B):\n",
    "    pattern = re.compile(\"(?<!\"+A+\"\\s)\"+B+\"\")\n",
    "    match = pattern.search(string)\n",
    "    print(\"position:{} Matched word: {}\".format(match.span(),match.group()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position:(26, 29) Matched word: nlp\n"
     ]
    }
   ],
   "source": [
    "neg_look_behind(\"i love nlp.everyone likes nlp\",\"love\",\"nlp\")\n",
    "# the word \"nlp\" that doesnt come after \"love\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4.43\"></a>\n",
    "<font size=\"+2\" color=\"indigo\"><b>4.43 Domain</b></font><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_domain(string): \n",
    "    text = re.findall(r'\\b(\\w+[.]\\w+)',string)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['who.int', 'unicef.org']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence=\"WHO provides valid information about covid in their site who.int . UNICEF supports disadvantageous childrens. know more in unicef.org\"\n",
    "find_domain(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4.44\"></a>\n",
    "<font size=\"+2\" color=\"indigo\"><b>4.44 Percentage</b></font><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_percent(string): \n",
    "    text = re.findall(r'\\b(100|[1-9][0-9]|[0-9])\\%',string)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['76', '2', '3']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence=\"COVID recovery rate has been increased to 76%.And death rate drops to 2% from 3%\"\n",
    "find_percent(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4.45\"></a>\n",
    "<font size=\"+2\" color=\"indigo\"><b>4.45 File Format</b></font><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_files(string): \n",
    "    text=re.findall(r'([a-zA-Z0-9_]+)\\.(jpg|png|gif|jpeg|pdf|ipynb|py)',string) # add any required file extensions\n",
    "    all_files=[]\n",
    "    for i in range(len(text)):\n",
    "        all_files.append('.'.join(text[i]))\n",
    "    return all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cheatsheet_text_helper.ipynb', 'Titanic.py']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence=\"This notebook file name is cheatsheet_text_helper.ipynb . Titanic.py file is most common among kaggle.\"\n",
    "find_files(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Data with new Features*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>url</th>\n",
       "      <th>emoji</th>\n",
       "      <th>email</th>\n",
       "      <th>hash</th>\n",
       "      <th>at_mention</th>\n",
       "      <th>number</th>\n",
       "      <th>...</th>\n",
       "      <th>only_words</th>\n",
       "      <th>only_num</th>\n",
       "      <th>bound</th>\n",
       "      <th>search_day</th>\n",
       "      <th>pick_senence</th>\n",
       "      <th>pick_unique</th>\n",
       "      <th>caps_word</th>\n",
       "      <th>text_length</th>\n",
       "      <th>char_length</th>\n",
       "      <th>get_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22116</th>\n",
       "      <td>e21e4b55e8</td>\n",
       "      <td>Dave i ask you for 'The Fix' by JK!!! and sen...</td>\n",
       "      <td>Dave i ask you for 'The Fix' by JK!!! and send...</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>Dave i ask you for The Fix by JK and send HI t...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ Dave i ask you for 'The Fix' by JK!!! and se...</td>\n",
       "      <td>[Dave, The, Fix, JK, HI, Lisette, Alejandra, M...</td>\n",
       "      <td>23</td>\n",
       "      <td>109</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>fa1385e537</td>\n",
       "      <td>He says he feels mama tucking him in at night...</td>\n",
       "      <td>. Tomorrow will be tough!</td>\n",
       "      <td>negative</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>He says he feels mama tucking him in at night ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ He says he feels mama tucking him in at nigh...</td>\n",
       "      <td>[He, He, Tomorrow]</td>\n",
       "      <td>19</td>\n",
       "      <td>99</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>3f81782f0b</td>\n",
       "      <td>going to EK nao... will meet bloggers there in...</td>\n",
       "      <td>going to EK nao... will meet bloggers there in...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>http://plurk.com/p/stnt0</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>going to EK nao will meet bloggers there inste...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[going to EK nao... will meet bloggers there i...</td>\n",
       "      <td>[EK, Makati]</td>\n",
       "      <td>12</td>\n",
       "      <td>87</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27317</th>\n",
       "      <td>45c36b5e05</td>\n",
       "      <td>_Aston Still looking  I filled out quite a few...</td>\n",
       "      <td>_Aston Still looking  I filled out quite a few...</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>_Aston Still looking I filled out quite a few ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[_Aston Still looking  I filled out quite a fe...</td>\n",
       "      <td>[Still]</td>\n",
       "      <td>19</td>\n",
       "      <td>104</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9417</th>\n",
       "      <td>c0bf50f198</td>\n",
       "      <td>. Tickets, i need my tickets, where are my tic...</td>\n",
       "      <td>. Tickets, i need my tickets, where are my tic...</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>Tickets i need my tickets where are my tickets...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[. Tickets, i need my tickets, where are my ti...</td>\n",
       "      <td>[Tickets]</td>\n",
       "      <td>14</td>\n",
       "      <td>74</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           textID                                               text  \\\n",
       "22116  e21e4b55e8   Dave i ask you for 'The Fix' by JK!!! and sen...   \n",
       "517    fa1385e537   He says he feels mama tucking him in at night...   \n",
       "1635   3f81782f0b  going to EK nao... will meet bloggers there in...   \n",
       "27317  45c36b5e05  _Aston Still looking  I filled out quite a few...   \n",
       "9417   c0bf50f198  . Tickets, i need my tickets, where are my tic...   \n",
       "\n",
       "                                           selected_text sentiment  \\\n",
       "22116  Dave i ask you for 'The Fix' by JK!!! and send...   neutral   \n",
       "517                            . Tomorrow will be tough!  negative   \n",
       "1635   going to EK nao... will meet bloggers there in...   neutral   \n",
       "27317  _Aston Still looking  I filled out quite a few...   neutral   \n",
       "9417   . Tickets, i need my tickets, where are my tic...   neutral   \n",
       "\n",
       "                            url emoji email hash at_mention number  ...  \\\n",
       "22116                              []                               ...   \n",
       "517                                []                               ...   \n",
       "1635   http://plurk.com/p/stnt0    []                            0  ...   \n",
       "27317                              []                               ...   \n",
       "9417                               []                               ...   \n",
       "\n",
       "                                              only_words only_num bound  \\\n",
       "22116  Dave i ask you for The Fix by JK and send HI t...                  \n",
       "517    He says he feels mama tucking him in at night ...                  \n",
       "1635   going to EK nao will meet bloggers there inste...                  \n",
       "27317  _Aston Still looking I filled out quite a few ...                  \n",
       "9417   Tickets i need my tickets where are my tickets...                  \n",
       "\n",
       "      search_day pick_senence  \\\n",
       "22116      False           []   \n",
       "517        False           []   \n",
       "1635       False           []   \n",
       "27317      False           []   \n",
       "9417       False           []   \n",
       "\n",
       "                                             pick_unique  \\\n",
       "22116  [ Dave i ask you for 'The Fix' by JK!!! and se...   \n",
       "517    [ He says he feels mama tucking him in at nigh...   \n",
       "1635   [going to EK nao... will meet bloggers there i...   \n",
       "27317  [_Aston Still looking  I filled out quite a fe...   \n",
       "9417   [. Tickets, i need my tickets, where are my ti...   \n",
       "\n",
       "                                               caps_word text_length  \\\n",
       "22116  [Dave, The, Fix, JK, HI, Lisette, Alejandra, M...          23   \n",
       "517                                   [He, He, Tomorrow]          19   \n",
       "1635                                        [EK, Makati]          12   \n",
       "27317                                            [Still]          19   \n",
       "9417                                           [Tickets]          14   \n",
       "\n",
       "      char_length get_id  \n",
       "22116         109     []  \n",
       "517            99     []  \n",
       "1635           87     []  \n",
       "27317         104     []  \n",
       "9417           74     []  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)\n",
    "# We will see empty values too as most of text may not have related feature.You can filter and check."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+3\" color=\"blue\"><b>5. End Notes</b></font><br> <a id=\"5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No worries.This is not the end of kernel.**I have updated this kernel with few more functions (Now version 27 is live)**.Going forward i will add more helper functions in upcoming versions.I would like to get appreciation from you with an 👍 .Please <font size=\"+1\" color=\"red\"><b>Upvote</b></font> and keep it in your favourite list.\n",
    "\n",
    "Thanks for your patience.\n",
    "\n",
    "\n",
    "*Happy Kaggling!!!*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+2\" color=\"chocolate\"><b>My Other Kernels</b></font><br>\n",
    "\n",
    "Click on the button to view kernels...\n",
    "\n",
    "<a href=\"https://www.kaggle.com/raenish/healthcare-eda-altair-interactive-plots\" class=\"btn btn-primary\" style=\"color:white;\">Healthcare - Altair Plots</a>\n",
    "\n",
    "<a href=\"https://www.kaggle.com/raenish/covid19-tweets-interactive-eda\" class=\"btn btn-primary\" style=\"color:white;\">COVID19 Tweets EDA</a>\n",
    "\n",
    "<a href=\"https://www.kaggle.com/raenish/kaggle-notebooks-eda\" class=\"btn btn-primary\" style=\"color:white;\">Kaggle Notebooks EDA</a>\n",
    "\n",
    "<a href=\"https://www.kaggle.com/raenish/kaggle-users-competitions-stats-eda/\" class=\"btn btn-primary\" style=\"color:white;\">Kaggle Users & Competition EDA</a>\n",
    "\n",
    "<a href=\"https://www.kaggle.com/raenish/covid19-tweets-interactive-eda\" class=\"btn btn-primary\" style=\"color:white;\">#COVID Tweets</a>\n",
    "\n",
    "<a href=\"https://www.kaggle.com/raenish/self-evaluation-kaggle-profiler\" class=\"btn btn-primary\" style=\"color:white;\">Kaggle Profiler</a>\n",
    "\n",
    "<a href=\"https://www.kaggle.com/raenish/cheatsheet-100-plotly-part-1-basic\" class=\"btn btn-primary\" style=\"color:white;\">100+ Plotly Basic</a>\n",
    "\n",
    "<a href=\"https://www.kaggle.com/raenish/cheatsheet-100-plotly-part-2-advanced\" class=\"btn btn-primary\" style=\"color:white;\">100+ Plotly Advanced</a>\n",
    "\n",
    "<a href=\"https://www.kaggle.com/raenish/don-t-shoot/\" class=\"btn btn-primary\" style=\"color:white;\">Don't Shoot</a>\n",
    "\n",
    "<a href=\"https://www.kaggle.com/raenish/become-grandmaster/\" class=\"btn btn-primary\" style=\"color:white;\">Become GrandMaster</a>\n",
    "\n",
    "<a href=\"https://www.kaggle.com/raenish/cheatsheet-date-helpers/\" class=\"btn btn-primary\" style=\"color:white;\">Cheatsheet Date Helpers</a>\n",
    "\n",
    "<a href=\"https://www.kaggle.com/raenish/tweet-sentiment-insight-eda/\" class=\"btn btn-primary\" style=\"color:white;\">Tweet Sentiment Extraction</a>\n",
    "<br>\n",
    "<br>\n",
    "### If these kernels impress you,give them an <font size=\"+2\" color=\"red\"><b>Upvote</b></font>.<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+2\" color=\"chocolate\"><b>Reference</b></font><br>\n",
    "* https://www.guru99.com/python-regular-expressions-complete-tutorial.html\n",
    "* https://docs.python.org/3.4/library/re.html\n",
    "* https://www3.ntu.edu.sg/home/ehchua/programming/howto/Regexe.html#zz-1.9\n",
    "* https://www.debuggex.com/cheatsheet/regex/python\n",
    "* https://blog.finxter.com/python-regex-and-operator-tutorial-video/\n",
    "* https://www.oreilly.com/library/view/regular-expressions-cookbook/9781449327453/ch04s04.html\n",
    "* https://www.webfx.com/tools/emoji-cheat-sheet/\n",
    "* https://github.com/nikhilkumarsingh/RegEx-In-Python/blob/master/17.%20Look%20behind.ipynb\n",
    "* https://github.com/nikhilkumarsingh/RegEx-In-Python/blob/master/16.%20Look%20ahead.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Version 28** : <font size=\"+3\" color=\"red\"><b><i>Loading...</i></b></font><br><br>\n",
    "<a href=\"#top\" class=\"btn btn-success btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"go to Colors\">Go to TOP</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
