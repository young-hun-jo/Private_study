<Week 2>
Bag-of-Words : 해당 단어가 있음을 나타내는 one-hot vector를 합하(?)여 단어의 빈도수에 따라 만든 column vector(N1 matrix)
N-gram : 연속된 단어N개 뭉치, machine learning처럼 phrase도 고려할 수 있음. ex) 번역 모델링 성능 평가때도 사용..
Tf-idf : Tf: : 문서(문장)에서 나오는 특정 단어 횟수 / idf : 특정 단어가 들어가는 문서(문장)가 등장하는 총 개수
# 불용어(stopwords)를 처리하기 위해서 documnet frequency(df)에 inverse를 시켜주어서 상대적으로 중요도를 낮추어 계산해줌!

<Week3>
#주제 : 벡터개념과 벡터간의 비슷함과 다름을 결정하는 기준인 거리를 계산하는 방식을 알아보자
- scalar = 숫자
- vector = 방향+숫자
- vector는 N차원 공간에 사는 존재
(보통 4차원이상의 공간은 사람의 눈으로 볼 수 있게 표현을 불가능)
- 예를들어 한 사람의 특징5가지(성별,키,몸무게,나이,연차)을 5차원의 벡터로 표현한다면 [1,181,79,26,0] 로 표현가능(물론 여기서 [1,181,79,26,0]은 열 벡터(column vector)로 표현해야 함)
- 다음 포스팅 주제는 '단어를 다른 방식의 벡터로 표현하는 word embedding' 에 대해 다룰 예정

<Week4>
Word embedding : 단어간의 관계를 학습해 vector에 저장하는 모델 ->일종의 unsupervised learning방식이며 단어는 주변단어들에 의해 정의된다는 'Distributional 가설'에 기반.

Word embedding의 종류
1. GloVe : 같은 문장에 한 단어가 어떤 근처 단어들과 몇 번 같이 나오는지 세보는 것(co-occurence matrix를 만듬) ->그런데 단어가 많아지면서 이 Matrix크기가 엄청 커져버리는데 이 때 SVD알고리즘을 사용하면서 Matrix의 차원을 축소시킴

2.word2vec : 기본적으로 neural network를 사용한 분류문제 해결을 기반으로 하여 단어간의 관계를 파악. 구체적으로 다음과 같은 두 가지 알고리즘을 사용함.
-CBOW(Continuous bag of words) : 주변 단어들을 모두 합쳐서 이를 바탕으로 타겟 단어를 맞추는 방법
-Skipgram : 타겟 단어를 보고 주변 단어를 맞추기(CBOW와는 반대방식 느낌!)

#참고로 corpus로 단어간의 관계들을 파악한 후의 워드 임베딩을 다른 NLP task의 input으로 사용하면 엄청난 성능 증가를 기대할 수 있음.

<Week5>
*BOW나 td-idf는 단어 출현의 빈도수를 계산하는 방법
*저번시간에 배운 word 임베딩은 단어들간의 관계를 파악하는 방법

그렇다면 이 단어들간의 관계 즉, 거리를 계산하는 방법는 단어 vector들 사이의 거리를 계산하는 것. 유클리디안 distance를 구하는 계산방법을 이용할 수 있다. 그런데 NLP문제에서 단어 빈도수를 계산하는 문제가 대부분이다. 예를들어 하나의 문서에 bank단어가 100번 등장한 것이랑 다른 하나의 문서에 bank단어가 10번 등장한 것이랑 주제는 '은행'관련될 것임을 알 수 있다. 즉, 빈도수가 크게 상관이 없어지기 때문에 벡터의 각도를 계산하는 Cosine Similartiy를 사용!

1.Cosine Similarity는 벡터의 크기(길이)는 무시하고 방향의 차이만 계산하기 때문에 크기 즉, 빈도수에 신경을 쓰지 않는다 라기보다는 절대 값이 아닌 상대값을 보는 것!
*Cosine Similarity 수식을 이해하면
-같은 방향(0도)이라면 1
-완전히 반대방향(180도)이라면 -1
-서로 독립적(90도)이면 0

2. Cosine Distance개념도 있는데 Cosine Distance = 1-Cosine Similarity이다. 따라서 Cosine Distance를 이해하면
-같은 방향(0도)면 0
-완전히 반대방향(180도)이면 2
-서로 독립적(90도)이면 1
-skipgram알고리즘으로 학습이 된 word2vec들 사이의 거리를 계산할 때 사용! 즉, 단어 vectors간의 유사성을 계산하는 데 사용

