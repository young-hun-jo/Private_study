{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-2-c1b08f74be9c>:73: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-2-c1b08f74be9c>:77: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /Users/younghun/opt/anaconda3/envs/venvforpython/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/younghun/opt/anaconda3/envs/venvforpython/lib/python3.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py:459: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x7f85f5258650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x7f85f5258650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x7f85f5258650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x7f85f5258650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f85f855b190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f85f855b190>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f85f855b190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f85f855b190>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "Epoch0번일 때, Cost:47.349\n",
      "Epoch100번일 때, Cost:0.775\n",
      "Epoch200번일 때, Cost:0.707\n",
      "Epoch300번일 때, Cost:0.672\n",
      "Epoch400번일 때, Cost:0.653\n",
      "Epoch500번일 때, Cost:0.638\n",
      "Epoch600번일 때, Cost:0.623\n",
      "Epoch700번일 때, Cost:0.610\n",
      "Epoch800번일 때, Cost:0.600\n",
      "Epoch900번일 때, Cost:0.589\n",
      "Epoch1000번일 때, Cost:0.589\n",
      "Epoch1100번일 때, Cost:0.572\n",
      "Epoch1200번일 때, Cost:0.565\n",
      "Epoch1300번일 때, Cost:0.559\n",
      "Epoch1400번일 때, Cost:0.735\n",
      "Epoch1500번일 때, Cost:0.547\n",
      "Epoch1600번일 때, Cost:0.541\n",
      "Epoch1700번일 때, Cost:0.529\n",
      "Epoch1800번일 때, Cost:0.519\n",
      "Epoch1900번일 때, Cost:0.560\n",
      "Epoch2000번일 때, Cost:0.509\n",
      "Epoch2100번일 때, Cost:0.490\n",
      "Epoch2200번일 때, Cost:0.481\n",
      "Epoch2300번일 때, Cost:0.473\n",
      "Epoch2400번일 때, Cost:0.464\n",
      "Epoch2500번일 때, Cost:0.471\n",
      "Epoch2600번일 때, Cost:0.451\n",
      "Epoch2700번일 때, Cost:0.447\n",
      "Epoch2800번일 때, Cost:0.444\n",
      "Epoch2900번일 때, Cost:0.441\n",
      "Epoch3000번일 때, Cost:0.443\n",
      "Epoch3100번일 때, Cost:0.437\n",
      "Epoch3200번일 때, Cost:0.432\n",
      "Epoch3300번일 때, Cost:0.470\n",
      "Epoch3400번일 때, Cost:0.462\n",
      "Epoch3500번일 때, Cost:0.525\n",
      "Epoch3600번일 때, Cost:0.431\n",
      "Epoch3700번일 때, Cost:0.410\n",
      "Epoch3800번일 때, Cost:0.406\n",
      "Epoch3900번일 때, Cost:0.402\n",
      "Epoch4000번일 때, Cost:0.400\n",
      "Epoch4100번일 때, Cost:0.396\n",
      "Epoch4200번일 때, Cost:0.530\n",
      "Epoch4300번일 때, Cost:0.480\n",
      "Epoch4400번일 때, Cost:0.387\n",
      "Epoch4500번일 때, Cost:0.385\n",
      "Epoch4600번일 때, Cost:0.384\n",
      "Epoch4700번일 때, Cost:0.620\n",
      "Epoch4800번일 때, Cost:0.379\n",
      "Epoch4900번일 때, Cost:0.389\n",
      "Epoch5000번일 때, Cost:0.375\n",
      "Epoch5100번일 때, Cost:0.374\n",
      "Epoch5200번일 때, Cost:0.372\n",
      "Epoch5300번일 때, Cost:0.369\n",
      "Epoch5400번일 때, Cost:0.384\n",
      "Epoch5500번일 때, Cost:0.366\n",
      "Epoch5600번일 때, Cost:0.363\n",
      "Epoch5700번일 때, Cost:0.366\n",
      "Epoch5800번일 때, Cost:0.360\n",
      "Epoch5900번일 때, Cost:0.418\n",
      "Epoch6000번일 때, Cost:0.356\n",
      "Epoch6100번일 때, Cost:0.355\n",
      "Epoch6200번일 때, Cost:0.354\n",
      "Epoch6300번일 때, Cost:0.358\n",
      "Epoch6400번일 때, Cost:0.378\n",
      "Epoch6500번일 때, Cost:0.352\n",
      "Epoch6600번일 때, Cost:0.357\n",
      "Epoch6700번일 때, Cost:0.350\n",
      "Epoch6800번일 때, Cost:0.341\n",
      "Epoch6900번일 때, Cost:0.351\n",
      "Epoch7000번일 때, Cost:0.334\n",
      "Epoch7100번일 때, Cost:0.328\n",
      "Epoch7200번일 때, Cost:0.326\n",
      "Epoch7300번일 때, Cost:0.447\n",
      "Epoch7400번일 때, Cost:0.318\n",
      "Epoch7500번일 때, Cost:0.914\n",
      "Epoch7600번일 때, Cost:0.313\n",
      "Epoch7700번일 때, Cost:0.308\n",
      "Epoch7800번일 때, Cost:0.308\n",
      "Epoch7900번일 때, Cost:0.304\n",
      "Epoch8000번일 때, Cost:0.306\n",
      "Epoch8100번일 때, Cost:0.301\n",
      "Epoch8200번일 때, Cost:0.297\n",
      "Epoch8300번일 때, Cost:0.297\n",
      "Epoch8400번일 때, Cost:0.293\n",
      "Epoch8500번일 때, Cost:0.308\n",
      "Epoch8600번일 때, Cost:0.290\n",
      "Epoch8700번일 때, Cost:0.287\n",
      "Epoch8800번일 때, Cost:0.291\n",
      "Epoch8900번일 때, Cost:0.283\n",
      "Epoch9000번일 때, Cost:0.297\n",
      "Epoch9100번일 때, Cost:0.279\n",
      "Epoch9200번일 때, Cost:0.282\n",
      "Epoch9300번일 때, Cost:0.276\n",
      "Epoch9400번일 때, Cost:0.274\n",
      "Epoch9500번일 때, Cost:0.273\n",
      "Epoch9600번일 때, Cost:0.272\n",
      "Epoch9700번일 때, Cost:0.273\n",
      "Epoch9800번일 때, Cost:0.268\n",
      "Epoch9900번일 때, Cost:0.288\n",
      "Epoch10000번일 때, Cost:0.277\n",
      "---------- Learning finished ----------\n",
      "[[0.7552072  0.7630278 ]\n",
      " [0.7496065  0.74268305]\n",
      " [0.81722724 0.79763734]\n",
      " [0.76388466 0.756567  ]\n",
      " [0.59186065 0.5839708 ]\n",
      " [0.64043033 0.6695039 ]\n",
      " [0.610175   0.6352433 ]\n",
      " [0.59399486 0.60120547]\n",
      " [0.60862446 0.62464786]\n",
      " [0.6356683  0.64649737]\n",
      " [0.68328905 0.697801  ]\n",
      " [0.6578537  0.6761106 ]\n",
      " [0.6494802  0.66244686]\n",
      " [0.63914394 0.65322614]\n",
      " [0.6494825  0.6627151 ]\n",
      " [0.66778994 0.6835476 ]\n",
      " [0.68576944 0.70046306]\n",
      " [0.73174953 0.7300217 ]\n",
      " [0.6925622  0.7075889 ]\n",
      " [0.69231164 0.7157328 ]\n",
      " [0.69295263 0.7019423 ]\n",
      " [0.6939745  0.72194135]\n",
      " [0.6935514  0.71303546]\n",
      " [0.6692443  0.6897192 ]\n",
      " [0.6085024  0.61302817]\n",
      " [0.60013056 0.61909366]\n",
      " [0.5598706  0.5551022 ]\n",
      " [0.5548071  0.5735997 ]\n",
      " [0.5760323  0.5870888 ]\n",
      " [0.5927725  0.606596  ]\n",
      " [0.6056653  0.6279019 ]\n",
      " [0.65279746 0.66677487]\n",
      " [0.6871115  0.70965874]\n",
      " [0.71281874 0.7358875 ]\n",
      " [0.730904   0.7445836 ]\n",
      " [0.76550114 0.77455854]\n",
      " [0.7662226  0.7754766 ]\n",
      " [0.7534132  0.7596766 ]\n",
      " [0.8374182  0.797456  ]\n",
      " [0.79024327 0.7747693 ]\n",
      " [0.7856877  0.76592803]\n",
      " [0.7502419  0.70685697]\n",
      " [0.80531883 0.75957286]\n",
      " [0.8344567  0.79531884]\n",
      " [0.8174232  0.79174495]\n",
      " [0.8265296  0.80218244]\n",
      " [0.8250525  0.8051046 ]\n",
      " [0.81942046 0.80623865]\n",
      " [0.8309809  0.8209646 ]\n",
      " [0.8307811  0.8193495 ]\n",
      " [0.79936504 0.7851403 ]\n",
      " [0.85327864 0.82503426]\n",
      " [0.8352206  0.81758463]\n",
      " [0.78269017 0.76409006]\n",
      " [0.7458043  0.72581506]\n",
      " [0.81617844 0.7956706 ]\n",
      " [0.7609432  0.74007833]\n",
      " [0.87213326 0.83728373]\n",
      " [0.7955241  0.77729046]\n",
      " [0.83616674 0.810693  ]\n",
      " [0.79525626 0.7642845 ]\n",
      " [0.8025975  0.777513  ]\n",
      " [0.79142916 0.75951815]\n",
      " [0.82967997 0.79546916]\n",
      " [0.82325065 0.77990985]\n",
      " [0.80740535 0.7768072 ]\n",
      " [0.88563764 0.8371439 ]\n",
      " [0.8531586  0.8137679 ]\n",
      " [0.91616786 0.86549044]\n",
      " [0.78915155 0.73522365]\n",
      " [0.87521887 0.8419882 ]\n",
      " [0.7414714  0.70472467]\n",
      " [0.7380327  0.72407675]\n",
      " [0.7116474  0.6658069 ]\n",
      " [0.8337821  0.80942667]\n",
      " [0.7480185  0.7148136 ]\n",
      " [0.750306   0.7047657 ]\n",
      " [0.656801   0.62689364]\n",
      " [0.7716731  0.7459065 ]\n",
      " [0.731737   0.7179384 ]\n",
      " [0.8383422  0.8312483 ]\n",
      " [0.77161145 0.78050244]\n",
      " [0.7362094  0.7266364 ]\n",
      " [0.7356132  0.7269199 ]\n",
      " [0.80327964 0.778077  ]\n",
      " [0.88626873 0.8418181 ]\n",
      " [0.85219264 0.8128177 ]\n",
      " [0.84783316 0.8156023 ]\n",
      " [0.7821715  0.7284167 ]\n",
      " [0.80177355 0.7515743 ]\n",
      " [0.80843747 0.765519  ]\n",
      " [0.81684315 0.78095007]\n",
      " [0.8434007  0.7987174 ]\n",
      " [0.8546891  0.8066939 ]\n",
      " [0.88674235 0.82473934]\n",
      " [0.83302724 0.7587389 ]\n",
      " [0.8565067  0.78196156]\n",
      " [0.835325   0.7642019 ]\n",
      " [0.8748733  0.81100845]\n",
      " [0.8847867  0.7943212 ]\n",
      " [0.9572855  0.87248814]\n",
      " [0.8230809  0.7921921 ]\n",
      " [0.7901126  0.74745655]\n",
      " [0.7628962  0.69255805]\n",
      " [0.7937033  0.7264397 ]\n",
      " [0.8382231  0.7647382 ]\n",
      " [0.89150584 0.80216646]\n",
      " [0.8882159  0.8005394 ]]\n",
      "RMSE for Test data: 0.005\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Min-Max scaling\n",
    "def MinMaxScaler(data):\n",
    "    numerator = data - np.min(data, axis=0)\n",
    "    denominator = np.max(data, axis=0) - np.min(data, axis=0)\n",
    "    return numerator / (denominator + 1e-7)\n",
    "\n",
    "# load data\n",
    "stock = np.loadtxt('data-02-stock_daily.csv', delimiter=',')\n",
    "# change time-series order\n",
    "stock = stock[::-1]\n",
    "# applying scaling\n",
    "stock = MinMaxScaler(stock)\n",
    "\n",
    "\n",
    "### Train Parameter ###\n",
    "# input : 7 days\n",
    "seq_length = 7\n",
    "# Feature(including Y)\n",
    "input_units = 5\n",
    "# Hidden units in RNN Cells\n",
    "hidden_units = 10\n",
    "# output : future 2 consecutive days\n",
    "output_units = 2\n",
    "learning_rate = 0.01\n",
    "iterations = 10001\n",
    "\n",
    "# Feature(including 2 pre-order Y variables)\n",
    "x = stock\n",
    "y = stock[:, [-1]]\n",
    "\n",
    "# Build dataset for predicting two-consecutive time-series\n",
    "dataX = []\n",
    "dataY = []\n",
    "cut_num = len(y) // 2\n",
    "\n",
    "# x는 730번 인덱스까지(총 732번 인덱스까지 중)\n",
    "for i in range(0, cut_num):\n",
    "    if i <= 362:\n",
    "        #print(i*2, i*2+seq_length-1)\n",
    "        #print(i*2+seq_length, i*2+seq_length+1)\n",
    "        #print()\n",
    "        _x = x[i*2: i*2+seq_length]\n",
    "        _y = y[i*2+seq_length: i*2+seq_length+2]\n",
    "        dataX.append(_x)\n",
    "        dataY.append(_y)\n",
    "        \n",
    "# split train/test\n",
    "train_size = int(len(dataY) *0.7)\n",
    "test_size = len(dataY) - train_size\n",
    "\n",
    "trainX = np.array(dataX[0:train_size])\n",
    "testX = np.array(dataX[train_size:len(dataX)-1])\n",
    "trainY = np.array(dataY[0:train_size]).reshape(-1,2)\n",
    "testY = np.stack(dataY[train_size:len(dataY)-1]).reshape(-1,2)\n",
    "\n",
    "#print(\"X shape: \", trainX.shape, testX.shape)\n",
    "#print(\"Y shape: \", trainY.shape, testY.shape)\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(123)\n",
    "\n",
    "#### Build Tensor Graph ####\n",
    "X = tf.placeholder(tf.float32, shape=[None, seq_length, input_units])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, output_units])\n",
    "\n",
    "# Basic RNN Cell\n",
    "cell = tf.contrib.rnn.BasicRNNCell(num_units=hidden_units,\n",
    "                                  activation=tf.tanh)\n",
    "\n",
    "# Outputs in RNN Cell(hidden units)\n",
    "outputs_seq, states = tf.nn.dynamic_rnn(cell, inputs=X,\n",
    "                                       dtype=tf.float32)\n",
    "\n",
    "# hidden units -> Output units 로가는 Dense layer\n",
    "Y_pred = tf.contrib.layers.fully_connected(outputs_seq[:,-1],\n",
    "                                          output_units,\n",
    "                                          activation_fn=None)\n",
    "\n",
    "# Cost function - Sum of Squared error\n",
    "cost = tf.reduce_sum(tf.square(Y_pred - Y))\n",
    "\n",
    "# Optimizer\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "#### Run Tensor Graph ####\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # 50번의 Epoch 수행\n",
    "    for i in range(iterations):\n",
    "        _ = sess.run(train, feed_dict={X : trainX,\n",
    "                                      Y: trainY})\n",
    "        if i % 100 == 0:\n",
    "            cost_val = sess.run(cost, feed_dict={X: trainX,\n",
    "                                                Y: trainY})\n",
    "            print(f\"Epoch{i}번일 때, Cost:{cost_val :.3f}\")\n",
    "    print(\"-\"*10,\"Learning finished\",\"-\"*10)\n",
    "    # Test 데이터로 검증 후  Mean of Squared Error 도출\n",
    "    test_predict = sess.run(Y_pred, feed_dict={X: testX})\n",
    "    print(test_predict)\n",
    "    mse = np.mean(np.square(test_predict - testY))\n",
    "    print(f\"RMSE for Test data: {mse :.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 삽질 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-Max scaling\n",
    "def MinMaxScaler(data):\n",
    "    numerator = data - np.min(data, axis=0)\n",
    "    denominator = np.max(data, axis=0) - np.min(data, axis=0)\n",
    "    return numerator / (denominator + 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "stock = np.loadtxt('data-02-stock_daily.csv', delimiter=',')\n",
    "# change time-series order\n",
    "stock = stock[::-1]\n",
    "# applying scaling\n",
    "stock = MinMaxScaler(stock)\n",
    "\n",
    "# Feature(including 2 pre-order Y variables)\n",
    "x = stock\n",
    "y = stock[:, [-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train Parameter ###\n",
    "\n",
    "# input : 7 days\n",
    "seq_length = 7\n",
    "# Feature(including Y)\n",
    "input_units = 5\n",
    "# Hidden units in RNN Cells\n",
    "hidden_units = 10\n",
    "# output : future 2 consecutive days\n",
    "output_units = 2\n",
    "learning_rate = 0.01\n",
    "iterations = 10001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6\n",
      "7 8\n",
      "\n",
      "2 8\n",
      "9 10\n",
      "\n",
      "4 10\n",
      "11 12\n",
      "\n",
      "6 12\n",
      "13 14\n",
      "\n",
      "8 14\n",
      "15 16\n",
      "\n",
      "10 16\n",
      "17 18\n",
      "\n",
      "12 18\n",
      "19 20\n",
      "\n",
      "14 20\n",
      "21 22\n",
      "\n",
      "16 22\n",
      "23 24\n",
      "\n",
      "18 24\n",
      "25 26\n",
      "\n",
      "20 26\n",
      "27 28\n",
      "\n",
      "22 28\n",
      "29 30\n",
      "\n",
      "24 30\n",
      "31 32\n",
      "\n",
      "26 32\n",
      "33 34\n",
      "\n",
      "28 34\n",
      "35 36\n",
      "\n",
      "30 36\n",
      "37 38\n",
      "\n",
      "32 38\n",
      "39 40\n",
      "\n",
      "34 40\n",
      "41 42\n",
      "\n",
      "36 42\n",
      "43 44\n",
      "\n",
      "38 44\n",
      "45 46\n",
      "\n",
      "40 46\n",
      "47 48\n",
      "\n",
      "42 48\n",
      "49 50\n",
      "\n",
      "44 50\n",
      "51 52\n",
      "\n",
      "46 52\n",
      "53 54\n",
      "\n",
      "48 54\n",
      "55 56\n",
      "\n",
      "50 56\n",
      "57 58\n",
      "\n",
      "52 58\n",
      "59 60\n",
      "\n",
      "54 60\n",
      "61 62\n",
      "\n",
      "56 62\n",
      "63 64\n",
      "\n",
      "58 64\n",
      "65 66\n",
      "\n",
      "60 66\n",
      "67 68\n",
      "\n",
      "62 68\n",
      "69 70\n",
      "\n",
      "64 70\n",
      "71 72\n",
      "\n",
      "66 72\n",
      "73 74\n",
      "\n",
      "68 74\n",
      "75 76\n",
      "\n",
      "70 76\n",
      "77 78\n",
      "\n",
      "72 78\n",
      "79 80\n",
      "\n",
      "74 80\n",
      "81 82\n",
      "\n",
      "76 82\n",
      "83 84\n",
      "\n",
      "78 84\n",
      "85 86\n",
      "\n",
      "80 86\n",
      "87 88\n",
      "\n",
      "82 88\n",
      "89 90\n",
      "\n",
      "84 90\n",
      "91 92\n",
      "\n",
      "86 92\n",
      "93 94\n",
      "\n",
      "88 94\n",
      "95 96\n",
      "\n",
      "90 96\n",
      "97 98\n",
      "\n",
      "92 98\n",
      "99 100\n",
      "\n",
      "94 100\n",
      "101 102\n",
      "\n",
      "96 102\n",
      "103 104\n",
      "\n",
      "98 104\n",
      "105 106\n",
      "\n",
      "100 106\n",
      "107 108\n",
      "\n",
      "102 108\n",
      "109 110\n",
      "\n",
      "104 110\n",
      "111 112\n",
      "\n",
      "106 112\n",
      "113 114\n",
      "\n",
      "108 114\n",
      "115 116\n",
      "\n",
      "110 116\n",
      "117 118\n",
      "\n",
      "112 118\n",
      "119 120\n",
      "\n",
      "114 120\n",
      "121 122\n",
      "\n",
      "116 122\n",
      "123 124\n",
      "\n",
      "118 124\n",
      "125 126\n",
      "\n",
      "120 126\n",
      "127 128\n",
      "\n",
      "122 128\n",
      "129 130\n",
      "\n",
      "124 130\n",
      "131 132\n",
      "\n",
      "126 132\n",
      "133 134\n",
      "\n",
      "128 134\n",
      "135 136\n",
      "\n",
      "130 136\n",
      "137 138\n",
      "\n",
      "132 138\n",
      "139 140\n",
      "\n",
      "134 140\n",
      "141 142\n",
      "\n",
      "136 142\n",
      "143 144\n",
      "\n",
      "138 144\n",
      "145 146\n",
      "\n",
      "140 146\n",
      "147 148\n",
      "\n",
      "142 148\n",
      "149 150\n",
      "\n",
      "144 150\n",
      "151 152\n",
      "\n",
      "146 152\n",
      "153 154\n",
      "\n",
      "148 154\n",
      "155 156\n",
      "\n",
      "150 156\n",
      "157 158\n",
      "\n",
      "152 158\n",
      "159 160\n",
      "\n",
      "154 160\n",
      "161 162\n",
      "\n",
      "156 162\n",
      "163 164\n",
      "\n",
      "158 164\n",
      "165 166\n",
      "\n",
      "160 166\n",
      "167 168\n",
      "\n",
      "162 168\n",
      "169 170\n",
      "\n",
      "164 170\n",
      "171 172\n",
      "\n",
      "166 172\n",
      "173 174\n",
      "\n",
      "168 174\n",
      "175 176\n",
      "\n",
      "170 176\n",
      "177 178\n",
      "\n",
      "172 178\n",
      "179 180\n",
      "\n",
      "174 180\n",
      "181 182\n",
      "\n",
      "176 182\n",
      "183 184\n",
      "\n",
      "178 184\n",
      "185 186\n",
      "\n",
      "180 186\n",
      "187 188\n",
      "\n",
      "182 188\n",
      "189 190\n",
      "\n",
      "184 190\n",
      "191 192\n",
      "\n",
      "186 192\n",
      "193 194\n",
      "\n",
      "188 194\n",
      "195 196\n",
      "\n",
      "190 196\n",
      "197 198\n",
      "\n",
      "192 198\n",
      "199 200\n",
      "\n",
      "194 200\n",
      "201 202\n",
      "\n",
      "196 202\n",
      "203 204\n",
      "\n",
      "198 204\n",
      "205 206\n",
      "\n",
      "200 206\n",
      "207 208\n",
      "\n",
      "202 208\n",
      "209 210\n",
      "\n",
      "204 210\n",
      "211 212\n",
      "\n",
      "206 212\n",
      "213 214\n",
      "\n",
      "208 214\n",
      "215 216\n",
      "\n",
      "210 216\n",
      "217 218\n",
      "\n",
      "212 218\n",
      "219 220\n",
      "\n",
      "214 220\n",
      "221 222\n",
      "\n",
      "216 222\n",
      "223 224\n",
      "\n",
      "218 224\n",
      "225 226\n",
      "\n",
      "220 226\n",
      "227 228\n",
      "\n",
      "222 228\n",
      "229 230\n",
      "\n",
      "224 230\n",
      "231 232\n",
      "\n",
      "226 232\n",
      "233 234\n",
      "\n",
      "228 234\n",
      "235 236\n",
      "\n",
      "230 236\n",
      "237 238\n",
      "\n",
      "232 238\n",
      "239 240\n",
      "\n",
      "234 240\n",
      "241 242\n",
      "\n",
      "236 242\n",
      "243 244\n",
      "\n",
      "238 244\n",
      "245 246\n",
      "\n",
      "240 246\n",
      "247 248\n",
      "\n",
      "242 248\n",
      "249 250\n",
      "\n",
      "244 250\n",
      "251 252\n",
      "\n",
      "246 252\n",
      "253 254\n",
      "\n",
      "248 254\n",
      "255 256\n",
      "\n",
      "250 256\n",
      "257 258\n",
      "\n",
      "252 258\n",
      "259 260\n",
      "\n",
      "254 260\n",
      "261 262\n",
      "\n",
      "256 262\n",
      "263 264\n",
      "\n",
      "258 264\n",
      "265 266\n",
      "\n",
      "260 266\n",
      "267 268\n",
      "\n",
      "262 268\n",
      "269 270\n",
      "\n",
      "264 270\n",
      "271 272\n",
      "\n",
      "266 272\n",
      "273 274\n",
      "\n",
      "268 274\n",
      "275 276\n",
      "\n",
      "270 276\n",
      "277 278\n",
      "\n",
      "272 278\n",
      "279 280\n",
      "\n",
      "274 280\n",
      "281 282\n",
      "\n",
      "276 282\n",
      "283 284\n",
      "\n",
      "278 284\n",
      "285 286\n",
      "\n",
      "280 286\n",
      "287 288\n",
      "\n",
      "282 288\n",
      "289 290\n",
      "\n",
      "284 290\n",
      "291 292\n",
      "\n",
      "286 292\n",
      "293 294\n",
      "\n",
      "288 294\n",
      "295 296\n",
      "\n",
      "290 296\n",
      "297 298\n",
      "\n",
      "292 298\n",
      "299 300\n",
      "\n",
      "294 300\n",
      "301 302\n",
      "\n",
      "296 302\n",
      "303 304\n",
      "\n",
      "298 304\n",
      "305 306\n",
      "\n",
      "300 306\n",
      "307 308\n",
      "\n",
      "302 308\n",
      "309 310\n",
      "\n",
      "304 310\n",
      "311 312\n",
      "\n",
      "306 312\n",
      "313 314\n",
      "\n",
      "308 314\n",
      "315 316\n",
      "\n",
      "310 316\n",
      "317 318\n",
      "\n",
      "312 318\n",
      "319 320\n",
      "\n",
      "314 320\n",
      "321 322\n",
      "\n",
      "316 322\n",
      "323 324\n",
      "\n",
      "318 324\n",
      "325 326\n",
      "\n",
      "320 326\n",
      "327 328\n",
      "\n",
      "322 328\n",
      "329 330\n",
      "\n",
      "324 330\n",
      "331 332\n",
      "\n",
      "326 332\n",
      "333 334\n",
      "\n",
      "328 334\n",
      "335 336\n",
      "\n",
      "330 336\n",
      "337 338\n",
      "\n",
      "332 338\n",
      "339 340\n",
      "\n",
      "334 340\n",
      "341 342\n",
      "\n",
      "336 342\n",
      "343 344\n",
      "\n",
      "338 344\n",
      "345 346\n",
      "\n",
      "340 346\n",
      "347 348\n",
      "\n",
      "342 348\n",
      "349 350\n",
      "\n",
      "344 350\n",
      "351 352\n",
      "\n",
      "346 352\n",
      "353 354\n",
      "\n",
      "348 354\n",
      "355 356\n",
      "\n",
      "350 356\n",
      "357 358\n",
      "\n",
      "352 358\n",
      "359 360\n",
      "\n",
      "354 360\n",
      "361 362\n",
      "\n",
      "356 362\n",
      "363 364\n",
      "\n",
      "358 364\n",
      "365 366\n",
      "\n",
      "360 366\n",
      "367 368\n",
      "\n",
      "362 368\n",
      "369 370\n",
      "\n",
      "364 370\n",
      "371 372\n",
      "\n",
      "366 372\n",
      "373 374\n",
      "\n",
      "368 374\n",
      "375 376\n",
      "\n",
      "370 376\n",
      "377 378\n",
      "\n",
      "372 378\n",
      "379 380\n",
      "\n",
      "374 380\n",
      "381 382\n",
      "\n",
      "376 382\n",
      "383 384\n",
      "\n",
      "378 384\n",
      "385 386\n",
      "\n",
      "380 386\n",
      "387 388\n",
      "\n",
      "382 388\n",
      "389 390\n",
      "\n",
      "384 390\n",
      "391 392\n",
      "\n",
      "386 392\n",
      "393 394\n",
      "\n",
      "388 394\n",
      "395 396\n",
      "\n",
      "390 396\n",
      "397 398\n",
      "\n",
      "392 398\n",
      "399 400\n",
      "\n",
      "394 400\n",
      "401 402\n",
      "\n",
      "396 402\n",
      "403 404\n",
      "\n",
      "398 404\n",
      "405 406\n",
      "\n",
      "400 406\n",
      "407 408\n",
      "\n",
      "402 408\n",
      "409 410\n",
      "\n",
      "404 410\n",
      "411 412\n",
      "\n",
      "406 412\n",
      "413 414\n",
      "\n",
      "408 414\n",
      "415 416\n",
      "\n",
      "410 416\n",
      "417 418\n",
      "\n",
      "412 418\n",
      "419 420\n",
      "\n",
      "414 420\n",
      "421 422\n",
      "\n",
      "416 422\n",
      "423 424\n",
      "\n",
      "418 424\n",
      "425 426\n",
      "\n",
      "420 426\n",
      "427 428\n",
      "\n",
      "422 428\n",
      "429 430\n",
      "\n",
      "424 430\n",
      "431 432\n",
      "\n",
      "426 432\n",
      "433 434\n",
      "\n",
      "428 434\n",
      "435 436\n",
      "\n",
      "430 436\n",
      "437 438\n",
      "\n",
      "432 438\n",
      "439 440\n",
      "\n",
      "434 440\n",
      "441 442\n",
      "\n",
      "436 442\n",
      "443 444\n",
      "\n",
      "438 444\n",
      "445 446\n",
      "\n",
      "440 446\n",
      "447 448\n",
      "\n",
      "442 448\n",
      "449 450\n",
      "\n",
      "444 450\n",
      "451 452\n",
      "\n",
      "446 452\n",
      "453 454\n",
      "\n",
      "448 454\n",
      "455 456\n",
      "\n",
      "450 456\n",
      "457 458\n",
      "\n",
      "452 458\n",
      "459 460\n",
      "\n",
      "454 460\n",
      "461 462\n",
      "\n",
      "456 462\n",
      "463 464\n",
      "\n",
      "458 464\n",
      "465 466\n",
      "\n",
      "460 466\n",
      "467 468\n",
      "\n",
      "462 468\n",
      "469 470\n",
      "\n",
      "464 470\n",
      "471 472\n",
      "\n",
      "466 472\n",
      "473 474\n",
      "\n",
      "468 474\n",
      "475 476\n",
      "\n",
      "470 476\n",
      "477 478\n",
      "\n",
      "472 478\n",
      "479 480\n",
      "\n",
      "474 480\n",
      "481 482\n",
      "\n",
      "476 482\n",
      "483 484\n",
      "\n",
      "478 484\n",
      "485 486\n",
      "\n",
      "480 486\n",
      "487 488\n",
      "\n",
      "482 488\n",
      "489 490\n",
      "\n",
      "484 490\n",
      "491 492\n",
      "\n",
      "486 492\n",
      "493 494\n",
      "\n",
      "488 494\n",
      "495 496\n",
      "\n",
      "490 496\n",
      "497 498\n",
      "\n",
      "492 498\n",
      "499 500\n",
      "\n",
      "494 500\n",
      "501 502\n",
      "\n",
      "496 502\n",
      "503 504\n",
      "\n",
      "498 504\n",
      "505 506\n",
      "\n",
      "500 506\n",
      "507 508\n",
      "\n",
      "502 508\n",
      "509 510\n",
      "\n",
      "504 510\n",
      "511 512\n",
      "\n",
      "506 512\n",
      "513 514\n",
      "\n",
      "508 514\n",
      "515 516\n",
      "\n",
      "510 516\n",
      "517 518\n",
      "\n",
      "512 518\n",
      "519 520\n",
      "\n",
      "514 520\n",
      "521 522\n",
      "\n",
      "516 522\n",
      "523 524\n",
      "\n",
      "518 524\n",
      "525 526\n",
      "\n",
      "520 526\n",
      "527 528\n",
      "\n",
      "522 528\n",
      "529 530\n",
      "\n",
      "524 530\n",
      "531 532\n",
      "\n",
      "526 532\n",
      "533 534\n",
      "\n",
      "528 534\n",
      "535 536\n",
      "\n",
      "530 536\n",
      "537 538\n",
      "\n",
      "532 538\n",
      "539 540\n",
      "\n",
      "534 540\n",
      "541 542\n",
      "\n",
      "536 542\n",
      "543 544\n",
      "\n",
      "538 544\n",
      "545 546\n",
      "\n",
      "540 546\n",
      "547 548\n",
      "\n",
      "542 548\n",
      "549 550\n",
      "\n",
      "544 550\n",
      "551 552\n",
      "\n",
      "546 552\n",
      "553 554\n",
      "\n",
      "548 554\n",
      "555 556\n",
      "\n",
      "550 556\n",
      "557 558\n",
      "\n",
      "552 558\n",
      "559 560\n",
      "\n",
      "554 560\n",
      "561 562\n",
      "\n",
      "556 562\n",
      "563 564\n",
      "\n",
      "558 564\n",
      "565 566\n",
      "\n",
      "560 566\n",
      "567 568\n",
      "\n",
      "562 568\n",
      "569 570\n",
      "\n",
      "564 570\n",
      "571 572\n",
      "\n",
      "566 572\n",
      "573 574\n",
      "\n",
      "568 574\n",
      "575 576\n",
      "\n",
      "570 576\n",
      "577 578\n",
      "\n",
      "572 578\n",
      "579 580\n",
      "\n",
      "574 580\n",
      "581 582\n",
      "\n",
      "576 582\n",
      "583 584\n",
      "\n",
      "578 584\n",
      "585 586\n",
      "\n",
      "580 586\n",
      "587 588\n",
      "\n",
      "582 588\n",
      "589 590\n",
      "\n",
      "584 590\n",
      "591 592\n",
      "\n",
      "586 592\n",
      "593 594\n",
      "\n",
      "588 594\n",
      "595 596\n",
      "\n",
      "590 596\n",
      "597 598\n",
      "\n",
      "592 598\n",
      "599 600\n",
      "\n",
      "594 600\n",
      "601 602\n",
      "\n",
      "596 602\n",
      "603 604\n",
      "\n",
      "598 604\n",
      "605 606\n",
      "\n",
      "600 606\n",
      "607 608\n",
      "\n",
      "602 608\n",
      "609 610\n",
      "\n",
      "604 610\n",
      "611 612\n",
      "\n",
      "606 612\n",
      "613 614\n",
      "\n",
      "608 614\n",
      "615 616\n",
      "\n",
      "610 616\n",
      "617 618\n",
      "\n",
      "612 618\n",
      "619 620\n",
      "\n",
      "614 620\n",
      "621 622\n",
      "\n",
      "616 622\n",
      "623 624\n",
      "\n",
      "618 624\n",
      "625 626\n",
      "\n",
      "620 626\n",
      "627 628\n",
      "\n",
      "622 628\n",
      "629 630\n",
      "\n",
      "624 630\n",
      "631 632\n",
      "\n",
      "626 632\n",
      "633 634\n",
      "\n",
      "628 634\n",
      "635 636\n",
      "\n",
      "630 636\n",
      "637 638\n",
      "\n",
      "632 638\n",
      "639 640\n",
      "\n",
      "634 640\n",
      "641 642\n",
      "\n",
      "636 642\n",
      "643 644\n",
      "\n",
      "638 644\n",
      "645 646\n",
      "\n",
      "640 646\n",
      "647 648\n",
      "\n",
      "642 648\n",
      "649 650\n",
      "\n",
      "644 650\n",
      "651 652\n",
      "\n",
      "646 652\n",
      "653 654\n",
      "\n",
      "648 654\n",
      "655 656\n",
      "\n",
      "650 656\n",
      "657 658\n",
      "\n",
      "652 658\n",
      "659 660\n",
      "\n",
      "654 660\n",
      "661 662\n",
      "\n",
      "656 662\n",
      "663 664\n",
      "\n",
      "658 664\n",
      "665 666\n",
      "\n",
      "660 666\n",
      "667 668\n",
      "\n",
      "662 668\n",
      "669 670\n",
      "\n",
      "664 670\n",
      "671 672\n",
      "\n",
      "666 672\n",
      "673 674\n",
      "\n",
      "668 674\n",
      "675 676\n",
      "\n",
      "670 676\n",
      "677 678\n",
      "\n",
      "672 678\n",
      "679 680\n",
      "\n",
      "674 680\n",
      "681 682\n",
      "\n",
      "676 682\n",
      "683 684\n",
      "\n",
      "678 684\n",
      "685 686\n",
      "\n",
      "680 686\n",
      "687 688\n",
      "\n",
      "682 688\n",
      "689 690\n",
      "\n",
      "684 690\n",
      "691 692\n",
      "\n",
      "686 692\n",
      "693 694\n",
      "\n",
      "688 694\n",
      "695 696\n",
      "\n",
      "690 696\n",
      "697 698\n",
      "\n",
      "692 698\n",
      "699 700\n",
      "\n",
      "694 700\n",
      "701 702\n",
      "\n",
      "696 702\n",
      "703 704\n",
      "\n",
      "698 704\n",
      "705 706\n",
      "\n",
      "700 706\n",
      "707 708\n",
      "\n",
      "702 708\n",
      "709 710\n",
      "\n",
      "704 710\n",
      "711 712\n",
      "\n",
      "706 712\n",
      "713 714\n",
      "\n",
      "708 714\n",
      "715 716\n",
      "\n",
      "710 716\n",
      "717 718\n",
      "\n",
      "712 718\n",
      "719 720\n",
      "\n",
      "714 720\n",
      "721 722\n",
      "\n",
      "716 722\n",
      "723 724\n",
      "\n",
      "718 724\n",
      "725 726\n",
      "\n",
      "720 726\n",
      "727 728\n",
      "\n",
      "722 728\n",
      "729 730\n",
      "\n",
      "724 730\n",
      "731 732\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataX = []\n",
    "dataY = []\n",
    "cut_num = len(y) // 2\n",
    "\n",
    "# x는 730번 인덱스까지(총 732번 인덱스까지 중)\n",
    "for i in range(0, cut_num):\n",
    "    if i <= 362:\n",
    "        print(i*2, i*2+seq_length-1)\n",
    "        print(i*2+seq_length, i*2+seq_length+1)\n",
    "        print()\n",
    "        _x = x[i*2: i*2+seq_length]\n",
    "        _y = y[i*2+seq_length: i*2+seq_length+2]\n",
    "        dataX.append(_x)\n",
    "        dataY.append(_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size + train_size == len(dataX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'list' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-d2a7130a0670>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrainX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtestX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtrainY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtestY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'list' and 'int'"
     ]
    }
   ],
   "source": [
    "# split train/test\n",
    "train_size = int(len(dataY) *0.7)\n",
    "test_size = len(dataY) - train_size\n",
    "\n",
    "trainX = np.array(dataX[0:train_size])\n",
    "testX = np.array(dataX[train_size:len(dataX)]-7)\n",
    "trainY = np.array(dataY[0:train_size]).reshape(-1,2)\n",
    "testY = np.stack(dataY[train_size:len(dataY)-1]).reshape(-1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# 끝에서 데이터 하나 빼주었음..shape 안맞음..왜 안맞지..?\\ntrainX = np.array(dataX[0:train_size])\\ntestX = np.array(dataX[train_size:len(dataX)])\\ntrainY = np.array(dataY[0:train_size]).reshape(-1,2)\\ntestY = np.stack(dataY[train_size:len(dataY)]).reshape(-1,2)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "# 끝에서 데이터 하나 빼주었음..shape 안맞음..왜 안맞지..?\n",
    "trainX = np.array(dataX[0:train_size])\n",
    "testX = np.array(dataX[train_size:len(dataX)])\n",
    "trainY = np.array(dataY[0:train_size]).reshape(-1,2)\n",
    "testY = np.stack(dataY[train_size:len(dataY)]).reshape(-1,2)\n",
    "'''\n",
    "\n",
    "#print(\"X shape: \", trainX.shape, testX.shape)\n",
    "#print(\"Y shape: \", trainY.shape, testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x7fe519a8bbd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x7fe519a8bbd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x7fe519a8bbd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x7fe519a8bbd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe518060490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe518060490>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe518060490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe518060490>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "Epoch0번일 때, Cost:47.349\n",
      "Epoch100번일 때, Cost:0.775\n",
      "Epoch200번일 때, Cost:0.707\n",
      "Epoch300번일 때, Cost:0.672\n",
      "Epoch400번일 때, Cost:0.653\n",
      "Epoch500번일 때, Cost:0.638\n",
      "Epoch600번일 때, Cost:0.623\n",
      "Epoch700번일 때, Cost:0.610\n",
      "Epoch800번일 때, Cost:0.600\n",
      "Epoch900번일 때, Cost:0.589\n",
      "Epoch1000번일 때, Cost:0.589\n",
      "Epoch1100번일 때, Cost:0.572\n",
      "Epoch1200번일 때, Cost:0.565\n",
      "Epoch1300번일 때, Cost:0.559\n",
      "Epoch1400번일 때, Cost:0.735\n",
      "Epoch1500번일 때, Cost:0.547\n",
      "Epoch1600번일 때, Cost:0.541\n",
      "Epoch1700번일 때, Cost:0.529\n",
      "Epoch1800번일 때, Cost:0.519\n",
      "Epoch1900번일 때, Cost:0.560\n",
      "Epoch2000번일 때, Cost:0.509\n",
      "Epoch2100번일 때, Cost:0.490\n",
      "Epoch2200번일 때, Cost:0.481\n",
      "Epoch2300번일 때, Cost:0.473\n",
      "Epoch2400번일 때, Cost:0.464\n",
      "Epoch2500번일 때, Cost:0.471\n",
      "Epoch2600번일 때, Cost:0.451\n",
      "Epoch2700번일 때, Cost:0.447\n",
      "Epoch2800번일 때, Cost:0.444\n",
      "Epoch2900번일 때, Cost:0.441\n",
      "Epoch3000번일 때, Cost:0.443\n",
      "Epoch3100번일 때, Cost:0.437\n",
      "Epoch3200번일 때, Cost:0.432\n",
      "Epoch3300번일 때, Cost:0.470\n",
      "Epoch3400번일 때, Cost:0.462\n",
      "Epoch3500번일 때, Cost:0.525\n",
      "Epoch3600번일 때, Cost:0.431\n",
      "Epoch3700번일 때, Cost:0.410\n",
      "Epoch3800번일 때, Cost:0.406\n",
      "Epoch3900번일 때, Cost:0.402\n",
      "Epoch4000번일 때, Cost:0.400\n",
      "Epoch4100번일 때, Cost:0.396\n",
      "Epoch4200번일 때, Cost:0.530\n",
      "Epoch4300번일 때, Cost:0.480\n",
      "Epoch4400번일 때, Cost:0.387\n",
      "Epoch4500번일 때, Cost:0.385\n",
      "Epoch4600번일 때, Cost:0.384\n",
      "Epoch4700번일 때, Cost:0.620\n",
      "Epoch4800번일 때, Cost:0.379\n",
      "Epoch4900번일 때, Cost:0.389\n",
      "Epoch5000번일 때, Cost:0.375\n",
      "Epoch5100번일 때, Cost:0.374\n",
      "Epoch5200번일 때, Cost:0.372\n",
      "Epoch5300번일 때, Cost:0.369\n",
      "Epoch5400번일 때, Cost:0.384\n",
      "Epoch5500번일 때, Cost:0.366\n",
      "Epoch5600번일 때, Cost:0.363\n",
      "Epoch5700번일 때, Cost:0.366\n",
      "Epoch5800번일 때, Cost:0.360\n",
      "Epoch5900번일 때, Cost:0.418\n",
      "Epoch6000번일 때, Cost:0.356\n",
      "Epoch6100번일 때, Cost:0.355\n",
      "Epoch6200번일 때, Cost:0.354\n",
      "Epoch6300번일 때, Cost:0.358\n",
      "Epoch6400번일 때, Cost:0.378\n",
      "Epoch6500번일 때, Cost:0.352\n",
      "Epoch6600번일 때, Cost:0.357\n",
      "Epoch6700번일 때, Cost:0.350\n",
      "Epoch6800번일 때, Cost:0.341\n",
      "Epoch6900번일 때, Cost:0.351\n",
      "Epoch7000번일 때, Cost:0.334\n",
      "Epoch7100번일 때, Cost:0.328\n",
      "Epoch7200번일 때, Cost:0.326\n",
      "Epoch7300번일 때, Cost:0.447\n",
      "Epoch7400번일 때, Cost:0.318\n",
      "Epoch7500번일 때, Cost:0.914\n",
      "Epoch7600번일 때, Cost:0.313\n",
      "Epoch7700번일 때, Cost:0.308\n",
      "Epoch7800번일 때, Cost:0.308\n",
      "Epoch7900번일 때, Cost:0.304\n",
      "Epoch8000번일 때, Cost:0.306\n",
      "Epoch8100번일 때, Cost:0.301\n",
      "Epoch8200번일 때, Cost:0.297\n",
      "Epoch8300번일 때, Cost:0.297\n",
      "Epoch8400번일 때, Cost:0.293\n",
      "Epoch8500번일 때, Cost:0.308\n",
      "Epoch8600번일 때, Cost:0.290\n",
      "Epoch8700번일 때, Cost:0.287\n",
      "Epoch8800번일 때, Cost:0.291\n",
      "Epoch8900번일 때, Cost:0.283\n",
      "Epoch9000번일 때, Cost:0.297\n",
      "Epoch9100번일 때, Cost:0.279\n",
      "Epoch9200번일 때, Cost:0.282\n",
      "Epoch9300번일 때, Cost:0.276\n",
      "Epoch9400번일 때, Cost:0.274\n",
      "Epoch9500번일 때, Cost:0.273\n",
      "Epoch9600번일 때, Cost:0.272\n",
      "Epoch9700번일 때, Cost:0.273\n",
      "Epoch9800번일 때, Cost:0.268\n",
      "Epoch9900번일 때, Cost:0.288\n",
      "Epoch10000번일 때, Cost:0.277\n",
      "---------- Learning finished ----------\n",
      "RMSE for Test data: 0.005\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(123)\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, seq_length, input_units])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, output_units])\n",
    "\n",
    "# Basic RNN Cell\n",
    "cell = tf.contrib.rnn.BasicRNNCell(num_units=hidden_units,\n",
    "                                  activation=tf.tanh)\n",
    "\n",
    "# Outputs in RNN Cell(hidden units)\n",
    "outputs_seq, states = tf.nn.dynamic_rnn(cell, inputs=X,\n",
    "                                       dtype=tf.float32)\n",
    "\n",
    "# hidden units -> Output units 로가는 Dense layer\n",
    "Y_pred = tf.contrib.layers.fully_connected(outputs_seq[:,-1],\n",
    "                                          output_units,\n",
    "                                          activation_fn=None)\n",
    "\n",
    "# Cost function - Sum of Squared error\n",
    "cost = tf.reduce_sum(tf.square(Y_pred - Y))\n",
    "\n",
    "# Optimizer\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "#### Run Tensor Graph ####\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # 50번의 Epoch 수행\n",
    "    for i in range(iterations):\n",
    "        _ = sess.run(train, feed_dict={X : trainX,\n",
    "                                      Y: trainY})\n",
    "        if i % 100 == 0:\n",
    "            cost_val = sess.run(cost, feed_dict={X: trainX,\n",
    "                                                Y: trainY})\n",
    "            print(f\"Epoch{i}번일 때, Cost:{cost_val :.3f}\")\n",
    "    print(\"-\"*10,\"Learning finished\",\"-\"*10)\n",
    "    # Test 데이터로 검증 후  Mean of Squared Error 도출\n",
    "    test_predict = sess.run(Y_pred, feed_dict={X: testX})\n",
    "    mse = np.mean(np.square(test_predict - testY))\n",
    "    print(f\"RMSE for Test data: {mse :.3f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
