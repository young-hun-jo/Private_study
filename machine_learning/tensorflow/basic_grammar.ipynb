{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow basic grammar\n",
    "- 해당 문법은 **Tensorflow 1.x** version 호환\n",
    "- **``Tensor로 구조를 만들고 구조를 실행하는 프로세스``**<br><br>\n",
    "- **구조**\n",
    "    * tf.constant(value, dtype, shape, name='Const', verify_shape=False)\n",
    "        - value : 고정값\n",
    "    * tf.Variable(value, name) \n",
    "        - value : 초기값을 부여 -> 점차적으로 변할 값. 즉, W,b 값\n",
    "    * tf.add\n",
    "    * tf.placeholder(dtype, shape, name)\n",
    "        - '무엇인가'를 받는 역할\n",
    "        - 값이 없이 틀(size)만 있는 상태로 존재 가능\n",
    "        - 실행할 때 값을 받는 역할. 즉, 학습, 검증, 평가할 때 데이터를 받는 역할<br><br>\n",
    "- **실행**\n",
    "    * tf.Session().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Tensorflow 2.x 버전인데 1.x버전으로 import<br>\n",
    "``import tensorflow.compat.v1 as tf``<br><br>\n",
    "\n",
    "- Tensorflow 2.x 문법을 모두 disable 하기<br>\n",
    "``tf.disable_v2_behavior()``\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/younghun/opt/anaconda3/envs/venvforpython/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/younghun/opt/anaconda3/envs/venvforpython/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/younghun/opt/anaconda3/envs/venvforpython/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/younghun/opt/anaconda3/envs/venvforpython/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/younghun/opt/anaconda3/envs/venvforpython/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/younghun/opt/anaconda3/envs/venvforpython/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/younghun/opt/anaconda3/envs/venvforpython/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/younghun/opt/anaconda3/envs/venvforpython/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/younghun/opt/anaconda3/envs/venvforpython/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/younghun/opt/anaconda3/envs/venvforpython/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/younghun/opt/anaconda3/envs/venvforpython/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/younghun/opt/anaconda3/envs/venvforpython/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Add:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(1)\n",
    "b = tf.constant(2)\n",
    "c = tf.add(a, b)\n",
    "# Tensor만 출력하면 구조가 출력됨\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(sess.run([a, b, c]))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5\n",
      "[3. 7.]\n"
     ]
    }
   ],
   "source": [
    "# placeholder 사이즈 설정 안해주면 유동적으로 사이즈가 변함\n",
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "adder_node = a + b\n",
    "\n",
    "sess = tf.Session()\n",
    "# feed_dict로 빈 placeholder에 데이터 입력\n",
    "print(sess.run(adder_node, feed_dict={a:3, b:4.5}))\n",
    "\n",
    "# 데이터 size 2개로 늘리기\n",
    "# 또한 placeholder에서 설정한 type으로 자동으로 변환해서 연산\n",
    "print(sess.run(adder_node, feed_dict={a:[1,3], b:[2,4]}))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'hello, tensorflow!'\n"
     ]
    }
   ],
   "source": [
    "# 문자열 출력하기\n",
    "# 문자열도 constant에 넣기\n",
    "string = tf.constant('hello, tensorflow!')\n",
    "\n",
    "sess = tf.Session()\n",
    "print(sess.run(string))\n",
    "sess.close()\n",
    "\n",
    "# 출력화면의 b는 인코딩관련 byte를 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Realize neural network using Tensorflow 1.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [1, 2, 3]\n",
    "Y = [1, 2 ,3]\n",
    "\n",
    "# W,b 값 초기화\n",
    "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# Tensor를 add함\n",
    "hypothesis = X * W + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost function 정의\n",
    "y_train = Y\n",
    "# reduce_mean 은 평균값 연산 함수\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD 정의\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "# 위에서 정의한 SGD로 cost값 최소화하도록 정의\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run/update graph and get results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##Step: 0\n",
      "##Cost value: 0.18199880421161652\n",
      "##Weight: [0.6224558], Bias: [0.46017772]\n",
      "\n",
      "##Step: 20\n",
      "##Cost value: 0.03716462850570679\n",
      "##Weight: [0.76605237], Bias: [0.49391416]\n",
      "\n",
      "##Step: 40\n",
      "##Cost value: 0.0325918011367321\n",
      "##Weight: [0.7890307], Bias: [0.47597364]\n",
      "\n",
      "##Step: 60\n",
      "##Cost value: 0.029589882120490074\n",
      "##Weight: [0.80008656], Bias: [0.45410663]\n",
      "\n",
      "##Step: 80\n",
      "##Cost value: 0.02687389962375164\n",
      "##Weight: [0.8095904], Bias: [0.4328131]\n",
      "\n",
      "##Step: 100\n",
      "##Cost value: 0.02440730296075344\n",
      "##Weight: [0.8185493], Bias: [0.412477]\n",
      "\n",
      "##Step: 120\n",
      "##Cost value: 0.022167107090353966\n",
      "##Weight: [0.82707775], Bias: [0.3930925]\n",
      "\n",
      "##Step: 140\n",
      "##Cost value: 0.020132534205913544\n",
      "##Weight: [0.8352046], Bias: [0.3746187]\n",
      "\n",
      "##Step: 160\n",
      "##Cost value: 0.01828468218445778\n",
      "##Weight: [0.8429494], Bias: [0.35701305]\n",
      "\n",
      "##Step: 180\n",
      "##Cost value: 0.016606450080871582\n",
      "##Weight: [0.8503301], Bias: [0.3402348]\n",
      "\n",
      "##Step: 200\n",
      "##Cost value: 0.015082251280546188\n",
      "##Weight: [0.85736406], Bias: [0.324245]\n",
      "\n",
      "##Step: 220\n",
      "##Cost value: 0.013697945512831211\n",
      "##Weight: [0.86406744], Bias: [0.3090067]\n",
      "\n",
      "##Step: 240\n",
      "##Cost value: 0.012440693564713001\n",
      "##Weight: [0.8704558], Bias: [0.2944845]\n",
      "\n",
      "##Step: 260\n",
      "##Cost value: 0.011298838071525097\n",
      "##Weight: [0.8765439], Bias: [0.28064474]\n",
      "\n",
      "##Step: 280\n",
      "##Cost value: 0.010261766612529755\n",
      "##Weight: [0.8823459], Bias: [0.2674555]\n",
      "\n",
      "##Step: 300\n",
      "##Cost value: 0.009319894015789032\n",
      "##Weight: [0.8878752], Bias: [0.25488606]\n",
      "\n",
      "##Step: 320\n",
      "##Cost value: 0.008464488200843334\n",
      "##Weight: [0.89314467], Bias: [0.24290736]\n",
      "\n",
      "##Step: 340\n",
      "##Cost value: 0.007687585894018412\n",
      "##Weight: [0.89816654], Bias: [0.23149158]\n",
      "\n",
      "##Step: 360\n",
      "##Cost value: 0.006981987506151199\n",
      "##Weight: [0.90295225], Bias: [0.22061232]\n",
      "\n",
      "##Step: 380\n",
      "##Cost value: 0.006341151427477598\n",
      "##Weight: [0.9075131], Bias: [0.21024437]\n",
      "\n",
      "##Step: 400\n",
      "##Cost value: 0.005759143736213446\n",
      "##Weight: [0.9118597], Bias: [0.20036367]\n",
      "\n",
      "##Step: 420\n",
      "##Cost value: 0.0052305348217487335\n",
      "##Weight: [0.9160019], Bias: [0.19094731]\n",
      "\n",
      "##Step: 440\n",
      "##Cost value: 0.004750468302518129\n",
      "##Weight: [0.9199495], Bias: [0.18197355]\n",
      "\n",
      "##Step: 460\n",
      "##Cost value: 0.004314454272389412\n",
      "##Weight: [0.92371166], Bias: [0.17342144]\n",
      "\n",
      "##Step: 480\n",
      "##Cost value: 0.003918448928743601\n",
      "##Weight: [0.9272969], Bias: [0.16527127]\n",
      "\n",
      "##Step: 500\n",
      "##Cost value: 0.0035587958991527557\n",
      "##Weight: [0.9307136], Bias: [0.1575042]\n",
      "\n",
      "##Step: 520\n",
      "##Cost value: 0.003232155693694949\n",
      "##Weight: [0.9339698], Bias: [0.15010212]\n",
      "\n",
      "##Step: 540\n",
      "##Cost value: 0.0029355052392929792\n",
      "##Weight: [0.937073], Bias: [0.14304788]\n",
      "\n",
      "##Step: 560\n",
      "##Cost value: 0.002666063606739044\n",
      "##Weight: [0.9400304], Bias: [0.13632512]\n",
      "\n",
      "##Step: 580\n",
      "##Cost value: 0.002421358833089471\n",
      "##Weight: [0.94284874], Bias: [0.12991832]\n",
      "\n",
      "##Step: 600\n",
      "##Cost value: 0.0021991205867379904\n",
      "##Weight: [0.94553465], Bias: [0.12381261]\n",
      "\n",
      "##Step: 620\n",
      "##Cost value: 0.001997280865907669\n",
      "##Weight: [0.9480943], Bias: [0.11799384]\n",
      "\n",
      "##Step: 640\n",
      "##Cost value: 0.0018139621242880821\n",
      "##Weight: [0.95053375], Bias: [0.11244854]\n",
      "\n",
      "##Step: 660\n",
      "##Cost value: 0.0016474643489345908\n",
      "##Weight: [0.9528584], Bias: [0.10716387]\n",
      "\n",
      "##Step: 680\n",
      "##Cost value: 0.0014962558634579182\n",
      "##Weight: [0.9550739], Bias: [0.10212758]\n",
      "\n",
      "##Step: 700\n",
      "##Cost value: 0.0013589219888672233\n",
      "##Weight: [0.95718527], Bias: [0.09732793]\n",
      "\n",
      "##Step: 720\n",
      "##Cost value: 0.001234198221936822\n",
      "##Weight: [0.95919746], Bias: [0.09275389]\n",
      "\n",
      "##Step: 740\n",
      "##Cost value: 0.0011209151707589626\n",
      "##Weight: [0.96111506], Bias: [0.08839472]\n",
      "\n",
      "##Step: 760\n",
      "##Cost value: 0.0010180323151871562\n",
      "##Weight: [0.9629425], Bias: [0.08424049]\n",
      "\n",
      "##Step: 780\n",
      "##Cost value: 0.0009245884721167386\n",
      "##Weight: [0.96468407], Bias: [0.08028147]\n",
      "\n",
      "##Step: 800\n",
      "##Cost value: 0.0008397317142225802\n",
      "##Weight: [0.9663438], Bias: [0.07650852]\n",
      "\n",
      "##Step: 820\n",
      "##Cost value: 0.000762654235586524\n",
      "##Weight: [0.9679255], Bias: [0.07291289]\n",
      "\n",
      "##Step: 840\n",
      "##Cost value: 0.0006926520727574825\n",
      "##Weight: [0.96943295], Bias: [0.06948627]\n",
      "\n",
      "##Step: 860\n",
      "##Cost value: 0.0006290831952355802\n",
      "##Weight: [0.9708694], Bias: [0.06622063]\n",
      "\n",
      "##Step: 880\n",
      "##Cost value: 0.0005713444552384317\n",
      "##Weight: [0.9722384], Bias: [0.0631085]\n",
      "\n",
      "##Step: 900\n",
      "##Cost value: 0.0005189016228541732\n",
      "##Weight: [0.97354317], Bias: [0.06014264]\n",
      "\n",
      "##Step: 920\n",
      "##Cost value: 0.00047127538709901273\n",
      "##Weight: [0.9747865], Bias: [0.05731616]\n",
      "\n",
      "##Step: 940\n",
      "##Cost value: 0.0004280198772903532\n",
      "##Weight: [0.97597146], Bias: [0.0546225]\n",
      "\n",
      "##Step: 960\n",
      "##Cost value: 0.00038873348967172205\n",
      "##Weight: [0.9771007], Bias: [0.05205546]\n",
      "\n",
      "##Step: 980\n",
      "##Cost value: 0.00035305379424244165\n",
      "##Weight: [0.9781769], Bias: [0.04960905]\n",
      "\n",
      "##Step: 1000\n",
      "##Cost value: 0.00032064964761957526\n",
      "##Weight: [0.97920245], Bias: [0.04727763]\n",
      "\n",
      "##Step: 1020\n",
      "##Cost value: 0.0002912194759119302\n",
      "##Weight: [0.98017997], Bias: [0.04505569]\n",
      "\n",
      "##Step: 1040\n",
      "##Cost value: 0.00026449013967067003\n",
      "##Weight: [0.9811114], Bias: [0.04293821]\n",
      "\n",
      "##Step: 1060\n",
      "##Cost value: 0.00024021463468670845\n",
      "##Weight: [0.9819991], Bias: [0.04092027]\n",
      "\n",
      "##Step: 1080\n",
      "##Cost value: 0.00021816336084157228\n",
      "##Weight: [0.9828451], Bias: [0.03899717]\n",
      "\n",
      "##Step: 1100\n",
      "##Cost value: 0.00019814031838905066\n",
      "##Weight: [0.98365134], Bias: [0.03716443]\n",
      "\n",
      "##Step: 1120\n",
      "##Cost value: 0.0001799550955183804\n",
      "##Weight: [0.98441964], Bias: [0.03541783]\n",
      "\n",
      "##Step: 1140\n",
      "##Cost value: 0.00016343592142220587\n",
      "##Weight: [0.9851519], Bias: [0.03375332]\n",
      "\n",
      "##Step: 1160\n",
      "##Cost value: 0.00014843673852737993\n",
      "##Weight: [0.9858497], Bias: [0.03216704]\n",
      "\n",
      "##Step: 1180\n",
      "##Cost value: 0.00013481108180712909\n",
      "##Weight: [0.9865147], Bias: [0.03065531]\n",
      "\n",
      "##Step: 1200\n",
      "##Cost value: 0.00012244026584085077\n",
      "##Weight: [0.98714846], Bias: [0.02921462]\n",
      "\n",
      "##Step: 1220\n",
      "##Cost value: 0.0001112019526772201\n",
      "##Weight: [0.9877524], Bias: [0.02784165]\n",
      "\n",
      "##Step: 1240\n",
      "##Cost value: 0.00010099549399456009\n",
      "##Weight: [0.988328], Bias: [0.02653321]\n",
      "\n",
      "##Step: 1260\n",
      "##Cost value: 9.172596037387848e-05\n",
      "##Weight: [0.9888765], Bias: [0.02528626]\n",
      "\n",
      "##Step: 1280\n",
      "##Cost value: 8.330697164637968e-05\n",
      "##Weight: [0.9893993], Bias: [0.02409792]\n",
      "\n",
      "##Step: 1300\n",
      "##Cost value: 7.566151180071756e-05\n",
      "##Weight: [0.98989743], Bias: [0.02296543]\n",
      "\n",
      "##Step: 1320\n",
      "##Cost value: 6.871515506645665e-05\n",
      "##Weight: [0.99037236], Bias: [0.02188608]\n",
      "\n",
      "##Step: 1340\n",
      "##Cost value: 6.240727816475555e-05\n",
      "##Weight: [0.9908248], Bias: [0.02085747]\n",
      "\n",
      "##Step: 1360\n",
      "##Cost value: 5.668095764121972e-05\n",
      "##Weight: [0.99125594], Bias: [0.01987722]\n",
      "\n",
      "##Step: 1380\n",
      "##Cost value: 5.1477341912686825e-05\n",
      "##Weight: [0.9916669], Bias: [0.01894308]\n",
      "\n",
      "##Step: 1400\n",
      "##Cost value: 4.6752102207392454e-05\n",
      "##Weight: [0.9920586], Bias: [0.01805281]\n",
      "\n",
      "##Step: 1420\n",
      "##Cost value: 4.246165553922765e-05\n",
      "##Weight: [0.99243176], Bias: [0.01720439]\n",
      "\n",
      "##Step: 1440\n",
      "##Cost value: 3.856463808915578e-05\n",
      "##Weight: [0.9927874], Bias: [0.01639585]\n",
      "\n",
      "##Step: 1460\n",
      "##Cost value: 3.502482650219463e-05\n",
      "##Weight: [0.99312645], Bias: [0.0156253]\n",
      "\n",
      "##Step: 1480\n",
      "##Cost value: 3.180988642270677e-05\n",
      "##Weight: [0.99344945], Bias: [0.01489094]\n",
      "\n",
      "##Step: 1500\n",
      "##Cost value: 2.88898099825019e-05\n",
      "##Weight: [0.9937573], Bias: [0.01419111]\n",
      "\n",
      "##Step: 1520\n",
      "##Cost value: 2.6238762075081468e-05\n",
      "##Weight: [0.99405074], Bias: [0.01352417]\n",
      "\n",
      "##Step: 1540\n",
      "##Cost value: 2.38303418882424e-05\n",
      "##Weight: [0.9943303], Bias: [0.01288857]\n",
      "\n",
      "##Step: 1560\n",
      "##Cost value: 2.1643209038302302e-05\n",
      "##Weight: [0.9945968], Bias: [0.01228285]\n",
      "\n",
      "##Step: 1580\n",
      "##Cost value: 1.965609953913372e-05\n",
      "##Weight: [0.9948507], Bias: [0.0117056]\n",
      "\n",
      "##Step: 1600\n",
      "##Cost value: 1.785227686923463e-05\n",
      "##Weight: [0.9950927], Bias: [0.01115545]\n",
      "\n",
      "##Step: 1620\n",
      "##Cost value: 1.621369483473245e-05\n",
      "##Weight: [0.9953233], Bias: [0.01063117]\n",
      "\n",
      "##Step: 1640\n",
      "##Cost value: 1.4724937500432134e-05\n",
      "##Weight: [0.9955431], Bias: [0.01013154]\n",
      "\n",
      "##Step: 1660\n",
      "##Cost value: 1.337364301434718e-05\n",
      "##Weight: [0.99575263], Bias: [0.00965539]\n",
      "\n",
      "##Step: 1680\n",
      "##Cost value: 1.2146384506195318e-05\n",
      "##Weight: [0.9959522], Bias: [0.00920161]\n",
      "\n",
      "##Step: 1700\n",
      "##Cost value: 1.1031411304429639e-05\n",
      "##Weight: [0.9961424], Bias: [0.00876918]\n",
      "\n",
      "##Step: 1720\n",
      "##Cost value: 1.001882083073724e-05\n",
      "##Weight: [0.9963237], Bias: [0.00835708]\n",
      "\n",
      "##Step: 1740\n",
      "##Cost value: 9.099621820496395e-06\n",
      "##Weight: [0.99649644], Bias: [0.00796435]\n",
      "\n",
      "##Step: 1760\n",
      "##Cost value: 8.264695679827128e-06\n",
      "##Weight: [0.9966611], Bias: [0.00759006]\n",
      "\n",
      "##Step: 1780\n",
      "##Cost value: 7.50585604691878e-06\n",
      "##Weight: [0.99681807], Bias: [0.00723335]\n",
      "\n",
      "##Step: 1800\n",
      "##Cost value: 6.81690517012612e-06\n",
      "##Weight: [0.99696755], Bias: [0.00689342]\n",
      "\n",
      "##Step: 1820\n",
      "##Cost value: 6.191441116243368e-06\n",
      "##Weight: [0.99711007], Bias: [0.00656947]\n",
      "\n",
      "##Step: 1840\n",
      "##Cost value: 5.622981916530989e-06\n",
      "##Weight: [0.9972459], Bias: [0.00626073]\n",
      "\n",
      "##Step: 1860\n",
      "##Cost value: 5.106932803755626e-06\n",
      "##Weight: [0.9973753], Bias: [0.00596649]\n",
      "\n",
      "##Step: 1880\n",
      "##Cost value: 4.638356131181354e-06\n",
      "##Weight: [0.9974987], Bias: [0.00568608]\n",
      "\n",
      "##Step: 1900\n",
      "##Cost value: 4.212590283714235e-06\n",
      "##Weight: [0.99761623], Bias: [0.00541886]\n",
      "\n",
      "##Step: 1920\n",
      "##Cost value: 3.825976364169037e-06\n",
      "##Weight: [0.9977283], Bias: [0.00516419]\n",
      "\n",
      "##Step: 1940\n",
      "##Cost value: 3.474936647762661e-06\n",
      "##Weight: [0.99783504], Bias: [0.0049215]\n",
      "\n",
      "##Step: 1960\n",
      "##Cost value: 3.1557365218759514e-06\n",
      "##Weight: [0.9979367], Bias: [0.00469022]\n",
      "\n",
      "##Step: 1980\n",
      "##Cost value: 2.866131353584933e-06\n",
      "##Weight: [0.9980337], Bias: [0.00446983]\n",
      "\n",
      "##Step: 2000\n",
      "##Cost value: 2.6029854325315682e-06\n",
      "##Weight: [0.9981261], Bias: [0.00425977]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "# 변수 초기화\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# Run & update graph\n",
    "for step in range(2001):\n",
    "    # cost값 최소하는 SGD 실행\n",
    "    sess.run(train)\n",
    "    if step % 20 == 0:\n",
    "        print(f\"##Step: {step}\\n##Cost value: {sess.run(cost)}\\n##Weight: {sess.run(W)}, Bias: {sess.run(b)}\\n\")\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##Step: 0\n",
      "##Cost value: 4.826385021209717\n",
      "##Weight: [-0.7149561], Bias: [1.7370837]\n",
      "\n",
      "##Step: 20\n",
      "##Cost value: 0.6058637499809265\n",
      "##Weight: [0.04899257], Bias: [1.956055]\n",
      "\n",
      "##Step: 40\n",
      "##Cost value: 0.5160055160522461\n",
      "##Weight: [0.15875465], Bias: [1.8927516]\n",
      "\n",
      "##Step: 60\n",
      "##Cost value: 0.46833381056785583\n",
      "##Weight: [0.20448583], Bias: [1.8065246]\n",
      "\n",
      "##Step: 80\n",
      "##Cost value: 0.42534565925598145\n",
      "##Weight: [0.24246201], Bias: [1.7218844]\n",
      "\n",
      "##Step: 100\n",
      "##Cost value: 0.3863056004047394\n",
      "##Weight: [0.27811968], Bias: [1.6409868]\n",
      "\n",
      "##Step: 120\n",
      "##Cost value: 0.35084882378578186\n",
      "##Weight: [0.31205082], Bias: [1.5638685]\n",
      "\n",
      "##Step: 140\n",
      "##Cost value: 0.31864655017852783\n",
      "##Weight: [0.34438232], Bias: [1.4903729]\n",
      "\n",
      "##Step: 160\n",
      "##Cost value: 0.28939998149871826\n",
      "##Weight: [0.37519398], Bias: [1.420331]\n",
      "\n",
      "##Step: 180\n",
      "##Cost value: 0.2628377377986908\n",
      "##Weight: [0.40455753], Bias: [1.3535806]\n",
      "\n",
      "##Step: 200\n",
      "##Cost value: 0.238713338971138\n",
      "##Weight: [0.43254116], Bias: [1.2899672]\n",
      "\n",
      "##Step: 220\n",
      "##Cost value: 0.21680335700511932\n",
      "##Weight: [0.45920965], Bias: [1.2293437]\n",
      "\n",
      "##Step: 240\n",
      "##Cost value: 0.19690436124801636\n",
      "##Weight: [0.48462483], Bias: [1.1715691]\n",
      "\n",
      "##Step: 260\n",
      "##Cost value: 0.1788315623998642\n",
      "##Weight: [0.50884557], Bias: [1.1165096]\n",
      "\n",
      "##Step: 280\n",
      "##Cost value: 0.1624177247285843\n",
      "##Weight: [0.531928], Bias: [1.0640376]\n",
      "\n",
      "##Step: 300\n",
      "##Cost value: 0.14751042425632477\n",
      "##Weight: [0.5539257], Bias: [1.0140319]\n",
      "\n",
      "##Step: 320\n",
      "##Cost value: 0.13397125899791718\n",
      "##Weight: [0.57488954], Bias: [0.96637607]\n",
      "\n",
      "##Step: 340\n",
      "##Cost value: 0.12167485803365707\n",
      "##Weight: [0.59486806], Bias: [0.9209599]\n",
      "\n",
      "##Step: 360\n",
      "##Cost value: 0.1105070635676384\n",
      "##Weight: [0.6139078], Bias: [0.8776783]\n",
      "\n",
      "##Step: 380\n",
      "##Cost value: 0.10036429017782211\n",
      "##Weight: [0.63205266], Bias: [0.8364306]\n",
      "\n",
      "##Step: 400\n",
      "##Cost value: 0.09115246683359146\n",
      "##Weight: [0.6493449], Bias: [0.79712147]\n",
      "\n",
      "##Step: 420\n",
      "##Cost value: 0.08278609812259674\n",
      "##Weight: [0.6658244], Bias: [0.7596596]\n",
      "\n",
      "##Step: 440\n",
      "##Cost value: 0.07518764585256577\n",
      "##Weight: [0.6815295], Bias: [0.7239582]\n",
      "\n",
      "##Step: 460\n",
      "##Cost value: 0.06828659772872925\n",
      "##Weight: [0.69649655], Bias: [0.68993485]\n",
      "\n",
      "##Step: 480\n",
      "##Cost value: 0.062019020318984985\n",
      "##Weight: [0.71076006], Bias: [0.6575105]\n",
      "\n",
      "##Step: 500\n",
      "##Cost value: 0.05632665380835533\n",
      "##Weight: [0.72435325], Bias: [0.62661]\n",
      "\n",
      "##Step: 520\n",
      "##Cost value: 0.05115674436092377\n",
      "##Weight: [0.73730767], Bias: [0.59716153]\n",
      "\n",
      "##Step: 540\n",
      "##Cost value: 0.046461429446935654\n",
      "##Weight: [0.7496532], Bias: [0.56909716]\n",
      "\n",
      "##Step: 560\n",
      "##Cost value: 0.042196985334157944\n",
      "##Weight: [0.7614186], Bias: [0.5423517]\n",
      "\n",
      "##Step: 580\n",
      "##Cost value: 0.03832397982478142\n",
      "##Weight: [0.772631], Bias: [0.5168632]\n",
      "\n",
      "##Step: 600\n",
      "##Cost value: 0.034806471318006516\n",
      "##Weight: [0.78331643], Bias: [0.4925726]\n",
      "\n",
      "##Step: 620\n",
      "##Cost value: 0.03161180019378662\n",
      "##Weight: [0.79349977], Bias: [0.46942356]\n",
      "\n",
      "##Step: 640\n",
      "##Cost value: 0.02871033549308777\n",
      "##Weight: [0.8032045], Bias: [0.4473624]\n",
      "\n",
      "##Step: 660\n",
      "##Cost value: 0.026075219735503197\n",
      "##Weight: [0.81245315], Bias: [0.42633802]\n",
      "\n",
      "##Step: 680\n",
      "##Cost value: 0.023681893944740295\n",
      "##Weight: [0.8212672], Bias: [0.4063017]\n",
      "\n",
      "##Step: 700\n",
      "##Cost value: 0.021508298814296722\n",
      "##Weight: [0.8296669], Bias: [0.3872071]\n",
      "\n",
      "##Step: 720\n",
      "##Cost value: 0.019534166902303696\n",
      "##Weight: [0.8376719], Bias: [0.36900985]\n",
      "\n",
      "##Step: 740\n",
      "##Cost value: 0.017741261050105095\n",
      "##Weight: [0.84530073], Bias: [0.35166773]\n",
      "\n",
      "##Step: 760\n",
      "##Cost value: 0.016112886369228363\n",
      "##Weight: [0.85257107], Bias: [0.33514062]\n",
      "\n",
      "##Step: 780\n",
      "##Cost value: 0.01463397592306137\n",
      "##Weight: [0.8594998], Bias: [0.31939018]\n",
      "\n",
      "##Step: 800\n",
      "##Cost value: 0.013290811330080032\n",
      "##Weight: [0.8661027], Bias: [0.30437997]\n",
      "\n",
      "##Step: 820\n",
      "##Cost value: 0.012070928700268269\n",
      "##Weight: [0.8723954], Bias: [0.2900752]\n",
      "\n",
      "##Step: 840\n",
      "##Cost value: 0.010963006876409054\n",
      "##Weight: [0.8783923], Bias: [0.27644277]\n",
      "\n",
      "##Step: 860\n",
      "##Cost value: 0.00995678175240755\n",
      "##Weight: [0.8841074], Bias: [0.26345095]\n",
      "\n",
      "##Step: 880\n",
      "##Cost value: 0.009042907506227493\n",
      "##Weight: [0.88955396], Bias: [0.25106975]\n",
      "\n",
      "##Step: 900\n",
      "##Cost value: 0.008212912827730179\n",
      "##Weight: [0.8947446], Bias: [0.23927042]\n",
      "\n",
      "##Step: 920\n",
      "##Cost value: 0.007459098007529974\n",
      "##Weight: [0.8996911], Bias: [0.2280256]\n",
      "\n",
      "##Step: 940\n",
      "##Cost value: 0.006774482782930136\n",
      "##Weight: [0.9044053], Bias: [0.21730924]\n",
      "\n",
      "##Step: 960\n",
      "##Cost value: 0.006152675021439791\n",
      "##Weight: [0.908898], Bias: [0.20709649]\n",
      "\n",
      "##Step: 980\n",
      "##Cost value: 0.005587974097579718\n",
      "##Weight: [0.91317934], Bias: [0.19736369]\n",
      "\n",
      "##Step: 1000\n",
      "##Cost value: 0.0050750840455293655\n",
      "##Weight: [0.9172596], Bias: [0.18808833]\n",
      "\n",
      "##Step: 1020\n",
      "##Cost value: 0.004609271883964539\n",
      "##Weight: [0.9211481], Bias: [0.1792489]\n",
      "\n",
      "##Step: 1040\n",
      "##Cost value: 0.004186214413493872\n",
      "##Weight: [0.92485386], Bias: [0.17082486]\n",
      "\n",
      "##Step: 1060\n",
      "##Cost value: 0.003801993327215314\n",
      "##Weight: [0.9283853], Bias: [0.16279675]\n",
      "\n",
      "##Step: 1080\n",
      "##Cost value: 0.0034530293196439743\n",
      "##Weight: [0.9317511], Bias: [0.15514591]\n",
      "\n",
      "##Step: 1100\n",
      "##Cost value: 0.0031360958237200975\n",
      "##Weight: [0.9349585], Bias: [0.1478546]\n",
      "\n",
      "##Step: 1120\n",
      "##Cost value: 0.0028482486959546804\n",
      "##Weight: [0.9380152], Bias: [0.14090599]\n",
      "\n",
      "##Step: 1140\n",
      "##Cost value: 0.0025868252851068974\n",
      "##Weight: [0.9409283], Bias: [0.13428389]\n",
      "\n",
      "##Step: 1160\n",
      "##Cost value: 0.0023493925109505653\n",
      "##Weight: [0.9437044], Bias: [0.12797306]\n",
      "\n",
      "##Step: 1180\n",
      "##Cost value: 0.0021337640937417746\n",
      "##Weight: [0.9463501], Bias: [0.12195881]\n",
      "\n",
      "##Step: 1200\n",
      "##Cost value: 0.0019379170844331384\n",
      "##Weight: [0.94887143], Bias: [0.11622719]\n",
      "\n",
      "##Step: 1220\n",
      "##Cost value: 0.0017600447172299027\n",
      "##Weight: [0.95127434], Bias: [0.11076494]\n",
      "\n",
      "##Step: 1240\n",
      "##Cost value: 0.0015985063510015607\n",
      "##Weight: [0.95356417], Bias: [0.10555942]\n",
      "\n",
      "##Step: 1260\n",
      "##Cost value: 0.0014517834642902017\n",
      "##Weight: [0.9557465], Bias: [0.10059854]\n",
      "\n",
      "##Step: 1280\n",
      "##Cost value: 0.001318537280894816\n",
      "##Weight: [0.9578262], Bias: [0.0958708]\n",
      "\n",
      "##Step: 1300\n",
      "##Cost value: 0.00119751354213804\n",
      "##Weight: [0.95980835], Bias: [0.09136523]\n",
      "\n",
      "##Step: 1320\n",
      "##Cost value: 0.0010875995503738523\n",
      "##Weight: [0.96169716], Bias: [0.08707137]\n",
      "\n",
      "##Step: 1340\n",
      "##Cost value: 0.000987776555120945\n",
      "##Weight: [0.9634972], Bias: [0.08297935]\n",
      "\n",
      "##Step: 1360\n",
      "##Cost value: 0.0008971143397502601\n",
      "##Weight: [0.96521276], Bias: [0.07907961]\n",
      "\n",
      "##Step: 1380\n",
      "##Cost value: 0.0008147744811140001\n",
      "##Weight: [0.96684766], Bias: [0.07536314]\n",
      "\n",
      "##Step: 1400\n",
      "##Cost value: 0.0007399919559247792\n",
      "##Weight: [0.9684056], Bias: [0.07182134]\n",
      "\n",
      "##Step: 1420\n",
      "##Cost value: 0.000672072172164917\n",
      "##Weight: [0.96989036], Bias: [0.06844607]\n",
      "\n",
      "##Step: 1440\n",
      "##Cost value: 0.0006103867781348526\n",
      "##Weight: [0.9713055], Bias: [0.06522937]\n",
      "\n",
      "##Step: 1460\n",
      "##Cost value: 0.0005543626029975712\n",
      "##Weight: [0.97265404], Bias: [0.06216381]\n",
      "\n",
      "##Step: 1480\n",
      "##Cost value: 0.0005034813657402992\n",
      "##Weight: [0.97393924], Bias: [0.05924233]\n",
      "\n",
      "##Step: 1500\n",
      "##Cost value: 0.0004572684410959482\n",
      "##Weight: [0.975164], Bias: [0.05645815]\n",
      "\n",
      "##Step: 1520\n",
      "##Cost value: 0.0004152994661126286\n",
      "##Weight: [0.9763312], Bias: [0.0538048]\n",
      "\n",
      "##Step: 1540\n",
      "##Cost value: 0.0003771799092646688\n",
      "##Weight: [0.9774435], Bias: [0.05127619]\n",
      "\n",
      "##Step: 1560\n",
      "##Cost value: 0.0003425621835049242\n",
      "##Weight: [0.9785035], Bias: [0.0488664]\n",
      "\n",
      "##Step: 1580\n",
      "##Cost value: 0.00031112213036976755\n",
      "##Weight: [0.9795137], Bias: [0.04656989]\n",
      "\n",
      "##Step: 1600\n",
      "##Cost value: 0.0002825644623953849\n",
      "##Weight: [0.9804766], Bias: [0.04438131]\n",
      "\n",
      "##Step: 1620\n",
      "##Cost value: 0.0002566306502558291\n",
      "##Weight: [0.9813941], Bias: [0.04229552]\n",
      "\n",
      "##Step: 1640\n",
      "##Cost value: 0.00023307546507567167\n",
      "##Weight: [0.9822686], Bias: [0.04030779]\n",
      "\n",
      "##Step: 1660\n",
      "##Cost value: 0.00021168375678826123\n",
      "##Weight: [0.98310184], Bias: [0.03841348]\n",
      "\n",
      "##Step: 1680\n",
      "##Cost value: 0.0001922543888213113\n",
      "##Weight: [0.983896], Bias: [0.03660819]\n",
      "\n",
      "##Step: 1700\n",
      "##Cost value: 0.00017460726667195559\n",
      "##Weight: [0.9846528], Bias: [0.03488774]\n",
      "\n",
      "##Step: 1720\n",
      "##Cost value: 0.00015858009282965213\n",
      "##Weight: [0.9853741], Bias: [0.03324813]\n",
      "\n",
      "##Step: 1740\n",
      "##Cost value: 0.00014402750821318477\n",
      "##Weight: [0.98606145], Bias: [0.03168559]\n",
      "\n",
      "##Step: 1760\n",
      "##Cost value: 0.00013080850476399064\n",
      "##Weight: [0.98671645], Bias: [0.03019651]\n",
      "\n",
      "##Step: 1780\n",
      "##Cost value: 0.00011880201782332733\n",
      "##Weight: [0.9873408], Bias: [0.02877739]\n",
      "\n",
      "##Step: 1800\n",
      "##Cost value: 0.00010789756197482347\n",
      "##Weight: [0.9879357], Bias: [0.02742494]\n",
      "\n",
      "##Step: 1820\n",
      "##Cost value: 9.799421968637034e-05\n",
      "##Weight: [0.9885027], Bias: [0.02613607]\n",
      "\n",
      "##Step: 1840\n",
      "##Cost value: 8.899992099031806e-05\n",
      "##Weight: [0.98904294], Bias: [0.0249078]\n",
      "\n",
      "##Step: 1860\n",
      "##Cost value: 8.083189459284768e-05\n",
      "##Weight: [0.9895578], Bias: [0.02373727]\n",
      "\n",
      "##Step: 1880\n",
      "##Cost value: 7.341318269027397e-05\n",
      "##Weight: [0.9900485], Bias: [0.02262183]\n",
      "\n",
      "##Step: 1900\n",
      "##Cost value: 6.667401612503454e-05\n",
      "##Weight: [0.9905163], Bias: [0.02155867]\n",
      "\n",
      "##Step: 1920\n",
      "##Cost value: 6.055524499970488e-05\n",
      "##Weight: [0.990962], Bias: [0.02054547]\n",
      "\n",
      "##Step: 1940\n",
      "##Cost value: 5.499759936355986e-05\n",
      "##Weight: [0.9913868], Bias: [0.0195799]\n",
      "\n",
      "##Step: 1960\n",
      "##Cost value: 4.994901246391237e-05\n",
      "##Weight: [0.99179155], Bias: [0.01865972]\n",
      "\n",
      "##Step: 1980\n",
      "##Cost value: 4.5364751713350415e-05\n",
      "##Weight: [0.9921773], Bias: [0.0177828]\n",
      "\n",
      "##Step: 2000\n",
      "##Cost value: 4.120125959161669e-05\n",
      "##Weight: [0.99254495], Bias: [0.01694707]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# with 구문통해서 sess.close() 안쓰고 run, update하기\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(2001):\n",
    "        sess.run(train)\n",
    "        if step % 20 == 0:\n",
    "            print(f\"##Step: {step}\\n##Cost value: {sess.run(cost)}\\n##Weight: {sess.run(W)}, Bias: {sess.run(b)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
