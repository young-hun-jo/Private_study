{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FNN(Feedforwarding Neural Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/younghun/opt/anaconda3/envs/venvforpython/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/younghun/opt/anaconda3/envs/venvforpython/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/younghun/opt/anaconda3/envs/venvforpython/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/younghun/opt/anaconda3/envs/venvforpython/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/younghun/opt/anaconda3/envs/venvforpython/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/younghun/opt/anaconda3/envs/venvforpython/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/younghun/opt/anaconda3/envs/venvforpython/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/younghun/opt/anaconda3/envs/venvforpython/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/younghun/opt/anaconda3/envs/venvforpython/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/younghun/opt/anaconda3/envs/venvforpython/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/younghun/opt/anaconda3/envs/venvforpython/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/younghun/opt/anaconda3/envs/venvforpython/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5.73203 [[ 0.7288166   0.7153621  -1.1801533 ]\n",
      " [-0.5775373  -0.1298833   1.6072978 ]\n",
      " [ 0.48373488 -0.51433605 -2.02127   ]]\n",
      "1 3.317995 [[ 0.6621908   0.74796313 -1.1461285 ]\n",
      " [-0.81948906  0.03000022  1.689366  ]\n",
      " [ 0.23214608 -0.33772916 -1.9462881 ]]\n",
      "2 2.0218027 [[ 0.6434202   0.7412768  -1.1206716 ]\n",
      " [-0.8116129  -0.00900117  1.7204912 ]\n",
      " [ 0.20866647 -0.35079566 -1.909742  ]]\n",
      "3 1.9710885 [[ 0.6235321   0.7400823  -1.099589  ]\n",
      " [-0.80967706 -0.01636279  1.725917  ]\n",
      " [ 0.17870611 -0.3366575  -1.8939198 ]]\n",
      "4 1.9446772 [[ 0.60733104  0.7366498  -1.0799555 ]\n",
      " [-0.79007834 -0.03363193  1.7235874 ]\n",
      " [ 0.16691463 -0.33406347 -1.8847224 ]]\n",
      "5 1.9235673 [[ 0.59031737  0.73510236 -1.0613943 ]\n",
      " [-0.77496755 -0.04048848  1.7153332 ]\n",
      " [ 0.15076597 -0.32209396 -1.8805432 ]]\n",
      "6 1.9035922 [[ 0.57437915  0.7326285  -1.0429822 ]\n",
      " [-0.75527763 -0.05152001  1.7066748 ]\n",
      " [ 0.13977788 -0.31497923 -1.8766699 ]]\n",
      "7 1.88408 [[ 0.5581266   0.73071784 -1.024819  ]\n",
      " [-0.7377567  -0.05928203  1.696916  ]\n",
      " [ 0.12698431 -0.3051834  -1.8736721 ]]\n",
      "8 1.8649302 [[ 0.54225254  0.72846895 -1.006696  ]\n",
      " [-0.7190969  -0.06834842  1.6873226 ]\n",
      " [ 0.11586068 -0.29726508 -1.8704668 ]]\n",
      "9 1.8461237 [[ 0.52631956  0.72638667 -0.9886808 ]\n",
      " [-0.70141983 -0.07617539  1.6774726 ]\n",
      " [ 0.1042026  -0.2886617  -1.8674121 ]]\n",
      "10 1.8276567 [[ 0.5105773   0.72416687 -0.97071874]\n",
      " [-0.68354446 -0.08428248  1.6677043 ]\n",
      " [ 0.09325794 -0.28090802 -1.8642211 ]]\n",
      "11 1.8095273 [[ 0.49487543  0.7219867  -0.9528367 ]\n",
      " [-0.66620725 -0.0917717   1.6578563 ]\n",
      " [ 0.08226088 -0.27309966 -1.8610324 ]]\n",
      "12 1.7917325 [[ 0.4793073   0.7197361  -0.9350179 ]\n",
      " [-0.6489746  -0.09918401  1.648036  ]\n",
      " [ 0.07167411 -0.26578876 -1.8577565 ]]\n",
      "13 1.774271 [[ 0.46381766  0.71748036 -0.9172725 ]\n",
      " [-0.6321231  -0.10618486  1.6381854 ]\n",
      " [ 0.06121072 -0.25863764 -1.8544443 ]]\n",
      "14 1.7571387 [[ 0.4484437   0.7151769  -0.89959514]\n",
      " [-0.61548597 -0.11297939  1.6283427 ]\n",
      " [ 0.05105057 -0.2518569  -1.8510649 ]]\n",
      "15 1.740332 [[ 0.43316424  0.71285105 -0.88198984]\n",
      " [-0.5991741  -0.11943595  1.6184874 ]\n",
      " [ 0.04107856 -0.24531215 -1.8476377 ]]\n",
      "16 1.7238464 [[ 0.41799513  0.7104853  -0.864455  ]\n",
      " [-0.5831196  -0.12563753  1.6086345 ]\n",
      " [ 0.03136764 -0.23908748 -1.8441514 ]]\n",
      "17 1.7076764 [[ 0.402928    0.70808995 -0.84699255]\n",
      " [-0.56736916 -0.13153006  1.5987766 ]\n",
      " [ 0.02186802 -0.2331251  -1.8406141 ]]\n",
      "18 1.6918168 [[ 0.38797012  0.7056574  -0.8296022 ]\n",
      " [-0.5518933  -0.13714987  1.5889205 ]\n",
      " [ 0.01260976 -0.22745906 -1.8370218 ]]\n",
      "19 1.676261 [[ 0.37311813  0.70319223 -0.812285  ]\n",
      " [-0.5367118  -0.14247464  1.5790638 ]\n",
      " [ 0.00356905 -0.22206181 -1.8333783 ]]\n",
      "20 1.6610024 [[ 0.35837558  0.70069104 -0.79504126]\n",
      " [-0.52181023 -0.14752217  1.5692097 ]\n",
      " [-0.00524238 -0.21694618 -1.8296825 ]]\n",
      "21 1.6460341 [[ 0.3437411   0.6981561  -0.7778718 ]\n",
      " [-0.50719637 -0.15228413  1.5593578 ]\n",
      " [-0.01383764 -0.21209696 -1.8259364 ]]\n",
      "22 1.6313491 [[ 0.32921642  0.695586   -0.760777  ]\n",
      " [-0.49286175 -0.15677097  1.54951   ]\n",
      " [-0.02221335 -0.20751749 -1.8221402 ]]\n",
      "23 1.6169399 [[ 0.31480098  0.6929821  -0.7437576 ]\n",
      " [-0.47880816 -0.160981    1.5396664 ]\n",
      " [-0.0303781  -0.20319764 -1.8182954 ]]\n",
      "24 1.602799 [[ 0.3004956   0.690344   -0.7268141 ]\n",
      " [-0.46502936 -0.16492172  1.5298283 ]\n",
      " [-0.03833259 -0.19913612 -1.8144023 ]]\n",
      "25 1.5889186 [[ 0.28629988  0.68767273 -0.7099471 ]\n",
      " [-0.45152393 -0.16859494  1.5199962 ]\n",
      " [-0.04608349 -0.19532502 -1.8104626 ]]\n",
      "26 1.5752909 [[ 0.2722141   0.68496853 -0.69315714]\n",
      " [-0.43828633 -0.17200711  1.5101707 ]\n",
      " [-0.05363365 -0.19176063 -1.8064768 ]]\n",
      "27 1.561909 [[ 0.25823796  0.6822323  -0.67644477]\n",
      " [-0.4253133  -0.17516197  1.5003525 ]\n",
      " [-0.06098886 -0.18843594 -1.8024462 ]]\n",
      "28 1.5487645 [[ 0.24437134  0.6794647  -0.65981054]\n",
      " [-0.4125993  -0.17806567  1.4905422 ]\n",
      " [-0.06815308 -0.18534605 -1.7983719 ]]\n",
      "29 1.5358508 [[ 0.23061384  0.6766666  -0.64325494]\n",
      " [-0.40014    -0.18072304  1.4807403 ]\n",
      " [-0.07513183 -0.18248427 -1.7942549 ]]\n",
      "30 1.5231597 [[ 0.21696515  0.6738388  -0.6267784 ]\n",
      " [-0.38792977 -0.18314031  1.4709474 ]\n",
      " [-0.08192956 -0.17984511 -1.7900963 ]]\n",
      "31 1.5106846 [[ 0.20342474  0.6709823  -0.61038154]\n",
      " [-0.3759636  -0.1853229   1.4611638 ]\n",
      " [-0.08855168 -0.17742203 -1.7858973 ]]\n",
      "32 1.4984186 [[ 0.18999213  0.6680981  -0.5940647 ]\n",
      " [-0.36423573 -0.18727711  1.4513901 ]\n",
      " [-0.0950029  -0.17520928 -1.7816588 ]]\n",
      "33 1.4863548 [[ 0.17666668  0.6651872  -0.57782835]\n",
      " [-0.35274073 -0.18900877  1.4416268 ]\n",
      " [-0.10128845 -0.17320049 -1.777382  ]]\n",
      "34 1.4744868 [[ 0.16344777  0.6622506  -0.56167287]\n",
      " [-0.34147277 -0.19052416  1.4318743 ]\n",
      " [-0.1074132  -0.17138971 -1.7730681 ]]\n",
      "35 1.4628086 [[ 0.15033467  0.6592894  -0.5455986 ]\n",
      " [-0.33042628 -0.19182931  1.422133  ]\n",
      " [-0.11338219 -0.16977078 -1.768718  ]]\n",
      "36 1.4513137 [[ 0.13732667  0.6563048  -0.529606  ]\n",
      " [-0.31959537 -0.19293049  1.4124032 ]\n",
      " [-0.11920022 -0.1683378  -1.7643329 ]]\n",
      "37 1.4399967 [[ 0.12442295  0.6532977  -0.51369524]\n",
      " [-0.30897442 -0.19383371  1.4026855 ]\n",
      " [-0.12487221 -0.16708478 -1.7599139 ]]\n",
      "38 1.4288518 [[ 0.1116227   0.6502694  -0.49786666]\n",
      " [-0.29855767 -0.19454521  1.3929802 ]\n",
      " [-0.13040286 -0.16600597 -1.755462  ]]\n",
      "39 1.4178739 [[ 0.09892503  0.6472209  -0.48212054]\n",
      " [-0.28833956 -0.19507094  1.3832878 ]\n",
      " [-0.13579687 -0.16509554 -1.7509785 ]]\n",
      "40 1.407058 [[ 0.08632909  0.6441534  -0.4664571 ]\n",
      " [-0.27831438 -0.19541699  1.3736087 ]\n",
      " [-0.14105871 -0.16434796 -1.7464643 ]]\n",
      "41 1.3963993 [[ 0.07383393  0.64106804 -0.45087653]\n",
      " [-0.26847678 -0.19558914  1.3639432 ]\n",
      " [-0.14619292 -0.16375762 -1.7419204 ]]\n",
      "42 1.3858929 [[ 0.06143863  0.6379658  -0.43537903]\n",
      " [-0.25882128 -0.19559333  1.3542919 ]\n",
      " [-0.15120374 -0.16331923 -1.737348  ]]\n",
      "43 1.3755349 [[ 0.04914221  0.6348479  -0.4199647 ]\n",
      " [-0.24934271 -0.19543515  1.3446552 ]\n",
      " [-0.1560955  -0.16302739 -1.732748  ]]\n",
      "44 1.3653208 [[ 0.03694373  0.63171536 -0.4046337 ]\n",
      " [-0.24003573 -0.19512038  1.3350334 ]\n",
      " [-0.16087215 -0.16287714 -1.7281216 ]]\n",
      "45 1.3552469 [[ 0.02484217  0.6285693  -0.3893861 ]\n",
      " [-0.23089543 -0.19465429  1.325427  ]\n",
      " [-0.16553776 -0.16286325 -1.7234699 ]]\n",
      "46 1.3453093 [[ 0.01283655  0.6254108  -0.37422192]\n",
      " [-0.22191678 -0.19404246  1.3158365 ]\n",
      " [-0.17009607 -0.16298106 -1.7187937 ]]\n",
      "47 1.3355044 [[ 9.2581753e-04  6.2224084e-01 -3.5914126e-01]\n",
      " [-2.1309513e-01 -1.9328997e-01  1.3062624e+00]\n",
      " [-1.7455094e-01 -1.6322564e-01 -1.7140943e+00]]\n",
      "48 1.3258295 [[-0.010891    0.6190605  -0.3441441 ]\n",
      " [-0.20442563 -0.19240205  1.296705  ]\n",
      " [-0.17890577 -0.16359249 -1.7093726 ]]\n",
      "49 1.3162802 [[-0.02261497  0.61587083 -0.32923043]\n",
      " [-0.19590396 -0.1913836   1.2871649 ]\n",
      " [-0.1831642  -0.16407698 -1.7046297 ]]\n",
      "50 1.3068546 [[-0.03424709  0.61267275 -0.3144002 ]\n",
      " [-0.18752554 -0.19023958  1.2776425 ]\n",
      " [-0.18732935 -0.16467491 -1.6998665 ]]\n",
      "51 1.2975491 [[-0.04578842  0.6094672  -0.29965335]\n",
      " [-0.17928632 -0.18897462  1.2681383 ]\n",
      " [-0.19140466 -0.16538188 -1.6950842 ]]\n",
      "52 1.2883613 [[-0.05723997  0.60625523 -0.2849898 ]\n",
      " [-0.17118199 -0.18759343  1.2586528 ]\n",
      " [-0.19539298 -0.16619392 -1.6902839 ]]\n",
      "53 1.2792886 [[-0.06860281  0.6030377  -0.27040944]\n",
      " [-0.16320872 -0.1861004   1.2491865 ]\n",
      " [-0.19929743 -0.16710693 -1.6854664 ]]\n",
      "54 1.2703284 [[-0.07987795  0.59981555 -0.2559121 ]\n",
      " [-0.15536262 -0.18449993  1.23974   ]\n",
      " [-0.2031208  -0.16811708 -1.6806328 ]]\n",
      "55 1.2614783 [[-0.09106643  0.5965896  -0.24149768]\n",
      " [-0.14763996 -0.18279624  1.2303137 ]\n",
      " [-0.20686579 -0.1692206  -1.6757843 ]]\n",
      "56 1.2527364 [[-0.1021693   0.5933608  -0.227166  ]\n",
      " [-0.1400372  -0.18099341  1.220908  ]\n",
      " [-0.21053505 -0.17041382 -1.6709219 ]]\n",
      "57 1.2441001 [[-0.11318755  0.5901299  -0.21291687]\n",
      " [-0.1325508  -0.17909545  1.2115237 ]\n",
      " [-0.21413103 -0.17169325 -1.6660465 ]]\n",
      "58 1.2355677 [[-0.12412224  0.5868978  -0.19875008]\n",
      " [-0.12517755 -0.17710617  1.2021611 ]\n",
      " [-0.21765618 -0.17305538 -1.6611592 ]]\n",
      "59 1.2271373 [[-0.13497435  0.58366525 -0.18466541]\n",
      " [-0.11791407 -0.17502938  1.1928208 ]\n",
      " [-0.22111268 -0.17449695 -1.6562611 ]]\n",
      "60 1.2188069 [[-0.14574492  0.5804331  -0.17066264]\n",
      " [-0.11075743 -0.17286862  1.1835034 ]\n",
      " [-0.22450288 -0.17601462 -1.6513532 ]]\n",
      "61 1.2105749 [[-0.15643494  0.57720196 -0.15674151]\n",
      " [-0.10370451 -0.17062758  1.1742095 ]\n",
      " [-0.2278287  -0.17760539 -1.6464366 ]]\n",
      "62 1.2024395 [[-0.16704541  0.5739727  -0.14290176]\n",
      " [-0.09675255 -0.1683095   1.1649394 ]\n",
      " [-0.23109226 -0.17926607 -1.6415123 ]]\n",
      "63 1.1943991 [[-0.1775773   0.57074594 -0.12914312]\n",
      " [-0.08989867 -0.16591786  1.1556939 ]\n",
      " [-0.23429534 -0.18099385 -1.6365814 ]]\n",
      "64 1.1864524 [[-0.18803163  0.5675224  -0.11546528]\n",
      " [-0.08314037 -0.16345574  1.1464735 ]\n",
      " [-0.23743993 -0.18278572 -1.631645  ]]\n",
      "65 1.1785977 [[-0.19840932  0.5643028  -0.10186797]\n",
      " [-0.07647493 -0.16092636  1.1372787 ]\n",
      " [-0.24052756 -0.18463899 -1.6267041 ]]\n",
      "66 1.1708338 [[-0.20871137  0.5610877  -0.08835086]\n",
      " [-0.06990001 -0.15833272  1.1281102 ]\n",
      " [-0.24355999 -0.18655092 -1.6217598 ]]\n",
      "67 1.1631591 [[-0.21893871  0.55787784 -0.07491364]\n",
      " [-0.06341316 -0.15567774  1.1189684 ]\n",
      " [-0.24653874 -0.18851884 -1.6168131 ]]\n",
      "68 1.1555725 [[-0.2290923   0.5546738  -0.06155599]\n",
      " [-0.05701216 -0.1529643   1.109854  ]\n",
      " [-0.24946533 -0.19054022 -1.611865  ]]\n",
      "69 1.148073 [[-0.23917305  0.5514761  -0.04827756]\n",
      " [-0.05069478 -0.15019514  1.1007675 ]\n",
      " [-0.25234115 -0.19261259 -1.6069169 ]]\n",
      "70 1.1406592 [[-0.2491819   0.5482854  -0.03507802]\n",
      " [-0.04445896 -0.14737296  1.0917095 ]\n",
      " [-0.25516757 -0.19473352 -1.6019696 ]]\n",
      "71 1.1333299 [[-0.25911975  0.54510224 -0.02195701]\n",
      " [-0.03830269 -0.14450036  1.0826806 ]\n",
      " [-0.25794587 -0.19690064 -1.5970242 ]]\n",
      "72 1.1260841 [[-0.26898748  0.54192716 -0.00891418]\n",
      " [-0.03222397 -0.14157993  1.0736815 ]\n",
      " [-0.26067722 -0.1991117  -1.5920818 ]]\n",
      "73 1.1189208 [[-0.278786    0.53876066  0.00405081]\n",
      " [-0.02622098 -0.138614    1.0647125 ]\n",
      " [-0.2633628  -0.20136441 -1.5871435 ]]\n",
      "74 1.111839 [[-0.2885162   0.5356033   0.01693835]\n",
      " [-0.02029195 -0.13560508  1.0557746 ]\n",
      " [-0.2660037  -0.20365667 -1.5822103 ]]\n",
      "75 1.1048377 [[-0.29817888  0.53245556  0.02974879]\n",
      " [-0.01443512 -0.13255541  1.0468681 ]\n",
      " [-0.26860097 -0.2059863  -1.5772834 ]]\n",
      "76 1.0979161 [[-0.30777493  0.5293179   0.04248251]\n",
      " [-0.00864881 -0.12946732  1.0379937 ]\n",
      " [-0.2711555  -0.20835133 -1.5723639 ]]\n",
      "77 1.0910732 [[-0.3173052   0.5261908   0.05513988]\n",
      " [-0.00293155 -0.1263429   1.0291519 ]\n",
      " [-0.27366838 -0.21074964 -1.5674527 ]]\n",
      "78 1.0843083 [[-0.3267705   0.52307475  0.06772129]\n",
      " [ 0.00271833 -0.1231844   1.0203435 ]\n",
      " [-0.2761403  -0.21317942 -1.5625509 ]]\n",
      "79 1.0776203 [[-0.3361717   0.5199701   0.08022709]\n",
      " [ 0.00830216 -0.11999375  1.011569  ]\n",
      " [-0.27857223 -0.21563862 -1.5576597 ]]\n",
      "80 1.0710086 [[-0.3455095   0.51687735  0.09265769]\n",
      " [ 0.01382145 -0.1167731   1.0028291 ]\n",
      " [-0.28096485 -0.21812549 -1.5527803 ]]\n",
      "81 1.0644722 [[-0.3547848   0.51379687  0.10501345]\n",
      " [ 0.01927747 -0.11352432  0.9941243 ]\n",
      " [-0.28331897 -0.22063816 -1.5479134 ]]\n",
      "82 1.0580108 [[-0.3639983   0.5107291   0.11729475]\n",
      " [ 0.02467156 -0.11024935  0.9854553 ]\n",
      " [-0.2856352  -0.22317487 -1.5430604 ]]\n",
      "83 1.0516233 [[-0.3731508   0.50767434  0.12950198]\n",
      " [ 0.03000492 -0.10695004  0.9768226 ]\n",
      " [-0.28791428 -0.22573389 -1.5382223 ]]\n",
      "84 1.0453093 [[-0.38224304  0.504633    0.14163554]\n",
      " [ 0.03527875 -0.10362823  0.96822697]\n",
      " [-0.29015675 -0.2283136  -1.5334002 ]]\n",
      "85 1.0390677 [[-0.39127576  0.5016055   0.15369578]\n",
      " [ 0.04049416 -0.10028562  0.95966893]\n",
      " [-0.2923633  -0.23091225 -1.528595  ]]\n",
      "86 1.0328985 [[-0.4002497   0.49859214  0.16568309]\n",
      " [ 0.04565233 -0.09692402  0.95114917]\n",
      " [-0.2945343  -0.23352838 -1.5238079 ]]\n",
      "87 1.0268004 [[-0.40916556  0.49559325  0.17759785]\n",
      " [ 0.05075418 -0.09354496  0.94266826]\n",
      " [-0.29667044 -0.23616023 -1.5190399 ]]\n",
      "88 1.0207732 [[-0.41802406  0.49260917  0.18944043]\n",
      " [ 0.05580086 -0.09015024  0.9342269 ]\n",
      " [-0.298772   -0.23880649 -1.514292  ]]\n",
      "89 1.0148159 [[-0.4268259   0.48964024  0.20121121]\n",
      " [ 0.06079315 -0.08674125  0.9258256 ]\n",
      " [-0.30083966 -0.24146543 -1.5095654 ]]\n",
      "90 1.0089283 [[-0.43557176  0.48668674  0.21291058]\n",
      " [ 0.06573218 -0.08331972  0.91746503]\n",
      " [-0.3028736  -0.2441358  -1.504861  ]]\n",
      "91 1.0031099 [[-0.44426233  0.48374897  0.22453889]\n",
      " [ 0.07061864 -0.07988702  0.90914583]\n",
      " [-0.30487442 -0.24681598 -1.50018   ]]\n",
      "92 0.9973597 [[-0.4528982   0.4808272   0.23609653]\n",
      " [ 0.07545355 -0.07644475  0.90086865]\n",
      " [-0.3068423  -0.24950476 -1.4955233 ]]\n",
      "93 0.99167746 [[-0.46148008  0.47792178  0.24758385]\n",
      " [ 0.08023755 -0.07299422  0.89263415]\n",
      " [-0.30877775 -0.25220063 -1.490892  ]]\n",
      "94 0.9860627 [[-0.47000858  0.4750329   0.25900123]\n",
      " [ 0.08497155 -0.06953694  0.88444287]\n",
      " [-0.31068093 -0.25490236 -1.4862871 ]]\n",
      "95 0.9805147 [[-0.47848433  0.47216085  0.27034903]\n",
      " [ 0.08965623 -0.06607419  0.87629545]\n",
      " [-0.3125522  -0.25760856 -1.4817096 ]]\n",
      "96 0.97503316 [[-0.48690796  0.46930587  0.2816276 ]\n",
      " [ 0.09429233 -0.06260738  0.86819255]\n",
      " [-0.31439182 -0.26031804 -1.4771605 ]]\n",
      "97 0.96961737 [[-0.49528003  0.46646824  0.2928373 ]\n",
      " [ 0.09888049 -0.05913769  0.8601347 ]\n",
      " [-0.31620008 -0.26302946 -1.4726408 ]]\n",
      "98 0.9642669 [[-0.50360113  0.46364817  0.30397847]\n",
      " [ 0.10342142 -0.05566652  0.8521226 ]\n",
      " [-0.31797713 -0.26574168 -1.4681515 ]]\n",
      "99 0.9589814 [[-0.5118719   0.4608459   0.31505153]\n",
      " [ 0.10791566 -0.05219504  0.8441569 ]\n",
      " [-0.31972325 -0.26845348 -1.4636935 ]]\n",
      "100 0.95376027 [[-0.52009284  0.4580616   0.32605678]\n",
      " [ 0.11236387 -0.04872449  0.83623815]\n",
      " [-0.3214386  -0.2711637  -1.4592679 ]]\n",
      "101 0.9486031 [[-0.5282646   0.45529556  0.33699456]\n",
      " [ 0.11676662 -0.04525602  0.82836694]\n",
      " [-0.32312337 -0.27387124 -1.4548756 ]]\n",
      "102 0.9435093 [[-0.5363876   0.45254794  0.34786522]\n",
      " [ 0.12112439 -0.04179079  0.82054394]\n",
      " [-0.32477775 -0.27657494 -1.4505175 ]]\n",
      "103 0.9384785 [[-0.5444625   0.4498189   0.35866913]\n",
      " [ 0.12543777 -0.03832997  0.8127698 ]\n",
      " [-0.32640186 -0.27927378 -1.4461945 ]]\n",
      "104 0.93351024 [[-0.55248976  0.44710872  0.3694066 ]\n",
      " [ 0.12970722 -0.03487457  0.8050449 ]\n",
      " [-0.32799584 -0.28196663 -1.4419076 ]]\n",
      "105 0.9286041 [[-0.5604699   0.4444175   0.380078  ]\n",
      " [ 0.13393326 -0.03142573  0.79737   ]\n",
      " [-0.32955977 -0.28465253 -1.4376578 ]]\n",
      "106 0.9237596 [[-0.5684035   0.44174546  0.39068362]\n",
      " [ 0.13811626 -0.02798444  0.78974575]\n",
      " [-0.33109388 -0.28733042 -1.4334458 ]]\n",
      "107 0.91897625 [[-0.57629097  0.43909273  0.40122384]\n",
      " [ 0.14225675 -0.0245518   0.7821726 ]\n",
      " [-0.33259815 -0.2899994  -1.4292725 ]]\n",
      "108 0.9142537 [[-0.58413285  0.4364595   0.41169894]\n",
      " [ 0.14635508 -0.02112867  0.77465117]\n",
      " [-0.33407277 -0.2926584  -1.425139  ]]\n",
      "109 0.90959144 [[-0.5919296   0.4338459   0.42210928]\n",
      " [ 0.1504117  -0.01771616  0.76718205]\n",
      " [-0.33551773 -0.2953066  -1.4210458 ]]\n",
      "110 0.90498894 [[-0.59968174  0.43125212  0.43245518]\n",
      " [ 0.15442693 -0.01431512  0.7597658 ]\n",
      " [-0.33693323 -0.29794303 -1.4169939 ]]\n",
      "111 0.90044594 [[-0.6073897   0.42867824  0.44273698]\n",
      " [ 0.1584012  -0.01092649  0.7524029 ]\n",
      " [-0.3383192  -0.30056685 -1.412984  ]]\n",
      "112 0.89596176 [[-0.6150539   0.42612445  0.452955  ]\n",
      " [ 0.16233481 -0.00755114  0.74509394]\n",
      " [-0.3396758  -0.30317718 -1.4090171 ]]\n",
      "113 0.8915362 [[-0.6226748   0.42359084  0.46310958]\n",
      " [ 0.1662281  -0.00418997  0.73783946]\n",
      " [-0.3410031  -0.3057732  -1.4050938 ]]\n",
      "114 0.8871686 [[-6.3025296e-01  4.2107755e-01  4.7320101e-01]\n",
      " [ 1.7008139e-01 -8.4384182e-04  7.3064005e-01]\n",
      " [-3.4230107e-01 -3.0835411e-01 -1.4012150e+00]]\n",
      "115 0.88285875 [[-0.6377887   0.41858467  0.4832296 ]\n",
      " [ 0.17389502  0.00248647  0.72349614]\n",
      " [-0.3435698  -0.3109191  -1.3973812 ]]\n",
      "116 0.87860596 [[-0.6452825   0.41611233  0.4931957 ]\n",
      " [ 0.17766926  0.00580017  0.7164082 ]\n",
      " [-0.3448093  -0.3134674  -1.3935933 ]]\n",
      "117 0.8744097 [[-0.65273476  0.41366062  0.5030996 ]\n",
      " [ 0.18140437  0.00909643  0.7093768 ]\n",
      " [-0.34601966 -0.31599838 -1.389852  ]]\n",
      "118 0.8702698 [[-0.6601459   0.41122964  0.5129417 ]\n",
      " [ 0.18510063  0.01237455  0.7024024 ]\n",
      " [-0.3472009  -0.31851122 -1.386158  ]]\n",
      "119 0.8661856 [[-0.66751623  0.40881947  0.52272224]\n",
      " [ 0.18875833  0.01563375  0.69548553]\n",
      " [-0.34835306 -0.32100528 -1.3825117 ]]\n",
      "120 0.8621566 [[-0.6748463   0.4064302   0.53244156]\n",
      " [ 0.19237767  0.01887341  0.6886265 ]\n",
      " [-0.3494762  -0.32347986 -1.378914  ]]\n",
      "121 0.85818255 [[-0.6821364   0.4040619   0.54209995]\n",
      " [ 0.19595897  0.02209276  0.6818259 ]\n",
      " [-0.35057026 -0.32593438 -1.3753654 ]]\n",
      "122 0.8542628 [[-0.68938696  0.40171468  0.5516978 ]\n",
      " [ 0.19950241  0.02529121  0.675084  ]\n",
      " [-0.35163537 -0.32836822 -1.3718665 ]]\n",
      "123 0.85039675 [[-0.69659835  0.39938855  0.5612353 ]\n",
      " [ 0.20300817  0.02846808  0.66840136]\n",
      " [-0.35267156 -0.33078077 -1.3684177 ]]\n",
      "124 0.8465842 [[-0.703771    0.39708358  0.5707129 ]\n",
      " [ 0.20647657  0.03162277  0.6617783 ]\n",
      " [-0.35367882 -0.3331715  -1.3650198 ]]\n",
      "125 0.84282446 [[-0.7109052   0.39479983  0.5801309 ]\n",
      " [ 0.20990777  0.03475469  0.65521514]\n",
      " [-0.3546572  -0.33553982 -1.3616731 ]]\n",
      "126 0.83911705 [[-0.71800137  0.39253733  0.5894895 ]\n",
      " [ 0.21330196  0.03786328  0.64871234]\n",
      " [-0.3556068  -0.33788523 -1.3583782 ]]\n",
      "127 0.8354615 [[-0.7250598   0.39029613  0.5987892 ]\n",
      " [ 0.21665938  0.04094795  0.64227027]\n",
      " [-0.35652757 -0.3402073  -1.3551353 ]]\n",
      "128 0.8318572 [[-0.73208094  0.38807628  0.6080302 ]\n",
      " [ 0.21998021  0.04400826  0.6358891 ]\n",
      " [-0.3574196  -0.34250548 -1.3519452 ]]\n",
      "129 0.8283038 [[-0.7390651   0.3858778   0.61721283]\n",
      " [ 0.22326465  0.04704366  0.6295693 ]\n",
      " [-0.35828295 -0.3447794  -1.3488079 ]]\n",
      "130 0.82480067 [[-0.7460126   0.38370067  0.62633747]\n",
      " [ 0.22651288  0.05005367  0.62331104]\n",
      " [-0.35911763 -0.3470286  -1.345724  ]]\n",
      "131 0.82134736 [[-0.75292385  0.38154495  0.6354044 ]\n",
      " [ 0.22972511  0.05303788  0.6171146 ]\n",
      " [-0.35992372 -0.3492527  -1.3426938 ]]\n",
      "132 0.8179431 [[-0.7597991   0.37941062  0.644414  ]\n",
      " [ 0.23290148  0.0559958   0.6109803 ]\n",
      " [-0.3607013  -0.35145137 -1.3397176 ]]\n",
      "133 0.8145876 [[-0.7666388   0.37729773  0.65336657]\n",
      " [ 0.23604219  0.05892706  0.6049083 ]\n",
      " [-0.3614504  -0.3536242  -1.3367957 ]]\n",
      "134 0.81128025 [[-0.7734432   0.37520623  0.66226244]\n",
      " [ 0.23914742  0.06183126  0.5988988 ]\n",
      " [-0.3621711  -0.35577092 -1.3339282 ]]\n",
      "135 0.8080205 [[-0.78021264  0.37313616  0.6711019 ]\n",
      " [ 0.24221738  0.06470805  0.5929521 ]\n",
      " [-0.3628635  -0.3578912  -1.3311156 ]]\n",
      "136 0.80480766 [[-0.7869474   0.37108746  0.6798854 ]\n",
      " [ 0.24525224  0.06755707  0.5870682 ]\n",
      " [-0.36352763 -0.35998482 -1.3283578 ]]\n",
      "137 0.80164146 [[-0.7936479   0.36906016  0.6886132 ]\n",
      " [ 0.24825212  0.07037806  0.5812473 ]\n",
      " [-0.36416364 -0.36205143 -1.3256552 ]]\n",
      "138 0.79852104 [[-0.80031437  0.36705416  0.6972856 ]\n",
      " [ 0.25121728  0.07317059  0.57548964]\n",
      " [-0.36477154 -0.36409095 -1.3230078 ]]\n",
      "139 0.795446 [[-0.8069472   0.3650695   0.705903  ]\n",
      " [ 0.2541478   0.07593456  0.56979513]\n",
      " [-0.36535156 -0.36610302 -1.3204157 ]]\n",
      "140 0.7924156 [[-0.81354654  0.36310613  0.71446574]\n",
      " [ 0.25704402  0.07866953  0.564164  ]\n",
      " [-0.36590362 -0.36808765 -1.3178791 ]]\n",
      "141 0.7894295 [[-0.8201129   0.361164    0.7229742 ]\n",
      " [ 0.25990593  0.08137545  0.55859613]\n",
      " [-0.366428   -0.37004447 -1.3153979 ]]\n",
      "142 0.7864869 [[-0.82664645  0.35924307  0.7314287 ]\n",
      " [ 0.26273385  0.08405197  0.5530917 ]\n",
      " [-0.3669247  -0.3719735  -1.3129721 ]]\n",
      "143 0.78358746 [[-0.8331475   0.3573433   0.7398296 ]\n",
      " [ 0.26552784  0.08669902  0.54765064]\n",
      " [-0.36739397 -0.37387455 -1.3106017 ]]\n",
      "144 0.78073025 [[-0.8396165   0.35546458  0.74817723]\n",
      " [ 0.26828828  0.08931629  0.5422729 ]\n",
      " [-0.36783576 -0.37574762 -1.3082868 ]]\n",
      "145 0.7779149 [[-0.84605354  0.3536069   0.756472  ]\n",
      " [ 0.27101508  0.09190379  0.5369586 ]\n",
      " [-0.36825043 -0.3775925  -1.3060273 ]]\n",
      "146 0.7751409 [[-0.852459    0.3517702   0.7647142 ]\n",
      " [ 0.2737087   0.0944612   0.5317075 ]\n",
      " [-0.3686379  -0.37940937 -1.303823  ]]\n",
      "147 0.77240735 [[-0.85883325  0.3499544   0.7729042 ]\n",
      " [ 0.27636912  0.09698867  0.52651966]\n",
      " [-0.3689985  -0.3811979  -1.3016738 ]]\n",
      "148 0.7697139 [[-0.8651765   0.34815937  0.78104246]\n",
      " [ 0.27899674  0.09948585  0.52139485]\n",
      " [-0.36933222 -0.38295838 -1.2995796 ]]\n",
      "149 0.7670599 [[-0.87148905  0.34638512  0.78912926]\n",
      " [ 0.28159153  0.1019529   0.516333  ]\n",
      " [-0.36963943 -0.38469058 -1.2975402 ]]\n",
      "150 0.7644448 [[-0.87777114  0.3446315   0.797165  ]\n",
      " [ 0.2841539   0.10438956  0.51133394]\n",
      " [-0.36992007 -0.38639474 -1.2955554 ]]\n",
      "151 0.7618679 [[-0.88402313  0.34289846  0.80515   ]\n",
      " [ 0.2866839   0.106796    0.50639755]\n",
      " [-0.37017453 -0.3880707  -1.2936249 ]]\n",
      "152 0.75932854 [[-0.89024526  0.3411859   0.81308466]\n",
      " [ 0.28918183  0.10917206  0.50152355]\n",
      " [-0.3704028  -0.38971874 -1.2917485 ]]\n",
      "153 0.7568263 [[-0.8964378   0.33949372  0.8209694 ]\n",
      " [ 0.29164782  0.11151787  0.49671176]\n",
      " [-0.37060526 -0.39133877 -1.289926  ]]\n",
      "154 0.75436044 [[-0.90260106  0.3378218   0.82880455]\n",
      " [ 0.2940822   0.11383331  0.49196193]\n",
      " [-0.37078193 -0.39293104 -1.2881571 ]]\n",
      "155 0.7519305 [[-0.90873533  0.33617008  0.8365905 ]\n",
      " [ 0.296485    0.11611856  0.48727384]\n",
      " [-0.37093318 -0.39449555 -1.2864413 ]]\n",
      "156 0.74953574 [[-0.9148408   0.33453843  0.8443277 ]\n",
      " [ 0.29885668  0.11837356  0.48264718]\n",
      " [-0.37105903 -0.39603257 -1.2847785 ]]\n",
      "157 0.7471757 [[-0.92091787  0.33292675  0.8520164 ]\n",
      " [ 0.30119723  0.12059851  0.47808164]\n",
      " [-0.37115988 -0.39754212 -1.2831681 ]]\n",
      "158 0.7448497 [[-0.92696667  0.3313349   0.85965705]\n",
      " [ 0.30350706  0.12279339  0.47357693]\n",
      " [-0.3712358  -0.39902446 -1.2816098 ]]\n",
      "159 0.7425573 [[-0.9329876   0.3297628   0.86725   ]\n",
      " [ 0.30578628  0.12495843  0.4691327 ]\n",
      " [-0.3712871  -0.40047967 -1.2801032 ]]\n",
      "160 0.7402977 [[-0.93898076  0.32821026  0.87479573]\n",
      " [ 0.30803522  0.12709361  0.46474856]\n",
      " [-0.37131396 -0.40190807 -1.2786479 ]]\n",
      "161 0.73807037 [[-0.9449466   0.32667726  0.8822946 ]\n",
      " [ 0.310254    0.12919918  0.4604242 ]\n",
      " [-0.37131667 -0.40330976 -1.2772435 ]]\n",
      "162 0.7358748 [[-0.95088524  0.3251636   0.8897469 ]\n",
      " [ 0.312443    0.13127519  0.45615923]\n",
      " [-0.3712954  -0.40468508 -1.2758894 ]]\n",
      "163 0.73371047 [[-0.956797    0.3236692   0.89715314]\n",
      " [ 0.3146023   0.13332193  0.4519532 ]\n",
      " [-0.37125045 -0.4060341  -1.2745852 ]]\n",
      "164 0.73157674 [[-0.9626822   0.32219386  0.90451366]\n",
      " [ 0.3167323   0.13533942  0.4478057 ]\n",
      " [-0.371182   -0.40735728 -1.2733306 ]]\n",
      "165 0.72947294 [[-0.968541    0.3207375   0.9118288 ]\n",
      " [ 0.31883308  0.13732798  0.44371635]\n",
      " [-0.3710904  -0.4086547  -1.2721248 ]]\n",
      "166 0.72739875 [[-0.9743737   0.3193      0.91909903]\n",
      " [ 0.32090506  0.13928774  0.43968463]\n",
      " [-0.37097585 -0.40992668 -1.2709674 ]]\n",
      "167 0.7253535 [[-0.98018056  0.31788117  0.9263247 ]\n",
      " [ 0.32294843  0.14121892  0.4357101 ]\n",
      " [-0.37083858 -0.41117352 -1.2698578 ]]\n",
      "168 0.7233365 [[-0.9859618   0.3164809   0.93350625]\n",
      " [ 0.32496342  0.14312175  0.43179226]\n",
      " [-0.3706789  -0.4123955  -1.2687955 ]]\n",
      "169 0.7213476 [[-0.9917177   0.31509906  0.94064397]\n",
      " [ 0.3269503   0.14499646  0.42793065]\n",
      " [-0.37049705 -0.4135929  -1.26778   ]]\n",
      "170 0.71938586 [[-0.9974485   0.31373549  0.94773835]\n",
      " [ 0.3289094   0.14684333  0.42412472]\n",
      " [-0.37029326 -0.41476598 -1.2668107 ]]\n",
      "171 0.7174509 [[-1.0031544   0.31239003  0.9547897 ]\n",
      " [ 0.3308409   0.14866254  0.420374  ]\n",
      " [-0.37006786 -0.41591513 -1.2658869 ]]\n",
      "172 0.7155423 [[-1.0088357   0.31106257  0.9617985 ]\n",
      " [ 0.33274505  0.1504544   0.41667798]\n",
      " [-0.36982113 -0.4170406  -1.2650082 ]]\n",
      "173 0.7136595 [[-1.0144926   0.30975294  0.9687651 ]\n",
      " [ 0.33462223  0.15221912  0.41303608]\n",
      " [-0.36955327 -0.41814277 -1.2641739 ]]\n",
      "174 0.71180195 [[-1.0201255   0.308461    0.9756898 ]\n",
      " [ 0.3364726   0.15395708  0.40944776]\n",
      " [-0.36926463 -0.41922185 -1.2633834 ]]\n",
      "175 0.70996916 [[-1.0257344   0.30718663  0.98257315]\n",
      " [ 0.33829656  0.15566842  0.40591246]\n",
      " [-0.36895537 -0.4202783  -1.2626362 ]]\n",
      "176 0.7081605 [[-1.0313197   0.30592963  0.9894154 ]\n",
      " [ 0.3400942   0.15735355  0.40242967]\n",
      " [-0.36862594 -0.4213124  -1.2619315 ]]\n",
      "177 0.70637596 [[-1.0368816   0.30468988  0.996217  ]\n",
      " [ 0.341866    0.15901266  0.3989988 ]\n",
      " [-0.36827648 -0.4223245  -1.2612689 ]]\n",
      "178 0.7046145 [[-1.0424203   0.3034672   1.0029783 ]\n",
      " [ 0.34361205  0.16064616  0.39561924]\n",
      " [-0.36790738 -0.4233149  -1.2606475 ]]\n",
      "179 0.702876 [[-1.047936    0.30226147  1.0096998 ]\n",
      " [ 0.34533277  0.16225423  0.39229044]\n",
      " [-0.36751878 -0.42428404 -1.260067  ]]\n",
      "180 0.7011599 [[-1.053429    0.30107254  1.0163817 ]\n",
      " [ 0.34702832  0.16383731  0.38901183]\n",
      " [-0.36711112 -0.42523214 -1.2595265 ]]\n",
      "181 0.69946575 [[-1.0588995   0.29990023  1.0230246 ]\n",
      " [ 0.34869912  0.16539559  0.38578278]\n",
      " [-0.3666845  -0.4261597  -1.2590256 ]]\n",
      "182 0.6977931 [[-1.0643477   0.2987444   1.0296286 ]\n",
      " [ 0.35034528  0.16692948  0.38260272]\n",
      " [-0.3662394  -0.42706695 -1.2585634 ]]\n",
      "183 0.6961416 [[-1.0697739   0.29760492  1.0361943 ]\n",
      " [ 0.35196725  0.16843924  0.37947103]\n",
      " [-0.3657759  -0.42795432 -1.2581395 ]]\n",
      "184 0.6945107 [[-1.0751783   0.2964816   1.042722  ]\n",
      " [ 0.35356516  0.16992524  0.37638712]\n",
      " [-0.3652945  -0.42882204 -1.2577531 ]]\n",
      "185 0.6929002 [[-1.080561    0.2953743   1.0492121 ]\n",
      " [ 0.35513943  0.17138773  0.37335038]\n",
      " [-0.36479527 -0.42967063 -1.2574037 ]]\n",
      "186 0.6913092 [[-1.0859225   0.29428288  1.0556649 ]\n",
      " [ 0.3566902   0.17282712  0.3703602 ]\n",
      " [-0.36427864 -0.43050033 -1.2570907 ]]\n",
      "187 0.6897378 [[-1.0912627   0.29320717  1.0620809 ]\n",
      " [ 0.3582179   0.17424364  0.367416  ]\n",
      " [-0.36374477 -0.43131158 -1.2568133 ]]\n",
      "188 0.6881855 [[-1.0965819   0.292147    1.0684603 ]\n",
      " [ 0.35972264  0.17563775  0.36451712]\n",
      " [-0.36319408 -0.4321046  -1.2565709 ]]\n",
      "189 0.68665177 [[-1.1018804   0.29110226  1.0748036 ]\n",
      " [ 0.36120492  0.17700961  0.361663  ]\n",
      " [-0.36262667 -0.4328799  -1.256363  ]]\n",
      "190 0.6851362 [[-1.1071584   0.2900728   1.0811111 ]\n",
      " [ 0.36266476  0.17835975  0.35885304]\n",
      " [-0.36204302 -0.43363768 -1.2561889 ]]\n",
      "191 0.6836387 [[-1.1124161   0.28905842  1.0873832 ]\n",
      " [ 0.3641027   0.17968829  0.35608655]\n",
      " [-0.3614432  -0.43437845 -1.256048  ]]\n",
      "192 0.68215865 [[-1.1176537   0.288059    1.0936202 ]\n",
      " [ 0.3655188   0.18099575  0.35336298]\n",
      " [-0.36082762 -0.43510237 -1.2559396 ]]\n",
      "193 0.68069583 [[-1.1228714   0.2870744   1.0998225 ]\n",
      " [ 0.3669135   0.18228228  0.35068175]\n",
      " [-0.36019647 -0.43581    -1.2558632 ]]\n",
      "194 0.67924976 [[-1.1280694   0.28610444  1.1059904 ]\n",
      " [ 0.36828697  0.1835484   0.3480422 ]\n",
      " [-0.3595501  -0.43650147 -1.2558181 ]]\n",
      "195 0.6778203 [[-1.1332479   0.28514898  1.1121243 ]\n",
      " [ 0.36963955  0.18479426  0.34544376]\n",
      " [-0.35888866 -0.4371773  -1.2558037 ]]\n",
      "196 0.676407 [[-1.138407    0.2842079   1.1182245 ]\n",
      " [ 0.37097144  0.18602034  0.34288576]\n",
      " [-0.35821253 -0.43783763 -1.2558194 ]]\n",
      "197 0.67500937 [[-1.1435469   0.28328103  1.1242914 ]\n",
      " [ 0.37228304  0.18722682  0.3403677 ]\n",
      " [-0.35752186 -0.438483   -1.2558647 ]]\n",
      "198 0.6736274 [[-1.148668    0.2823682   1.1303253 ]\n",
      " [ 0.37357447  0.18841417  0.33788896]\n",
      " [-0.35681707 -0.4391136  -1.255939  ]]\n",
      "199 0.67226064 [[-1.1537704   0.28146932  1.1363266 ]\n",
      " [ 0.37484613  0.18958256  0.3354489 ]\n",
      " [-0.35609823 -0.43972987 -1.2560415 ]]\n",
      "200 0.67090875 [[-1.1588542   0.28058422  1.1422955 ]\n",
      " [ 0.3760982   0.19073246  0.3330469 ]\n",
      " [-0.35536575 -0.440332   -1.256172  ]]\n",
      "Prediction:\n",
      " [2 2 2]\n",
      "Accuracy:\n",
      " 1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "x_data = [[1,2,1],[1,3,2],[1,3,4],\n",
    "         [1,5,5],[1,7,5],[1,2,5],[1,6,6],\n",
    "         [1,7,7]]\n",
    "y_data = [[0,0,1],[0,0,1],[0,0,1],\n",
    "         [0,1,0],[0,1,0],[0,1,0],[1,0,0],\n",
    "         [1,0,0]]\n",
    "\n",
    "x_test = [[2,1,1],[3,1,2],[3,3,4]]\n",
    "y_test = [[0,0,1],[0,0,1],[0,0,1]]\n",
    "\n",
    "# tf.float32 -> 'float'으로 사용 가능\n",
    "X = tf.placeholder('float',[None, 3])\n",
    "# y_data가 3개의 요소로되어있는 벡터이기 때문에 [None,3]으로 해주기\n",
    "Y = tf.placeholder('float',[None,3])\n",
    "\n",
    "# Y값 shape가 [3,1] 이기 때문에 Wegiht를 모두 계산하려면 Weight Matrix는 3행 3열로 이루어져야 함\n",
    "W = tf.Variable(tf.random_normal([3,3]))\n",
    "# bias는 요소가 1개\n",
    "b = tf.Variable(tf.random_normal([3]))\n",
    "\n",
    "# softmax로 여러 class로 분류될 확률 summation\n",
    "# hypothesis의 shape = [3,1]. 여기서 3은 클래스 개수\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "\n",
    "# cross-entropy cost function 정의\n",
    "# multi-class이기 때문에 axis=1(행)로 Y값(label)이 들어있는 값 지칭해주기\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# argmax는 가장큰 요소를 갖는 index반환\n",
    "# hypothesis의 3개 요소중 가장 큰 값의 index반환. 3개 요소를 열 방향으로 비교하기 때문에 1 넣어주기\n",
    "prediction = tf.argmax(hypothesis, 1)\n",
    "# 예측값과 실제값을 비교해 Boolean 값으로 반환\n",
    "is_correct = tf.equal(prediction, tf.argmax(Y, 1))\n",
    "# is_correct값들 중 True인 값들만 합해서 데이터 개수로 나누어 평균 정확도 측정\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(201):\n",
    "        cost_val, W_val, _ = sess.run([cost, W, optimizer], feed_dict={X:x_data, Y:y_data})\n",
    "        print(step, cost_val, W_val)\n",
    "    # 학습후 테스트 데이터로 예측값 반환 - 테스트 데이터로 다시 동작시키므로 feed_dict 해주기\n",
    "    print(\"Prediction:\\n\", sess.run(prediction, feed_dict={X:x_test}))\n",
    "    print(\"Accuracy:\\n\", sess.run(accuracy, feed_dict={X:x_test, Y:y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1],\n",
    "             [2],\n",
    "             [3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [3],\n",
       "       [4]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST data hands_on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-8bf8ae5a5303>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/younghun/opt/anaconda3/envs/venvforpython/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/younghun/opt/anaconda3/envs/venvforpython/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /Users/younghun/opt/anaconda3/envs/venvforpython/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /Users/younghun/opt/anaconda3/envs/venvforpython/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/younghun/opt/anaconda3/envs/venvforpython/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/younghun/opt/anaconda3/envs/venvforpython/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1, Cost:3.026574\n",
      "\n",
      "Epoch:2, Cost:1.125213\n",
      "\n",
      "Epoch:3, Cost:0.889004\n",
      "\n",
      "Epoch:4, Cost:0.776008\n",
      "\n",
      "Epoch:5, Cost:0.705967\n",
      "\n",
      "Epoch:6, Cost:0.657075\n",
      "\n",
      "Epoch:7, Cost:0.619899\n",
      "\n",
      "Epoch:8, Cost:0.590395\n",
      "\n",
      "Epoch:9, Cost:0.566203\n",
      "\n",
      "Epoch:10, Cost:0.545325\n",
      "\n",
      "Epoch:11, Cost:0.527488\n",
      "\n",
      "Epoch:12, Cost:0.512184\n",
      "\n",
      "Epoch:13, Cost:0.498391\n",
      "\n",
      "Epoch:14, Cost:0.486831\n",
      "\n",
      "Epoch:15, Cost:0.475247\n",
      "\n",
      "Learning Finished\n",
      "Accuracy:\n",
      " 0.8869\n",
      "Label: [9]\n",
      "Prediciton:\n",
      " [9]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "# MNIST 클래스 0~9까지므로 10개\n",
    "nb_classes = 10\n",
    "# image 픽셀 한칸을 하나의 Feature로 하기 때문에 가로 28 세로 28\n",
    "X = tf.placeholder(tf.float32, [None, 28*28])\n",
    "Y = tf.placeholder(tf.float32, [None, nb_classes])\n",
    "\n",
    "# Y값이 [10,1]이기 때문에 28*28개의 Feature의 모든 weight 계산하기 위한 Weight Matrix shape\n",
    "W = tf.Variable(tf.random_normal([28*28, nb_classes]))\n",
    "b = tf.Variable(tf.random_normal([nb_classes]))\n",
    "\n",
    "# multi-class분류라 softmax로 summation\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "# multi class의 cross-entropy\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# 모델 테스트하는 텐서 만들기\n",
    "is_correct = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, dtype=tf.float32))\n",
    "\n",
    "# epoch, batch size 파라미터 설정\n",
    "# 100개씩 15번 반복 학습\n",
    "num_epochs = 15\n",
    "batch_size = 100\n",
    "num_iterations = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # epoch 15번을 한 번씩 수행하도록 반복문 \n",
    "    for epoch in range(num_epochs):\n",
    "        avg_cost = 0 \n",
    "        for i in range(num_iterations):\n",
    "            # batch size만큼 MNIST 데이터 분할 메소드\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            # SGD 수행하면서 cost 계산\n",
    "            _, cost_val = sess.run([optimizer, cost], feed_dict={X:batch_xs, Y:batch_ys})\n",
    "            # 평균 cost값 계산(반복문 밖에서 수행해도 괜찮)\n",
    "            avg_cost += cost_val / num_iterations\n",
    "        print(f\"Epoch:{epoch+1}, Cost:{avg_cost:4f}\")\n",
    "        print()\n",
    "    print(\"Learning Finished\")\n",
    "    print('Accuracy:\\n',sess.run(accuracy, feed_dict={X:mnist.test.images, Y:mnist.test.labels}))\n",
    "    \n",
    "    # MNIST 이미지 데이터 중 하나 랜덤으로 추출\n",
    "    r = random.randint(0, mnist.test.num_examples - 1)\n",
    "    # 위에서 뽑은 랜덤 데이터하나에 매핑된 정답 이미지 추출\n",
    "    print('Label:', sess.run(tf.argmax(mnist.test.labels[r: r+1], 1)))\n",
    "\n",
    "    # 위에서 뽑은 랜덤 데이터를 모델에 집어넣어 모델리 예측한 이미지 반환\n",
    "    print('Prediciton:\\n',sess.run(tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r: r+1]}))\n",
    "    \n",
    "    # 정답 레이블 이미지 출력\n",
    "    plt.imshow(mnist.test.images[r: r+1].reshape(28, 28),\n",
    "              cmap='Greys', interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep FNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.array([[0,0], [0,1], [1,0], [1,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "x = tf.cast([0.3, 1.2], dtype=tf.float32)\n",
    "y = tf.cast(x > 0.5, dtype=tf.float32)\n",
    "print(sess.run(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "z = tf.equal(1,2)\n",
    "print(sess.run(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
